a:5:{s:5:"title";N;s:6:"status";i:1;s:6:"number";i:105;s:8:"comments";a:108:{s:32:"e5737b70c777da90c29ee01e726ac2cc";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"gneta";s:4:"name";s:9:"Gila Neta";s:4:"mail";s:20:"netagil@mail.nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1533572975;}s:3:"raw";s:717:"Hi everyone,

I just wanted to take a moment to welcome you to our small group and to let you know how excited I am to be working with you over the coming months. 

As we move through the modules, we appreciate your timely completion of assignments, and we will be providing feedback as we go. We welcome each of you to provide feedback and ask questions as well. While the course is self paced, please help us keep this group on track by posting by the due dates.

We will be scheduling a call with you to have each of you deliver your elevator pitch and get live feedback from the group. Please stay tuned for an email and doodle poll to schedule this call. 

Looking forward to working with all of you!

Best,
Gila";s:5:"xhtml";s:772:"Hi everyone,<br /><br />I just wanted to take a moment to welcome you to our small group and to let you know how excited I am to be working with you over the coming months. <br /><br />As we move through the modules, we appreciate your timely completion of assignments, and we will be providing feedback as we go. We welcome each of you to provide feedback and ask questions as well. While the course is self paced, please help us keep this group on track by posting by the due dates.<br /><br />We will be scheduling a call with you to have each of you deliver your elevator pitch and get live feedback from the group. Please stay tuned for an email and doodle poll to schedule this call. <br /><br />Looking forward to working with all of you!<br /><br />Best,<br />Gila";s:6:"parent";N;s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"e5737b70c777da90c29ee01e726ac2cc";}s:32:"e36a97bc17530b285bf87bcfa9d473b9";a:8:{s:4:"user";a:5:{s:2:"id";s:6:"klyons";s:4:"name";s:14:"Kathleen Lyons";s:4:"mail";s:30:"Kathleen.D.Lyons@dartmouth.edu";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1534452051;}s:3:"raw";s:611:"Dear Gila and group members,
I am really excited about this training and the chance to work with everyone. I will be posting my assignment today, but wanted to let you know that I will be traveling outside of the country for vacation without access to email from 8/17 to 8/26. I will check the site again the week I return to make sure I don't miss anything.

I am uploading my assignment 1, but I'm already thinking I might end up working on another proposal building on a local opportunity where I work...but whether it is this project or another one, I am happy to have this training!

Thank you,
Kathy Lyons";s:5:"xhtml";s:651:"Dear Gila and group members,<br />I am really excited about this training and the chance to work with everyone. I will be posting my assignment today, but wanted to let you know that I will be traveling outside of the country for vacation without access to email from 8/17 to 8/26. I will check the site again the week I return to make sure I don&#039;t miss anything.<br /><br />I am uploading my assignment 1, but I&#039;m already thinking I might end up working on another proposal building on a local opportunity where I work...but whether it is this project or another one, I am happy to have this training!<br /><br />Thank you,<br />Kathy Lyons";s:6:"parent";N;s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"e36a97bc17530b285bf87bcfa9d473b9";}s:32:"b751b3e817966e08f2208079c5f3f68a";a:8:{s:4:"user";a:5:{s:2:"id";s:6:"klyons";s:4:"name";s:14:"Kathleen Lyons";s:4:"mail";s:30:"Kathleen.D.Lyons@dartmouth.edu";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1534452208;}s:3:"raw";s:8253:"Lyons- Assignment #1a
Draft a specific aims page.
My response to that is:

Symptom burden during chemotherapy. Patients undergoing chemotherapy experience an average of eight different symptoms and side effects (Chang, Hwang, Feuerman, & Kasimis, 2000). Symptoms often present in clusters such as nausea-vomiting, anxiety-depression, fatigue-drowsiness, and pain-constipation (Kirkova, Aktas, Walsh, & Davis, 2011). Ineffective symptom management leads to patient and family distress and, at times, necessitates dose reductions, which decrease cancer treatment effectiveness (Camp-Sorrell, 2018). Globally, there are many practice guidelines and a robust evidence base for symptom management (National Comprehensive Cancer Network, 2016).

Symptom management in Honduras. Honduras is one of the most under-developed countries in Latin America in terms of the capacity of deliver palliative care (Pastrana, Torres-Vigil, & De Lima, 2014) and Honduran nurses have identified symptom management as a priority area for continuing education (Sheldon et al., 2013). However, a lack of education is not the only barrier to effective symptom management in Honduras. Hondurans being treated for cancer may need to travel long distances, sometimes by foot, to receive cancer treatment at clinics that are often operating at peak capacity. Patients who experience high symptom burden may find it difficult to return to the clinic for cancer treatment and clinics may be unable to accommodate separate appointments for symptom management. A nurse-led, telephone-delivered symptom management intervention could be one way to help lower patients’ symptom burden without necessitating a clinic visit.    
    
Evidence-based symptom management. A recent meta-analysis indicated nurse-led, telephone-delivered interventions can result in a moderate reduction of cancer symptoms and treatment side effects (Suh & Lee, 2017). One such intervention is the ENABLE supportive care intervention, originally developed for adults with advanced cancer (Bakitas et al., 2009; Bakitas et al., 2015). ENABLE was recommended by the National Cancer Institute Research-Tested Intervention Program after clinical trials generated Level I evidence establishing the program’s efficacy in improving quality of life, mood, and survival as compared to a usual care condition.(Bakitas et al., 2009; Bakitas et al., 2015) The advantage of the ENABLE program is that it builds upon nurses’ existing skill set regarding symptom assessment and management and uses standardized manuals to structure the delivery and education processes. Pilot projects exploring ways to disseminate and implement ENABLE have been conducted both within and outside of the United States, but full-scale controlled trials evaluating implementation strategies have not been conducted.

Pilot work. In order to use an evidence-based intervention in a new setting, it must be culturally tailored and implemented in a sustainable fashion that retains the intervention’s potency and effectiveness. Within the past year, we completed a feasibility study in which we trained nurses at La Liga Contra el Cancer in San Pedro Sula, Honduras to use the symptom management module of ENABLE. The project was part of a larger program of research by our international research team where findings in basic and clinical research are used to not only address local problems, but to spur innovation and identify implementation strategies that can be utilized in any environment where access to care is a problem. The nurses in our feasibility study appreciated the training and enjoyed making the telephone calls, as they felt it gave them a new role and a way to provide more holistic care. However, one of the major implementation challenges was that they were expected to complete the telephone calls in addition to their usual workload. Additionally, they were given a dedicated telephone, but they did not have a private space to complete the calls. They are interested in using the ENABLE module with more patients, but they want to identify adaptations that would allow them to better integrate the intervention into their daily work routines. 

Research questions. Our next step in this line of research will address the following questions: Can we adapt the ENABLE intervention to increase the ease of implementation in a low resource setting? If so, will those adaptations dilute or enhance the intervention’s effectiveness?

Specific Aims

Aim 1: Identify adaptations to the ENABLE intervention that will extend the reach of the intervention (i.e., the proportion of patients undergoing chemotherapy who are exposed to the symptom management content).

We will adopt a mixed method approach including a descriptive study in which we engage the providers in processes to identify solutions to barriers identified in our pilot study. We will collect qualitative data via interview, observation, and focus group and we will collect quantitative data (regarding delays in treatment, hospitalizations) via chart review.

Aim 2: Explore the feasibility and effectiveness of the revised intervention by adapting and implementing it over a six-month period. 

We will utilize a single arm pre-post design that collects data on both patient level effectiveness outcomes (e.g., symptom burden, treatment delays, number of missed appointments) and the system level implementation outcome of reach (e.g., number of patients exposed to the intervention/number of patients beginning chemotherapy).

Impact and potential for reverse translation. What we learn in Honduras is applicable to other low resource environments within and outside of the United States. The advantage of conducting implementation research at La Liga stems from the lack of competing clinical trials and high desire for engagement in research by both patients and providers. This allows rapid execution of small studies that can generate knowledge more quickly than what could be achieved within our home institution. For example, in the feasibility study we accrued our target sample of 25 participants in a little over one month, with only one person declining to enroll in the study.

References

Bakitas, M. A., Lyons, K. D., Hegel, M. T., Balan, S., Brokaw, F. C., Seville, J., . . . Ahles, T. A. (2009). Effects of a palliative care intervention on clinical outcomes in patients with advanced cancer: The Project ENABLE II randomized controlled trial. JAMA, 302(7), 741-749. doi:10.1001/jama.2009.1198
Bakitas, M. A., Tosteson, T. D., Li, Z., Lyons, K. D., Hull, J. G., Li, Z., . . . Ahles, T. A. (2015). Early versus delayed initiation of concurrent palliative oncology care: Patient outcomes in the ENABLE III randomized controlled trial. Journal of Clinical Oncology, 33(13), 1438-1445. doi:JCO.2014.58.6362.
Camp-Sorrell, D. (2018). Chemotherapy toxicities and management. In C. H. Yarbro, D. Wujcik, & B. H. Gobel (Eds.), Cancer Nursing: Principles and Practice (8th ed., pp. 497-554). Burlington, MA: Jones & Bartlett Learning.
Chang, V. T., Hwang, S. S., Feuerman, M., & Kasimis, B. S. (2000). Symptom and quality of life survey of medical oncology patients at a veterans affairs medical center: a role for symptom assessment. Cancer, 88(5), 1175-1183. 
Kirkova, J., Aktas, A., Walsh, D., & Davis, M. P. (2011). Cancer symptom clusters: clinical and research methodology. Journal of Palliative Medicine, 14(10), 1149-1166. doi:10.1089/jpm.2010.0507
National Comprehensive Cancer Network. (2016). NCCN Clinical Practice Guidelines in Oncology: Palliative Care. Retrieved from www.nccn.org
Pastrana, T., Torres-Vigil, I., & De Lima, L. (2014). Palliative care development in Latin America: An analysis using macro indicators. Palliative Medicine, 28(10), 1231-1238. doi:10.1177/0269216314538893
Sheldon, L. K., Wise, B., Carlson, J. R., Dowds, C., Sarchet, V., & Sanchez, J. A. (2013). Developing a Longitudinal Cancer Nursing Education Program in Honduras. Journal of Cancer Education, 28(4), 669-675. doi:10.1007/s13187-013-0497-6
Suh, S.-R., & Lee, M. K. (2017). Effects of Nurse-Led Telephone-Based Supportive Interventions for Patients With Cancer: A Meta-Analysis. Oncology Nursing Forum, 44(4), E168-E184. doi:10.1188/17.onf.e168-e184

";s:5:"xhtml";s:8475:"Lyons- Assignment #1a<br />Draft a specific aims page.<br />My response to that is:<br /><br />Symptom burden during chemotherapy. Patients undergoing chemotherapy experience an average of eight different symptoms and side effects (Chang, Hwang, Feuerman, &amp; Kasimis, 2000). Symptoms often present in clusters such as nausea-vomiting, anxiety-depression, fatigue-drowsiness, and pain-constipation (Kirkova, Aktas, Walsh, &amp; Davis, 2011). Ineffective symptom management leads to patient and family distress and, at times, necessitates dose reductions, which decrease cancer treatment effectiveness (Camp-Sorrell, 2018). Globally, there are many practice guidelines and a robust evidence base for symptom management (National Comprehensive Cancer Network, 2016).<br /><br />Symptom management in Honduras. Honduras is one of the most under-developed countries in Latin America in terms of the capacity of deliver palliative care (Pastrana, Torres-Vigil, &amp; De Lima, 2014) and Honduran nurses have identified symptom management as a priority area for continuing education (Sheldon et al., 2013). However, a lack of education is not the only barrier to effective symptom management in Honduras. Hondurans being treated for cancer may need to travel long distances, sometimes by foot, to receive cancer treatment at clinics that are often operating at peak capacity. Patients who experience high symptom burden may find it difficult to return to the clinic for cancer treatment and clinics may be unable to accommodate separate appointments for symptom management. A nurse-led, telephone-delivered symptom management intervention could be one way to help lower patients’ symptom burden without necessitating a clinic visit.    <br />    <br />Evidence-based symptom management. A recent meta-analysis indicated nurse-led, telephone-delivered interventions can result in a moderate reduction of cancer symptoms and treatment side effects (Suh &amp; Lee, 2017). One such intervention is the ENABLE supportive care intervention, originally developed for adults with advanced cancer (Bakitas et al., 2009; Bakitas et al., 2015). ENABLE was recommended by the National Cancer Institute Research-Tested Intervention Program after clinical trials generated Level I evidence establishing the program’s efficacy in improving quality of life, mood, and survival as compared to a usual care condition.(Bakitas et al., 2009; Bakitas et al., 2015) The advantage of the ENABLE program is that it builds upon nurses’ existing skill set regarding symptom assessment and management and uses standardized manuals to structure the delivery and education processes. Pilot projects exploring ways to disseminate and implement ENABLE have been conducted both within and outside of the United States, but full-scale controlled trials evaluating implementation strategies have not been conducted.<br /><br />Pilot work. In order to use an evidence-based intervention in a new setting, it must be culturally tailored and implemented in a sustainable fashion that retains the intervention’s potency and effectiveness. Within the past year, we completed a feasibility study in which we trained nurses at La Liga Contra el Cancer in San Pedro Sula, Honduras to use the symptom management module of ENABLE. The project was part of a larger program of research by our international research team where findings in basic and clinical research are used to not only address local problems, but to spur innovation and identify implementation strategies that can be utilized in any environment where access to care is a problem. The nurses in our feasibility study appreciated the training and enjoyed making the telephone calls, as they felt it gave them a new role and a way to provide more holistic care. However, one of the major implementation challenges was that they were expected to complete the telephone calls in addition to their usual workload. Additionally, they were given a dedicated telephone, but they did not have a private space to complete the calls. They are interested in using the ENABLE module with more patients, but they want to identify adaptations that would allow them to better integrate the intervention into their daily work routines. <br /><br />Research questions. Our next step in this line of research will address the following questions: Can we adapt the ENABLE intervention to increase the ease of implementation in a low resource setting? If so, will those adaptations dilute or enhance the intervention’s effectiveness?<br /><br />Specific Aims<br /><br />Aim 1: Identify adaptations to the ENABLE intervention that will extend the reach of the intervention (i.e., the proportion of patients undergoing chemotherapy who are exposed to the symptom management content).<br /><br />We will adopt a mixed method approach including a descriptive study in which we engage the providers in processes to identify solutions to barriers identified in our pilot study. We will collect qualitative data via interview, observation, and focus group and we will collect quantitative data (regarding delays in treatment, hospitalizations) via chart review.<br /><br />Aim 2: Explore the feasibility and effectiveness of the revised intervention by adapting and implementing it over a six-month period. <br /><br />We will utilize a single arm pre-post design that collects data on both patient level effectiveness outcomes (e.g., symptom burden, treatment delays, number of missed appointments) and the system level implementation outcome of reach (e.g., number of patients exposed to the intervention/number of patients beginning chemotherapy).<br /><br />Impact and potential for reverse translation. What we learn in Honduras is applicable to other low resource environments within and outside of the United States. The advantage of conducting implementation research at La Liga stems from the lack of competing clinical trials and high desire for engagement in research by both patients and providers. This allows rapid execution of small studies that can generate knowledge more quickly than what could be achieved within our home institution. For example, in the feasibility study we accrued our target sample of 25 participants in a little over one month, with only one person declining to enroll in the study.<br /><br />References<br /><br />Bakitas, M. A., Lyons, K. D., Hegel, M. T., Balan, S., Brokaw, F. C., Seville, J., . . . Ahles, T. A. (2009). Effects of a palliative care intervention on clinical outcomes in patients with advanced cancer: The Project ENABLE II randomized controlled trial. JAMA, 302(7), 741-749. doi:10.1001/jama.2009.1198<br />Bakitas, M. A., Tosteson, T. D., Li, Z., Lyons, K. D., Hull, J. G., Li, Z., . . . Ahles, T. A. (2015). Early versus delayed initiation of concurrent palliative oncology care: Patient outcomes in the ENABLE III randomized controlled trial. Journal of Clinical Oncology, 33(13), 1438-1445. doi:JCO.2014.58.6362.<br />Camp-Sorrell, D. (2018). Chemotherapy toxicities and management. In C. H. Yarbro, D. Wujcik, &amp; B. H. Gobel (Eds.), Cancer Nursing: Principles and Practice (8th ed., pp. 497-554). Burlington, MA: Jones &amp; Bartlett Learning.<br />Chang, V. T., Hwang, S. S., Feuerman, M., &amp; Kasimis, B. S. (2000). Symptom and quality of life survey of medical oncology patients at a veterans affairs medical center: a role for symptom assessment. Cancer, 88(5), 1175-1183. <br />Kirkova, J., Aktas, A., Walsh, D., &amp; Davis, M. P. (2011). Cancer symptom clusters: clinical and research methodology. Journal of Palliative Medicine, 14(10), 1149-1166. doi:10.1089/jpm.2010.0507<br />National Comprehensive Cancer Network. (2016). NCCN Clinical Practice Guidelines in Oncology: Palliative Care. Retrieved from www.nccn.org<br />Pastrana, T., Torres-Vigil, I., &amp; De Lima, L. (2014). Palliative care development in Latin America: An analysis using macro indicators. Palliative Medicine, 28(10), 1231-1238. doi:10.1177/0269216314538893<br />Sheldon, L. K., Wise, B., Carlson, J. R., Dowds, C., Sarchet, V., &amp; Sanchez, J. A. (2013). Developing a Longitudinal Cancer Nursing Education Program in Honduras. Journal of Cancer Education, 28(4), 669-675. doi:10.1007/s13187-013-0497-6<br />Suh, S.-R., &amp; Lee, M. K. (2017). Effects of Nurse-Led Telephone-Based Supportive Interventions for Patients With Cancer: A Meta-Analysis. Oncology Nursing Forum, 44(4), E168-E184. doi:10.1188/17.onf.e168-e184";s:6:"parent";N;s:7:"replies";a:2:{i:0;s:32:"53cc79d7b885b954ed25c5f6fd850e30";i:1;s:32:"d2399894ebf59c5d84127371d9d96af5";}s:4:"show";b:1;s:3:"cid";s:32:"b751b3e817966e08f2208079c5f3f68a";}s:32:"055323f4e3078d397b25a124538e5173";a:8:{s:4:"user";a:5:{s:2:"id";s:8:"kschmitz";s:4:"name";s:15:"Kathryn Schmitz";s:4:"mail";s:20:"kschmitz@phs.psu.edu";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1534852004;}s:3:"raw";s:6084:"Schmitz - Assignment #1a.
Draft a Specific Aims page...
 
Chemotherapy is a crucial part of curative cancer treatments, indicated for approximately 50% of patients.  The ability to complete chemotherapy as originally prescribed is associated with progression free survival of cancer.  Key among the causes of chemotherapy dose alterations are dose limiting toxicities, including patient reported symptoms.  Interventions to address these symptoms have the potential to alter progression free survival.
The evidence base supporting prescription of exercise during chemotherapy is compelling.  A recent meta-analysis included 177 randomized controlled trials that demonstrate that exercise is more effective than pharmacologic interventions for cancer related fatigue.  Improvements in anxiety, depression, and quality of life are also well documented.  Recent evidence suggests that exercise may improve tolerance or efficacy to chemotherapy.  Further, there are multiple published guidelines from major organizations (ACSM, ACS, ASCO, NCCN) that call for exercise to be standard of care after a cancer diagnosis.  Recently the Clinical Oncology Society of Australia published a position stand calling for exercise prescription to be standard practice during cancer care. 
Unfortunately, for cancer patients treated in community oncology settings (85% of cancer is treated in community settings), the likelihood of access to a high quality community based exercise program during treatment is entirely serendipitous.   If there happens to be a champion for such programming in the community, there may be some programming.  Within the clinical setting, we are unaware of very few programs with a goal of providing exercise to all chemotherapy patients.  The barriers to accomplishing this include location, workforce development, cost, regulatory issues, and the culture of cancer (rest, don’t push yourself).
At the Penn State Cancer Institute, we have opened a 300 square foot ‘Exercise Medicine Unit’ within the chemo infusion suite, staffed by an experienced exercise professional with specialty training in exercise oncology.  We are attempting to identify and offer exercise to every patient receiving infusion therapy for cancer at our institute.  At one year into the ENACT protocol, we have screened over 400 patients, consented 140 patients into the pre-post trial, and we identified numerous barriers and noted facilitators that could be levers to move this agenda forward.  We have gained the trust of the clinical staff, and 75% of our participants now come from clinical referrals rather than identification of patients through review of medical records.  We have learned about the challenges of identifying patients through the Electronic Medical Records, the need to individualize patient approach to reflect a given physician’s wishes, and the astounding resilience of metastatic cancer patients to undertake an exercise program.  We are undertaking qualitative research to understand how the physicians, nurses, medical schedulers, and patients have experienced the ENACT program. One of the reasons for applying for TIDIRH at this time is goal of understanding whether there is additional preliminary D&I data to be collected in the ENACT protocol that would facilitate a successful grant application.  It will be too late to do this next year, so time is of the essence.
The target population for the proposed research is patients receiving infusion therapy for a solid cancer tumor, including metastatic patients.  The setting in which we would like to study dissemination and implementation of an exercise oncology intervention is the infusion suite of community oncology clinics.  
Specific Aims
Primary Aim.  To successfully implement a personalized exercise intervention program (ENACT) within the setting of chemotherapy infusion suites of N=8 community oncology clinics.
Accomplishing this aim will require 2 steps.  (1) A one year ‘smart’ pilot during which we adapt implementation strategies learned through the ENACT trial to the community oncology clinic setting, learning from our stakeholders as we proceed. (2) A 2-3 year roll out of the best implementation strategy determined from prior work and evaluate success in a stepped wedge group randomized trial.  Success will be defined as % of patients who get the intervention (primary outcome) and % of providers referring patients into the intervention.
Secondary Aim 1.  To conduct a multilevel evaluation of the implementation strategies employed in the part 2 of the primary aim.  
Qualitative and quantitative data collection will take place at the level of patients, providers, and clinic management to evaluate each implementation strategy employed.  Each measure will be well validated and theoretically justified.  Which theory?  NOT A CLUE.  (I seek help here.)
Secondary Aim 2.  To evaluate the cost of implementation (a business impact analysis).  
To accomplish this aim, we collect collection on the cost of each element of implementation strategy.  In combination with data from Aim 2, we will produce a summative analysis of the possible range of costs of implementation, including and excluding less effective strategies.   
Secondary Aim 3.  To evaluate whether the revised intervention retains effectiveness after translation to the community oncology setting, particularly with regard to cancer related fatigue.  
To accomplish this aim, we will administer self-reported patient reported outcomes measures of cancer symptoms from the NCI PROMIS initiative to a subset of patients at each participating clinic. Symptoms to be assessed will include fatigue, pain, and anxiety.
Exercise has been shown to be effective to address patient reported symptoms that could impact the ability to successfully complete chemotherapy.  This, in turn, may effect progression free survival of cancer.  The proposed work aims to develop best practice methods to implement effective exercise programming as standard practice within community oncology clinics to address this care gap. 


";s:5:"xhtml";s:6169:"Schmitz - Assignment #1a.<br />Draft a Specific Aims page...<br /> <br />Chemotherapy is a crucial part of curative cancer treatments, indicated for approximately 50% of patients.  The ability to complete chemotherapy as originally prescribed is associated with progression free survival of cancer.  Key among the causes of chemotherapy dose alterations are dose limiting toxicities, including patient reported symptoms.  Interventions to address these symptoms have the potential to alter progression free survival.<br />The evidence base supporting prescription of exercise during chemotherapy is compelling.  A recent meta-analysis included 177 randomized controlled trials that demonstrate that exercise is more effective than pharmacologic interventions for cancer related fatigue.  Improvements in anxiety, depression, and quality of life are also well documented.  Recent evidence suggests that exercise may improve tolerance or efficacy to chemotherapy.  Further, there are multiple published guidelines from major organizations (ACSM, ACS, ASCO, NCCN) that call for exercise to be standard of care after a cancer diagnosis.  Recently the Clinical Oncology Society of Australia published a position stand calling for exercise prescription to be standard practice during cancer care. <br />Unfortunately, for cancer patients treated in community oncology settings (85% of cancer is treated in community settings), the likelihood of access to a high quality community based exercise program during treatment is entirely serendipitous.   If there happens to be a champion for such programming in the community, there may be some programming.  Within the clinical setting, we are unaware of very few programs with a goal of providing exercise to all chemotherapy patients.  The barriers to accomplishing this include location, workforce development, cost, regulatory issues, and the culture of cancer (rest, don’t push yourself).<br />At the Penn State Cancer Institute, we have opened a 300 square foot ‘Exercise Medicine Unit’ within the chemo infusion suite, staffed by an experienced exercise professional with specialty training in exercise oncology.  We are attempting to identify and offer exercise to every patient receiving infusion therapy for cancer at our institute.  At one year into the ENACT protocol, we have screened over 400 patients, consented 140 patients into the pre-post trial, and we identified numerous barriers and noted facilitators that could be levers to move this agenda forward.  We have gained the trust of the clinical staff, and 75% of our participants now come from clinical referrals rather than identification of patients through review of medical records.  We have learned about the challenges of identifying patients through the Electronic Medical Records, the need to individualize patient approach to reflect a given physician’s wishes, and the astounding resilience of metastatic cancer patients to undertake an exercise program.  We are undertaking qualitative research to understand how the physicians, nurses, medical schedulers, and patients have experienced the ENACT program. One of the reasons for applying for TIDIRH at this time is goal of understanding whether there is additional preliminary D&amp;I data to be collected in the ENACT protocol that would facilitate a successful grant application.  It will be too late to do this next year, so time is of the essence.<br />The target population for the proposed research is patients receiving infusion therapy for a solid cancer tumor, including metastatic patients.  The setting in which we would like to study dissemination and implementation of an exercise oncology intervention is the infusion suite of community oncology clinics.  <br />Specific Aims<br />Primary Aim.  To successfully implement a personalized exercise intervention program (ENACT) within the setting of chemotherapy infusion suites of N=8 community oncology clinics.<br />Accomplishing this aim will require 2 steps.  (1) A one year ‘smart’ pilot during which we adapt implementation strategies learned through the ENACT trial to the community oncology clinic setting, learning from our stakeholders as we proceed. (2) A 2-3 year roll out of the best implementation strategy determined from prior work and evaluate success in a stepped wedge group randomized trial.  Success will be defined as % of patients who get the intervention (primary outcome) and % of providers referring patients into the intervention.<br />Secondary Aim 1.  To conduct a multilevel evaluation of the implementation strategies employed in the part 2 of the primary aim.  <br />Qualitative and quantitative data collection will take place at the level of patients, providers, and clinic management to evaluate each implementation strategy employed.  Each measure will be well validated and theoretically justified.  Which theory?  NOT A CLUE.  (I seek help here.)<br />Secondary Aim 2.  To evaluate the cost of implementation (a business impact analysis).  <br />To accomplish this aim, we collect collection on the cost of each element of implementation strategy.  In combination with data from Aim 2, we will produce a summative analysis of the possible range of costs of implementation, including and excluding less effective strategies.   <br />Secondary Aim 3.  To evaluate whether the revised intervention retains effectiveness after translation to the community oncology setting, particularly with regard to cancer related fatigue.  <br />To accomplish this aim, we will administer self-reported patient reported outcomes measures of cancer symptoms from the NCI PROMIS initiative to a subset of patients at each participating clinic. Symptoms to be assessed will include fatigue, pain, and anxiety.<br />Exercise has been shown to be effective to address patient reported symptoms that could impact the ability to successfully complete chemotherapy.  This, in turn, may effect progression free survival of cancer.  The proposed work aims to develop best practice methods to implement effective exercise programming as standard practice within community oncology clinics to address this care gap.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"e49d84835f4358dbb9bec3651b0139ef";}s:4:"show";b:1;s:3:"cid";s:32:"055323f4e3078d397b25a124538e5173";}s:32:"d68470090607df648eb174d63afaa8be";a:8:{s:4:"user";a:5:{s:2:"id";s:8:"kschmitz";s:4:"name";s:15:"Kathryn Schmitz";s:4:"mail";s:20:"kschmitz@phs.psu.edu";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:2:{s:7:"created";i:1534852091;s:8:"modified";i:1534852245;}s:3:"raw";s:250:"Good morning everyone - 

I am STOKED to learn from our experts and from all of our group members. 
Looking forward to call #1!

Meanwhile... I think I could be a participant in the study outlined in the elevator speech example PPT. :)

Katie Schmitz";s:5:"xhtml";s:285:"Good morning everyone - <br /><br />I am STOKED to learn from our experts and from all of our group members. <br />Looking forward to call #1!<br /><br />Meanwhile... I think I could be a participant in the study outlined in the elevator speech example PPT. :)<br /><br />Katie Schmitz";s:6:"parent";N;s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"d68470090607df648eb174d63afaa8be";}s:32:"518a04dcb43f367baf3cf989cf607e7a";a:8:{s:4:"user";a:5:{s:2:"id";s:10:"ldimartino";s:4:"name";s:14:"Lisa DiMartino";s:4:"mail";s:18:"ldimartino@rti.org";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:2:{s:7:"created";i:1534872442;s:8:"modified";i:1534873108;}s:3:"raw";s:6226:"DiMartino-Module #1 Specific Aims
I recently submitted a similar proposal idea to AHRQ but it was not funded.  I am interested in continuing to pursue this idea and resubmitting to one of the DIRH funding mechanism.  I look forward to receiving feedback on this from the group!

Many cancer patients experience poor symptom control and aggressive treatment near the end of their lives, including costly hospitalizations, with limited medical benefits. In 2009, 4.7 million hospitalizations were due to adult cancer; the total costs associated with these hospitalizations were $20.1 billion and accounted for 6% of all hospital costs. In addition, cancer patients frequent the emergency department for their acute care needs, such as uncontrolled pain or respiratory distress, which often result in inpatient admissions.Integration of palliative care (PC) services concurrently with cancer treatment is associated with improved quality of life, reduced intensity of treatment, and similar or improved survival. Several studies also show PC can reduce hospital costs up to 24%, with earlier integration having larger cost-saving effect.  Despite existing guideline recommendations and strong evidence-base for PC integration in oncology, many cancer inpatients do not receive PC. Prior research indicates that <50% advanced cancer inpatients receive PC services.  Increasingly, hospitalized cancer patients who need PC are identified using predetermined clinical criteria (e.g., presence of metastatic disease with uncontrolled symptoms). Implementation of these criteria has been shown to improve quality of cancer care, including increased PC consult use by nearly 20%, reduced 30-day readmissions, and increased hospice use. Yet, no standard approach exists to automatically identify patients who meet criteria for PC. Clinical decision support (CDS) tools may provide a promising strategy to efficiently identify cancer patients who need PC based on clinical criteria in the electronic health record (EHR), thereby improving uptake of these services. However, identifying cancer inpatients in the EHR who meet criteria for PC is more challenging than expected, especially when trying to achieve effective population health management.  Criteria for PC (e.g. pain severity, disease progression, number and severity of comorbid conditions) are found in varied locations, recorded by clinicians from different disciplines, and inconsistently documented. Further, clinical information on these criteria exist in structured data elements and unstructured free-text narratives, requiring time-consuming and costly manual abstraction.  The proposed study addresses an urgent need to develop evidence-based CDS tools to improve the identification of hospitalized cancer patients who need PC, thereby improving value and quality of care in this seriously ill population. 

The long-term goal of the study is to increase rates of PC service delivery among hospitalized cancer patients.  The objective of this application is to develop and examine the feasibility of a CDS tool (automated EHR-generated reminder) using machine learning (ML) to identify hospitalized cancer patients who need PC. CDS tools have been shown to be an effective strategy for improving uptake of evidence-based care across a variety of health conditions, including cancer.   However, adoption of CDS tools in clinical practice is often suboptimal, with nearly 96% of recommendations ignored by providers. To improve adoption and maximize the potential of the CDS tool as a strategy in this setting, the tool will be developed by: 1) using ML to tailor PC access and services to match patient needs. ML is a statistical technique that gives computer systems the ability to learn with data, without being explicitly programmed, and is increasingly combined with CDS tool development; and 2) formatively evaluating provider and organizational contextual factors related to adoption of a ML-based CDS tool.
Listed below are research aims I intend to pursue as a part of this R21 grant application to be submitted to NIH (PAR-16-236).  

Specific Aim 1: Develop a “proof of concept” ML-based CDS tool (implementation strategy) using EHR data (structured and unstructured) to identify hospitalized cancer patients who need PC.  Develop ML algorithms that identify patterns in EHR data between patient characteristics and receipt of PC. This includes using ML and natural language processing (NLP) to scope structured and unstructured data elements and evaluating a variety of modelling approaches. Model accuracy will be assessed through analytic validation and domain-expert evaluation by comparing results to a gold standard (i.e., chart review). This aim will rely on existing EHR data from University of North Carolina (UNC) Hospitals.

Specific Aim 2: Conduct a formative evaluation of a ML-based CDS tool as a novel implementation strategy for identifying hospitalized cancer patients who need PC.  Conduct semi-structured interviews with key stakeholders (e.g., oncologists, PC physicians, nurses, and others) from several healthcare institutions (n=3) to elucidate potential provider and organizational level barriers/facilitators to tool adoption and to inform necessary modifications to the tool.  Quantitative surveys will assess the feasibility, acceptability, and appropriateness of the tool as a strategy.  The evaluation will be guided by the Theoretical Domains Framework (TDF) and Consolidated Framework for Implementation Research (CFIR).

This study is innovative in that it seeks to develop a novel CDS tool using ML techniques as a strategy for identifying hospitalized cancer patients who would benefit the most from PC.  The expected outcomes of the project will provide the basis for an implementation-effectiveness trial testing the tool in clinical practice and examining whether its use translates into more appropriate care and improved outcomes for hospitalized cancer patients.  The ultimate goal of the study is to contribute to the evidence-base about best practices for improving integration of PC services in oncology, while also informing future use of ML-based CDS tools as a novel strategy to support implementation.  




";s:5:"xhtml";s:6282:"DiMartino-Module #1 Specific Aims<br />I recently submitted a similar proposal idea to AHRQ but it was not funded.  I am interested in continuing to pursue this idea and resubmitting to one of the DIRH funding mechanism.  I look forward to receiving feedback on this from the group!<br /><br />Many cancer patients experience poor symptom control and aggressive treatment near the end of their lives, including costly hospitalizations, with limited medical benefits. In 2009, 4.7 million hospitalizations were due to adult cancer; the total costs associated with these hospitalizations were $20.1 billion and accounted for 6% of all hospital costs. In addition, cancer patients frequent the emergency department for their acute care needs, such as uncontrolled pain or respiratory distress, which often result in inpatient admissions.Integration of palliative care (PC) services concurrently with cancer treatment is associated with improved quality of life, reduced intensity of treatment, and similar or improved survival. Several studies also show PC can reduce hospital costs up to 24%, with earlier integration having larger cost-saving effect.  Despite existing guideline recommendations and strong evidence-base for PC integration in oncology, many cancer inpatients do not receive PC. Prior research indicates that &lt;50% advanced cancer inpatients receive PC services.  Increasingly, hospitalized cancer patients who need PC are identified using predetermined clinical criteria (e.g., presence of metastatic disease with uncontrolled symptoms). Implementation of these criteria has been shown to improve quality of cancer care, including increased PC consult use by nearly 20%, reduced 30-day readmissions, and increased hospice use. Yet, no standard approach exists to automatically identify patients who meet criteria for PC. Clinical decision support (CDS) tools may provide a promising strategy to efficiently identify cancer patients who need PC based on clinical criteria in the electronic health record (EHR), thereby improving uptake of these services. However, identifying cancer inpatients in the EHR who meet criteria for PC is more challenging than expected, especially when trying to achieve effective population health management.  Criteria for PC (e.g. pain severity, disease progression, number and severity of comorbid conditions) are found in varied locations, recorded by clinicians from different disciplines, and inconsistently documented. Further, clinical information on these criteria exist in structured data elements and unstructured free-text narratives, requiring time-consuming and costly manual abstraction.  The proposed study addresses an urgent need to develop evidence-based CDS tools to improve the identification of hospitalized cancer patients who need PC, thereby improving value and quality of care in this seriously ill population. <br /><br />The long-term goal of the study is to increase rates of PC service delivery among hospitalized cancer patients.  The objective of this application is to develop and examine the feasibility of a CDS tool (automated EHR-generated reminder) using machine learning (ML) to identify hospitalized cancer patients who need PC. CDS tools have been shown to be an effective strategy for improving uptake of evidence-based care across a variety of health conditions, including cancer.   However, adoption of CDS tools in clinical practice is often suboptimal, with nearly 96% of recommendations ignored by providers. To improve adoption and maximize the potential of the CDS tool as a strategy in this setting, the tool will be developed by: 1) using ML to tailor PC access and services to match patient needs. ML is a statistical technique that gives computer systems the ability to learn with data, without being explicitly programmed, and is increasingly combined with CDS tool development; and 2) formatively evaluating provider and organizational contextual factors related to adoption of a ML-based CDS tool.<br />Listed below are research aims I intend to pursue as a part of this R21 grant application to be submitted to NIH (PAR-16-236).  <br /><br />Specific Aim 1: Develop a “proof of concept” ML-based CDS tool (implementation strategy) using EHR data (structured and unstructured) to identify hospitalized cancer patients who need PC.  Develop ML algorithms that identify patterns in EHR data between patient characteristics and receipt of PC. This includes using ML and natural language processing (NLP) to scope structured and unstructured data elements and evaluating a variety of modelling approaches. Model accuracy will be assessed through analytic validation and domain-expert evaluation by comparing results to a gold standard (i.e., chart review). This aim will rely on existing EHR data from University of North Carolina (UNC) Hospitals.<br /><br />Specific Aim 2: Conduct a formative evaluation of a ML-based CDS tool as a novel implementation strategy for identifying hospitalized cancer patients who need PC.  Conduct semi-structured interviews with key stakeholders (e.g., oncologists, PC physicians, nurses, and others) from several healthcare institutions (n=3) to elucidate potential provider and organizational level barriers/facilitators to tool adoption and to inform necessary modifications to the tool.  Quantitative surveys will assess the feasibility, acceptability, and appropriateness of the tool as a strategy.  The evaluation will be guided by the Theoretical Domains Framework (TDF) and Consolidated Framework for Implementation Research (CFIR).<br /><br />This study is innovative in that it seeks to develop a novel CDS tool using ML techniques as a strategy for identifying hospitalized cancer patients who would benefit the most from PC.  The expected outcomes of the project will provide the basis for an implementation-effectiveness trial testing the tool in clinical practice and examining whether its use translates into more appropriate care and improved outcomes for hospitalized cancer patients.  The ultimate goal of the study is to contribute to the evidence-base about best practices for improving integration of PC services in oncology, while also informing future use of ML-based CDS tools as a novel strategy to support implementation.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"fb23a554dd1c68396a9eceb74dd89ca8";}s:4:"show";b:1;s:3:"cid";s:32:"518a04dcb43f367baf3cf989cf607e7a";}s:32:"53cc79d7b885b954ed25c5f6fd850e30";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"gneta";s:4:"name";s:9:"Gila Neta";s:4:"mail";s:20:"netagil@mail.nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1535046977;}s:3:"raw";s:497:"Kathy, this is a very interesting project and a nicely told story. It seems like you laid out quite clearly what the implementation problem is, that nurses just don't have time to make these calls. So I was expecting the research question to focus on examining a specific strategy or set of strategies to address that particular barrier. Perhaps through task shifting? I think having a bit more specificity in your aims would help strengthen them. And you've set yourself up very well to do this. ";s:5:"xhtml";s:506:"Kathy, this is a very interesting project and a nicely told story. It seems like you laid out quite clearly what the implementation problem is, that nurses just don&#039;t have time to make these calls. So I was expecting the research question to focus on examining a specific strategy or set of strategies to address that particular barrier. Perhaps through task shifting? I think having a bit more specificity in your aims would help strengthen them. And you&#039;ve set yourself up very well to do this.";s:6:"parent";s:32:"b751b3e817966e08f2208079c5f3f68a";s:7:"replies";a:1:{i:0;s:32:"5898a8ef0096e1b0c895858c53e12925";}s:4:"show";b:1;s:3:"cid";s:32:"53cc79d7b885b954ed25c5f6fd850e30";}s:32:"5898a8ef0096e1b0c895858c53e12925";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"gneta";s:4:"name";s:9:"Gila Neta";s:4:"mail";s:20:"netagil@mail.nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1535047174;}s:3:"raw";s:295:"One more reaction I wanted to share, perhaps more of a question: How good are the telecommunication systems in Honduras? My experience in Mexico and Central America is that phone service can be quite unreliable and prohibitively expensive for some households. Might this be an issue in Honduras?";s:5:"xhtml";s:295:"One more reaction I wanted to share, perhaps more of a question: How good are the telecommunication systems in Honduras? My experience in Mexico and Central America is that phone service can be quite unreliable and prohibitively expensive for some households. Might this be an issue in Honduras?";s:6:"parent";s:32:"53cc79d7b885b954ed25c5f6fd850e30";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"5898a8ef0096e1b0c895858c53e12925";}s:32:"268faf1f2f3e0c805e52e2868f86216a";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"lreinke";s:4:"name";s:11:"Lynn Reinke";s:4:"mail";s:19:"Lynn.Reinke1@va.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1535064785;}s:3:"raw";s:4679:"Reinke #1. Draft of SA:

Implementation of a nurse-led palliative care intervention into oncology services for Veterans newly diagnosed with lung cancer

Background: 
VA cares for approximately 10,000 incident cases of lung cancer per year, which is nearly 6% of all lung cancers diagnosed within the US annually. Because 40% of lung cancer diagnoses are made when disease is advanced, the disease is highly fatal with nearly 85% of all patients dying within 5 years of diagnosis. The American College of Chest Physicians and the American Society of Clinical Oncology recommends the integration of palliative care approaches at the onset of diagnosis which includes a set of supportive services that integrates care designed to prolong life as well as improve symptoms.  Palliative care, which is distinct from hospice, focuses on the “effective management of pain and other distressing symptoms, while incorporating psychosocial and spiritual care with consideration of patient and family needs, preferences, values, beliefs and culture.” The primary treatments for lung cancer including surgical resections, chemotherapy and radiation therapy produce morbidity and symptom burden. 
Despite studies demonstrating that initiation of early palliative care services leads to significant improvements in quality of life and prolonged survival, there has been little focus on testing integrative care models during curative treatments. To address this gap, we conducted a pilot study testing a palliative care intervention with 40 subjects demonstrating patient acceptability and feasibility. We conducted qualitative interviews with clinicians in 6 geographically diverse VAs to assess their perceptions of integrating palliative and oncology care. We found large variability among clinicians’ attitudes related to integrating services. Clinicians offered practical suggestions to promote successful adoption of a nurse-led model of care. Currently we are conducting a VA funded multi-site RCT to determine the efficacy of a nurse-led telephone-based palliative care intervention for patients newly diagnosed with lung cancer on quality of life, symptom burden and satisfaction of care. 
The goal of this proposal is to use a hybrid effectiveness/implementation design, Type 2, to determine the clinical effectiveness of the palliative care intervention while simultaneously testing implementation strategies in 4 geographically diverse Veterans Integrated Service Networks (VISNs). 
Specific Aims:

1.	Among patients with newly diagnosed lung cancer, determine the effectiveness of a nurse-led, telephone-based palliative care intervention for patients newly diagnosed with lung cancer on clinical outcomes including quality of life, symptom burden and patient satisfaction of care. 

This aim will be accomplished by conducting a clustered randomized trial (unit of randomization is a VISN) testing the effectiveness of the nurse-led palliative care intervention on patients newly diagnosed with lung cancer.   


2.	Among 4 VISNs, test an implementation strategy of a nurse-led palliative care intervention on provider education, champion engagement, marketing and cost estimates to facilitate adoption, fidelity and sustainability of the palliative care intervention.  

This will be accomplished by applying mixed methods including directly observing and conducting interviews with stakeholders to identify factors (behavioral, social, cultural, institutional, economic) that may shape behavior or organizational processes and then select appropriate theoretical constructs to predict desired changes. For example, if the VA facility has an established oncology nurse navigator team we will leverage this program as a platform to incorporate and adapt our intervention to the cultural context of the medical center with input from stakeholders. We will also collect quantitative data such as nurse FTE and patient health care utilization. 


Timeframe:  The estimated timeframe to test this hybrid effectiveness/implementation design, Type 2 will occur over a 4 year funding period.


Importance to the field:  The application of evidence-based palliative care protocols will elevate the quality of care delivery by clinicians resulting in improved quality of life, decreased symptom burden and higher patient satisfaction of care.  Integration of palliative care principles into oncology and pulmonary services will improve patient access to palliative care by eliminating a specialty consultation visit. Furthermore, telephonic delivery of the intervention will reduce travel burden for patients thereby preserving their energy for important activities of living.  



";s:5:"xhtml";s:4788:"Reinke #1. Draft of SA:<br /><br />Implementation of a nurse-led palliative care intervention into oncology services for Veterans newly diagnosed with lung cancer<br /><br />Background: <br />VA cares for approximately 10,000 incident cases of lung cancer per year, which is nearly 6% of all lung cancers diagnosed within the US annually. Because 40% of lung cancer diagnoses are made when disease is advanced, the disease is highly fatal with nearly 85% of all patients dying within 5 years of diagnosis. The American College of Chest Physicians and the American Society of Clinical Oncology recommends the integration of palliative care approaches at the onset of diagnosis which includes a set of supportive services that integrates care designed to prolong life as well as improve symptoms.  Palliative care, which is distinct from hospice, focuses on the “effective management of pain and other distressing symptoms, while incorporating psychosocial and spiritual care with consideration of patient and family needs, preferences, values, beliefs and culture.” The primary treatments for lung cancer including surgical resections, chemotherapy and radiation therapy produce morbidity and symptom burden. <br />Despite studies demonstrating that initiation of early palliative care services leads to significant improvements in quality of life and prolonged survival, there has been little focus on testing integrative care models during curative treatments. To address this gap, we conducted a pilot study testing a palliative care intervention with 40 subjects demonstrating patient acceptability and feasibility. We conducted qualitative interviews with clinicians in 6 geographically diverse VAs to assess their perceptions of integrating palliative and oncology care. We found large variability among clinicians’ attitudes related to integrating services. Clinicians offered practical suggestions to promote successful adoption of a nurse-led model of care. Currently we are conducting a VA funded multi-site RCT to determine the efficacy of a nurse-led telephone-based palliative care intervention for patients newly diagnosed with lung cancer on quality of life, symptom burden and satisfaction of care. <br />The goal of this proposal is to use a hybrid effectiveness/implementation design, Type 2, to determine the clinical effectiveness of the palliative care intervention while simultaneously testing implementation strategies in 4 geographically diverse Veterans Integrated Service Networks (VISNs). <br />Specific Aims:<br /><br />1.	Among patients with newly diagnosed lung cancer, determine the effectiveness of a nurse-led, telephone-based palliative care intervention for patients newly diagnosed with lung cancer on clinical outcomes including quality of life, symptom burden and patient satisfaction of care. <br /><br />This aim will be accomplished by conducting a clustered randomized trial (unit of randomization is a VISN) testing the effectiveness of the nurse-led palliative care intervention on patients newly diagnosed with lung cancer.   <br /><br /><br />2.	Among 4 VISNs, test an implementation strategy of a nurse-led palliative care intervention on provider education, champion engagement, marketing and cost estimates to facilitate adoption, fidelity and sustainability of the palliative care intervention.  <br /><br />This will be accomplished by applying mixed methods including directly observing and conducting interviews with stakeholders to identify factors (behavioral, social, cultural, institutional, economic) that may shape behavior or organizational processes and then select appropriate theoretical constructs to predict desired changes. For example, if the VA facility has an established oncology nurse navigator team we will leverage this program as a platform to incorporate and adapt our intervention to the cultural context of the medical center with input from stakeholders. We will also collect quantitative data such as nurse FTE and patient health care utilization. <br /><br /><br />Timeframe:  The estimated timeframe to test this hybrid effectiveness/implementation design, Type 2 will occur over a 4 year funding period.<br /><br /><br />Importance to the field:  The application of evidence-based palliative care protocols will elevate the quality of care delivery by clinicians resulting in improved quality of life, decreased symptom burden and higher patient satisfaction of care.  Integration of palliative care principles into oncology and pulmonary services will improve patient access to palliative care by eliminating a specialty consultation visit. Furthermore, telephonic delivery of the intervention will reduce travel burden for patients thereby preserving their energy for important activities of living.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"25aae1b5d90cf58b1fbdee26a2e60c2b";}s:4:"show";b:1;s:3:"cid";s:32:"268faf1f2f3e0c805e52e2868f86216a";}s:32:"d74a60d134cb36ac8c3c755e5225bbb3";a:8:{s:4:"user";a:5:{s:2:"id";s:10:"moluwasanu";s:4:"name";s:18:"Mojisola Oluwasanu";s:4:"mail";s:15:"ope3m@yahoo.com";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:2:{s:7:"created";i:1535109195;s:8:"modified";i:1535109467;}s:3:"raw";s:8078:"Oluwasanu- Assignment #1a

SPECIFIC AIMS
Breast cancer is the most common cancer in women and the leading cause of cancer-related deaths in Nigeria [1,2]. In Nigeria, it is a catastrophic illness characterized by late presentation and low survival which is attributed to poor breast cancer awareness and screening, inadequate knowledge on the clinical features of breast cancer coupled with fear of treatment and the stigma associated with the disease [3,4]. Though the incidence of breast cancer is higher in developed countries, there has been improved outcomes largely due to the implementation of widespread health promotion interventions [5,6,7].Specifically, community-based, group education delivered by lay persons and the use of culturally sensitive educational materials have been found to increase breast awareness, breast cancer knowledge, risk perception and screening practices in several countries [5,8,9]. 

The national response for the prevention of breast cancer in Nigeria is in its infancy with little done on community-led, health promotion interventions [2,4]. Factors contributing to this include the poor understanding of the potential of cancer prevention programmes coupled with low political priority and investment in breast cancer prevention in the face of other competing health needs [10,11]. The 2018-2022 Nigeria National Cancer Control Plan emphasizes the importance of community involvement and empowerment for national breast cancer control efforts. Furthermore, it identified the need to leverage on existing HIV community-level prevention platforms for cancer prevention and control. HIV prevention and management programmes in Nigeria have been vertical however, in view of the economic climate, it is imperative to maximize resources using feasible, effective and low-cost interventions to address both HIV and breast cancer targeting the same population. An integrated primary prevention approach leveraging previously established HIV prevention strategies and programmes at community levels have the potential to improve preventive behaviours, increase breast awareness, knowledge of the risk factors and utilization of screening services for both HIV and breast cancer inclusive [12,13]. Pilot studies are ongoing to assess the feasibility of integrated HIV and NCDs studies for people living with HIV however; the utilization of this approach for the general population has not been tested and the evidence-base for its effectiveness is limited [13]. 

The objective of this 2-year study is to utilise a hybrid effectiveness/implementation trial, type II design to investigate the effect of a community-based initiative that adopts the Combination Prevention Approach for the delivery of integrated HIV and breast cancer risk reduction information and its outcome on modifying behaviours and use of screening services among female population in the informal work sector in Ibadan, Nigeria. The government of Nigeria has adopted an intervention approach called the “Minimum Prevention Package Intervention (MPPI)” for increasing HIV prevention information and screening among the general population. Internationally, the MPPI is also known as “Combination Prevention” and it is an evidence-based approach which utilizes structured behavioural, bio-medical and structural interventions to reduce HIV risk behaviours, stigmatization and increase HIV testing [14]. This intervention has contributed to decreasing and stabilising the prevalence of HIV in several countries [15]. Furthermore, considering the similarities in the prevention and control of HIV infection and breast cancer—specifically promotion of healthy behaviors and screening practices—the models, tools, and approaches developed in the implementation of HIV programs could be adapted to address breast cancer. The intervention and measures will be guided by the Health Belief Model and the RE-AIM framework will be used to evaluate its impact. I will test the hypothesis that an integrated HIV and Breast cancer intervention premised on the Combination Prevention Approach can decrease breast cancer risk behaviours and improve utilization of screening services. The specific aims of the study are:

Aim 1. To determine the effectiveness of a combination prevention model using a cluster randomized trial for the delivery of lifestyle modification information and its outcome on HIV and breast cancer risk behaviours as well as utilization of screening services for HIV and breast cancer among 500 females. This will comprise female artisans in two urban local government areas (LGAs) in Ibadan These are workers in the informal sector who have strong organizational structures/associations and contribute over half of Nigeria’s Gross Domestic Product. The women are socio-economically disadvantaged, poorly educated and underserved because they are not integrated into government’s national health insurance scheme. Furthermore, a systematic review of breast cancer knowledge in Nigeria found that they have poor knowledge on various breast cancer knowledge subthemes and screening practices (Agodirin, 2017). We will cluster randomize 22 artisan groups into the intervention group (integrated 4-months HIV and breast cancer risk reduction intervention) and control group (observation only) with measurement at baseline, post intervention and 12 months using a mixed methods approach for data collection (semi-structured questionnaires, observation with the use of checklist and interviews). 

Hypothesis 1: The delivery of an integrated 4 months HIV and breast cancer risk reduction intervention, using the combination prevention approach will increase knowledge, adoption of risk reduction behaviours and utilization of screening services among 500 females (250 each for the intervention and control groups) in the informal work sector in two urban LGAs in Oyo State, Nigeria.
Key outcome measures include knowledge of HIV and breast cancer risk factors and preventive actions, perceived severity, susceptibility, benefits, barriers, cue to action and adoption of risk reduction behaviours, utilization of screening services. Other physical measures (Body mass index and waist- to- hip ratio).

Aim 2: To evaluate the feasibility and impact of the integrated HIV and breast cancer prevention model delivered by 50 trained artisans/peer influencers in two urban LGAs. 

Hypothesis 1: Trained artisans can be trained to provide information and referral for HIV and age-appropriate breast cancer screening services at designated primary and secondary health facilities which offer clinical breast examination and donor/private sector subsidized mammography. 

Hypothesis 2: The delivery of an integrated HIV and breast cancer risk reduction intervention at community levels using the combination prevention approach is appropriate, acceptable and feasible for the prevention, early detection and screening of breast cancer. 

Key outcome measures include: number of artisans trained as peer influencers/leaders to provide information and referral services for HIV and breast cancer screening, proportion of female artisans who participate and complete the four months- intervention, proportion of female artisans provided with integrated HIV and breast cancer information, proportion of female artisans who were referred and screened for HIV and breast cancer, number of artisan groups which adopt the integrated HIV and breast cancer prevention programme, proportion of trained artisans/peer influencer who continue to provide services 12 months post intervention. 

This approach is novel and will promote a shift from vertical to integrated programming for HIV, and breast cancer prevention programmes at community levels with a potential to expand coverage and reduce missed opportunities for the prevention and early detection of these diseases. The proposed study is apt and timely, due to the urgent need to identify ways to leverage investments in communicable diseases to address the rising epidemic of breast cancer and other NCDs in Nigeria.
";s:5:"xhtml";s:8187:"Oluwasanu- Assignment #1a<br /><br />SPECIFIC AIMS<br />Breast cancer is the most common cancer in women and the leading cause of cancer-related deaths in Nigeria [1,2]. In Nigeria, it is a catastrophic illness characterized by late presentation and low survival which is attributed to poor breast cancer awareness and screening, inadequate knowledge on the clinical features of breast cancer coupled with fear of treatment and the stigma associated with the disease [3,4]. Though the incidence of breast cancer is higher in developed countries, there has been improved outcomes largely due to the implementation of widespread health promotion interventions [5,6,7].Specifically, community-based, group education delivered by lay persons and the use of culturally sensitive educational materials have been found to increase breast awareness, breast cancer knowledge, risk perception and screening practices in several countries [5,8,9]. <br /><br />The national response for the prevention of breast cancer in Nigeria is in its infancy with little done on community-led, health promotion interventions [2,4]. Factors contributing to this include the poor understanding of the potential of cancer prevention programmes coupled with low political priority and investment in breast cancer prevention in the face of other competing health needs [10,11]. The 2018-2022 Nigeria National Cancer Control Plan emphasizes the importance of community involvement and empowerment for national breast cancer control efforts. Furthermore, it identified the need to leverage on existing HIV community-level prevention platforms for cancer prevention and control. HIV prevention and management programmes in Nigeria have been vertical however, in view of the economic climate, it is imperative to maximize resources using feasible, effective and low-cost interventions to address both HIV and breast cancer targeting the same population. An integrated primary prevention approach leveraging previously established HIV prevention strategies and programmes at community levels have the potential to improve preventive behaviours, increase breast awareness, knowledge of the risk factors and utilization of screening services for both HIV and breast cancer inclusive [12,13]. Pilot studies are ongoing to assess the feasibility of integrated HIV and NCDs studies for people living with HIV however; the utilization of this approach for the general population has not been tested and the evidence-base for its effectiveness is limited [13]. <br /><br />The objective of this 2-year study is to utilise a hybrid effectiveness/implementation trial, type II design to investigate the effect of a community-based initiative that adopts the Combination Prevention Approach for the delivery of integrated HIV and breast cancer risk reduction information and its outcome on modifying behaviours and use of screening services among female population in the informal work sector in Ibadan, Nigeria. The government of Nigeria has adopted an intervention approach called the “Minimum Prevention Package Intervention (MPPI)” for increasing HIV prevention information and screening among the general population. Internationally, the MPPI is also known as “Combination Prevention” and it is an evidence-based approach which utilizes structured behavioural, bio-medical and structural interventions to reduce HIV risk behaviours, stigmatization and increase HIV testing [14]. This intervention has contributed to decreasing and stabilising the prevalence of HIV in several countries [15]. Furthermore, considering the similarities in the prevention and control of HIV infection and breast cancer—specifically promotion of healthy behaviors and screening practices—the models, tools, and approaches developed in the implementation of HIV programs could be adapted to address breast cancer. The intervention and measures will be guided by the Health Belief Model and the RE-AIM framework will be used to evaluate its impact. I will test the hypothesis that an integrated HIV and Breast cancer intervention premised on the Combination Prevention Approach can decrease breast cancer risk behaviours and improve utilization of screening services. The specific aims of the study are:<br /><br />Aim 1. To determine the effectiveness of a combination prevention model using a cluster randomized trial for the delivery of lifestyle modification information and its outcome on HIV and breast cancer risk behaviours as well as utilization of screening services for HIV and breast cancer among 500 females. This will comprise female artisans in two urban local government areas (LGAs) in Ibadan These are workers in the informal sector who have strong organizational structures/associations and contribute over half of Nigeria’s Gross Domestic Product. The women are socio-economically disadvantaged, poorly educated and underserved because they are not integrated into government’s national health insurance scheme. Furthermore, a systematic review of breast cancer knowledge in Nigeria found that they have poor knowledge on various breast cancer knowledge subthemes and screening practices (Agodirin, 2017). We will cluster randomize 22 artisan groups into the intervention group (integrated 4-months HIV and breast cancer risk reduction intervention) and control group (observation only) with measurement at baseline, post intervention and 12 months using a mixed methods approach for data collection (semi-structured questionnaires, observation with the use of checklist and interviews). <br /><br />Hypothesis 1: The delivery of an integrated 4 months HIV and breast cancer risk reduction intervention, using the combination prevention approach will increase knowledge, adoption of risk reduction behaviours and utilization of screening services among 500 females (250 each for the intervention and control groups) in the informal work sector in two urban LGAs in Oyo State, Nigeria.<br />Key outcome measures include knowledge of HIV and breast cancer risk factors and preventive actions, perceived severity, susceptibility, benefits, barriers, cue to action and adoption of risk reduction behaviours, utilization of screening services. Other physical measures (Body mass index and waist- to- hip ratio).<br /><br />Aim 2: To evaluate the feasibility and impact of the integrated HIV and breast cancer prevention model delivered by 50 trained artisans/peer influencers in two urban LGAs. <br /><br />Hypothesis 1: Trained artisans can be trained to provide information and referral for HIV and age-appropriate breast cancer screening services at designated primary and secondary health facilities which offer clinical breast examination and donor/private sector subsidized mammography. <br /><br />Hypothesis 2: The delivery of an integrated HIV and breast cancer risk reduction intervention at community levels using the combination prevention approach is appropriate, acceptable and feasible for the prevention, early detection and screening of breast cancer. <br /><br />Key outcome measures include: number of artisans trained as peer influencers/leaders to provide information and referral services for HIV and breast cancer screening, proportion of female artisans who participate and complete the four months- intervention, proportion of female artisans provided with integrated HIV and breast cancer information, proportion of female artisans who were referred and screened for HIV and breast cancer, number of artisan groups which adopt the integrated HIV and breast cancer prevention programme, proportion of trained artisans/peer influencer who continue to provide services 12 months post intervention. <br /><br />This approach is novel and will promote a shift from vertical to integrated programming for HIV, and breast cancer prevention programmes at community levels with a potential to expand coverage and reduce missed opportunities for the prevention and early detection of these diseases. The proposed study is apt and timely, due to the urgent need to identify ways to leverage investments in communicable diseases to address the rising epidemic of breast cancer and other NCDs in Nigeria.";s:6:"parent";N;s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"d74a60d134cb36ac8c3c755e5225bbb3";}s:32:"766a61ec4c9064968e79ae092faeabd5";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"wnorton";s:4:"name";s:12:"Wynne Norton";s:4:"mail";s:20:"wynne.norton@nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1535124244;}s:3:"raw";s:1695:"Very interesting project! Sounds like a great opportunity to conduct rigorous research while also having an impact on the community. 
Just a couple of general comments to consider as you move through the course, and perhaps some ideas to think through during some of the lectures and readings:
--Your study sounds like a better fit for a hybrid type 1 design, where your primary aim is to assess the effectiveness of the intervention while collecting data on the implementation process. The lecture on methods will help you decide what type of hybrid is most appropriate given the objectives of your study. 
--What type of training will the artisans receive for delivering the intervention? Opportunity to think about developing an effective yet sustainable training model for future use and scale-up.
--I would strongly encourage you to consider other health behavior models to inform your behavior change intervention and selection of process and outcome measures at the patient level. The Health Behavior Model is generally seen as dated and studies have even demonstrated it to be a poor fit for understanding or changing health behavior. Consider using a different, more robust and validated modes of behavior change (e.g., Theory of Reasoned Action, Theory of Planned Behavior). Your use of RE-AIM for evaluation is good. 
--Does your proposed intervention include more than provision of information about prevention and screening? Would be good to include multiple components that address not only information deficits but motivation, self-efficacy, etc. constructs to effectively change behavior. 
Look forward to learning more about your proposed study over the course of this training!";s:5:"xhtml";s:1725:"Very interesting project! Sounds like a great opportunity to conduct rigorous research while also having an impact on the community. <br />Just a couple of general comments to consider as you move through the course, and perhaps some ideas to think through during some of the lectures and readings:<br />--Your study sounds like a better fit for a hybrid type 1 design, where your primary aim is to assess the effectiveness of the intervention while collecting data on the implementation process. The lecture on methods will help you decide what type of hybrid is most appropriate given the objectives of your study. <br />--What type of training will the artisans receive for delivering the intervention? Opportunity to think about developing an effective yet sustainable training model for future use and scale-up.<br />--I would strongly encourage you to consider other health behavior models to inform your behavior change intervention and selection of process and outcome measures at the patient level. The Health Behavior Model is generally seen as dated and studies have even demonstrated it to be a poor fit for understanding or changing health behavior. Consider using a different, more robust and validated modes of behavior change (e.g., Theory of Reasoned Action, Theory of Planned Behavior). Your use of RE-AIM for evaluation is good. <br />--Does your proposed intervention include more than provision of information about prevention and screening? Would be good to include multiple components that address not only information deficits but motivation, self-efficacy, etc. constructs to effectively change behavior. <br />Look forward to learning more about your proposed study over the course of this training!";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"8499f0cb4f6dec804bdbe8b4026a1aef";}s:4:"show";b:1;s:3:"cid";s:32:"766a61ec4c9064968e79ae092faeabd5";}s:32:"85a6cf00af34e0b436e08ad03d0b6a28";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"lpace";s:4:"name";s:10:"Lydia Pace";s:4:"mail";s:21:"LPACE@BWH.HARVARD.EDU";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1535124275;}s:3:"raw";s:9190:"Pace- Assignment #1a
Draft a specific aims page.
My response to that is:

Background 
The burden of breast cancer is rising in low- and middle-income countries (LMICs),1,2 including in sub-Saharan Africa, where the majority of patients present with late-stage disease, and outcomes are poor.3-5 There is pressing need to develop effective and feasible strategies to promote earlier diagnosis and treatment of breast cancer in such settings,5 where population-based mammography screening is not yet financially feasible. Preliminary data from some studies in India suggest that screening strategies based on clinical breast exam (CBE) can reduce stage of diagnosis in LMICs,6,7 though a study from the Philippines raised concerns about screening CBE accuracy and rates of follow-up of abnormal exams.8 An impact of CBE screening on mortality has not yet been demonstrated. 

In light of uncertainty around the benefit of screening asymptomatic women, and the substantial resources involved, many experts recommend adopting a phased implementation approach to early detection in LMICs with an initial focus on facilitating earlier clinical diagnosis of symptomatic women through CBE,3,9 before launching any population-based screening programs. Data from high-income settings suggest that reducing the interval between the onset of symptoms and breast cancer diagnosis can improve survival,10 and longer delays have been associated with later-stage disease in SSA.11 An approach targeting symptomatic women might increase the positive predictive value of CBE, enhance the feasibility for health providers and systems, and direct resources to women who will benefit the most.

However, few studies exist to identify the most feasible and effective strategies to deliver CBE-based early detection or screening services in rural, limited resource settings. Challenges face by such health care systems include health care workers with limited training and high rates of turnover, understaffing and competing clinical priorities, limited community breast cancer awareness, and nascent or fragmented referral pathways for patients with breast concerns. No studies have analyzed in detail the health system facilitators that make early detection or screening programs possible in an LMIC, or analyzed the impact of such programs on health service delivery.

In partnership with the Ministry of Health (MOH) and the non-governmental organization Partners In Health, from 2015-2017 we implemented a pilot early detection intervention in Burera District, a rural district in northwestern Rwanda where Rwanda’s first public cancer facility, Butaro Cancer Center of Excellence (BCCOE), is located. Our intervention entailed training of health care workers at the community, health center, and hospital levels, and establishment of regular breast clinics and referral pathways for patients with breast concerns. We randomized 12 of the district’s 19 health centers to receive the trainings and compared patient volume, service delivery and outcomes in intervention versus control sectors. Our training led to statistically significant improvements in knowledge and skills among community health workers (CHWs) and nurses.12 Preliminary analyses suggest that it has increased the number of patients receiving care for breast concerns, and exploratory analyses of patient outcomes demonstrated a non-significant increase in incidence of earlier stage breast cancer in intervention health centers’ catchment areas.13 The MOH has asked us to collaborate in expanding this intervention to 2 other districts. The MOH has chosen to adopt an approach that includes training for health center and district hospital clinicians to provide opportunistic screening of any woman who requests a breast exam and all women eligible for cervical cancer screening, as well as evaluation of symptomatic women. We are also engaging a patient navigator to support patients referred by the district hospitals to tertiary referral centers for suspected cancer. The goals of this project are to understand the impact of this scale-up on both patients and the health care system. Implementation science will be critical to understand barriers and facilitators of this approach in a “real-world” context and extract lessons for further expansion in the future.
Specific aims

Aim 1. Assess the feasibility and sustainability of the breast cancer screening program scale-up by determining its impact on patient volume and services provided at the health center and district hospital levels, and investigating providers’ knowledge and comfort with breast health and perceptions of barriers to and facilitators of the program.

We will utilize routinely collected data from health center and district hospital registries, as well as data collection forms specifically designed for the early detection scale-up, to identify patient volume and services received. We will utilize our pre- and post-training knowledge evaluation forms to assess trainee knowledge and comfort, and will conduct focus groups to evaluate provider perceptions of the program.

Aim 2. Describe cancer detection rates among patients referred by participating health centers assess false positive rates and positive predictive value of CBE performed at the health center level.

We will utilize routinely collected district hospital data, as well as pathologic diagnosis information gathered by the patient navigator, to identify the proportion of patients referred from health centers for positive CBE who are ultimately diagnosed with cancer.

Aim 3. Examine rates of follow up and time to definitive diagnosis among women referred to other facilities by health centers and district hospitals.

We will utilize health center data to identify the proportion of patients who have positive CBEs at health centers and are referred to the district hospital but do not go, and the proportion who receive a definitive diagnosis. We will also assess the proportion of patients referred to tertiary facilities who receive a definitive diagnosis and the proportion lost to follow up.

Importance
This study will advance understanding of the feasibility of breast cancer early detection efforts in a rural limited-resource setting and help guide Rwanda and other low-income countries in planning future breast control efforts. In addition, it will lay the foundation for future work to compare early diagnosis programs targeting symptomatic women to programs focused on asymptomatic women. 

References
1.	Ferlay J, Soerjomataram I, Dikshit R, et al. Cancer incidence and mortality worldwide: sources, methods and major patterns in GLOBOCAN 2012. Int J Cancer. 2015;136(5):E359-386.
2.	Bray F, Jemal A, Grey N, Ferlay J, Forman D. Global cancer transitions according to the Human Development Index (2008-2030): a population-based study. Lancet Oncol. 2012;13(8):790-801.
3.	Yip CH, Smith RA, Anderson BO, et al. Guideline implementation for breast healthcare in low- and middle-income countries: early detection resource allocation. Cancer. 2008;113(8 Suppl):2244-2256.
4.	Pace LE, Shulman LN. Breast Cancer in Sub-Saharan Africa: Challenges and Opportunities to Reduce Mortality. Oncologist. 2016;21(6):739-744.
5.	Jedy-Agba E, McCormack V, Adebamowo C, dos-Santos-Silva I. Stage at diagnosis of breast cancer in sub-Saharan Africa: a systematic review and meta-analysis. The Lancet Global Health. 2016;4(12):e923-e935.
6.	Sankaranarayanan R, Ramadas K, Thara S, et al. Clinical breast examination: preliminary results from a cluster randomized controlled trial in India. J Natl Cancer Inst. 2011;103(19):1476-1480.
7.	Mittra I, Mishra GA, Singh S, et al. A cluster randomized, controlled trial of breast and cervix cancer screening in Mumbai, India: methodology and interim results after three rounds of screening. Int J Cancer. 2010;126(4):976-984.
8.	Pisani P, Parkin DM, Ngelangel C, et al. Outcome of screening by clinical examination of the breast in a trial in the Philippines. Int J Cancer. 2006;118(1):149-154.
9.	Gelband H, Sankaranarayanan R, Gauvreau CL, et al. Costs, affordability, and feasibility of an essential package of cancer control interventions in low-income and middle-income countries: key messages from Disease Control Priorities, 3rd edition. Lancet. 2015.
10.	Richards MA, Smith P, Ramirez AJ, Fentiman IS, Rubens RD. The influence on survival of delay in the presentation and treatment of symptomatic breast cancer. Br J Cancer. 1999;79(5-6):858-864.
11.	Pace LE, Mpunga T, Hategekimana V, et al. Delays in Breast Cancer Presentation and Diagnosis at Two Rural Cancer Referral Centers in Rwanda. Oncologist. 2015;20(7):780-788.
12.	Pace LE, Dusengimana J-MV, Keating NL, et al. Impact of Breast Cancer Early Detection Training on Rwandan Health Workers’ Knowledge and Skills. Journal of Global Oncology. 2018(4):1-10.
13.	Pace L, Keating N, Dusengimana J, et al. Promoting early detection of breast cancer in rural Rwanda: impact of a community health worker and health center nurse training program. Poster presented at the African Organization for Research and Training in Cancer meeting; 2017; Kigali, Rwanda, November 2017.
";s:5:"xhtml";s:9399:"Pace- Assignment #1a<br />Draft a specific aims page.<br />My response to that is:<br /><br />Background <br />The burden of breast cancer is rising in low- and middle-income countries (LMICs),1,2 including in sub-Saharan Africa, where the majority of patients present with late-stage disease, and outcomes are poor.3-5 There is pressing need to develop effective and feasible strategies to promote earlier diagnosis and treatment of breast cancer in such settings,5 where population-based mammography screening is not yet financially feasible. Preliminary data from some studies in India suggest that screening strategies based on clinical breast exam (CBE) can reduce stage of diagnosis in LMICs,6,7 though a study from the Philippines raised concerns about screening CBE accuracy and rates of follow-up of abnormal exams.8 An impact of CBE screening on mortality has not yet been demonstrated. <br /><br />In light of uncertainty around the benefit of screening asymptomatic women, and the substantial resources involved, many experts recommend adopting a phased implementation approach to early detection in LMICs with an initial focus on facilitating earlier clinical diagnosis of symptomatic women through CBE,3,9 before launching any population-based screening programs. Data from high-income settings suggest that reducing the interval between the onset of symptoms and breast cancer diagnosis can improve survival,10 and longer delays have been associated with later-stage disease in SSA.11 An approach targeting symptomatic women might increase the positive predictive value of CBE, enhance the feasibility for health providers and systems, and direct resources to women who will benefit the most.<br /><br />However, few studies exist to identify the most feasible and effective strategies to deliver CBE-based early detection or screening services in rural, limited resource settings. Challenges face by such health care systems include health care workers with limited training and high rates of turnover, understaffing and competing clinical priorities, limited community breast cancer awareness, and nascent or fragmented referral pathways for patients with breast concerns. No studies have analyzed in detail the health system facilitators that make early detection or screening programs possible in an LMIC, or analyzed the impact of such programs on health service delivery.<br /><br />In partnership with the Ministry of Health (MOH) and the non-governmental organization Partners In Health, from 2015-2017 we implemented a pilot early detection intervention in Burera District, a rural district in northwestern Rwanda where Rwanda’s first public cancer facility, Butaro Cancer Center of Excellence (BCCOE), is located. Our intervention entailed training of health care workers at the community, health center, and hospital levels, and establishment of regular breast clinics and referral pathways for patients with breast concerns. We randomized 12 of the district’s 19 health centers to receive the trainings and compared patient volume, service delivery and outcomes in intervention versus control sectors. Our training led to statistically significant improvements in knowledge and skills among community health workers (CHWs) and nurses.12 Preliminary analyses suggest that it has increased the number of patients receiving care for breast concerns, and exploratory analyses of patient outcomes demonstrated a non-significant increase in incidence of earlier stage breast cancer in intervention health centers’ catchment areas.13 The MOH has asked us to collaborate in expanding this intervention to 2 other districts. The MOH has chosen to adopt an approach that includes training for health center and district hospital clinicians to provide opportunistic screening of any woman who requests a breast exam and all women eligible for cervical cancer screening, as well as evaluation of symptomatic women. We are also engaging a patient navigator to support patients referred by the district hospitals to tertiary referral centers for suspected cancer. The goals of this project are to understand the impact of this scale-up on both patients and the health care system. Implementation science will be critical to understand barriers and facilitators of this approach in a “real-world” context and extract lessons for further expansion in the future.<br />Specific aims<br /><br />Aim 1. Assess the feasibility and sustainability of the breast cancer screening program scale-up by determining its impact on patient volume and services provided at the health center and district hospital levels, and investigating providers’ knowledge and comfort with breast health and perceptions of barriers to and facilitators of the program.<br /><br />We will utilize routinely collected data from health center and district hospital registries, as well as data collection forms specifically designed for the early detection scale-up, to identify patient volume and services received. We will utilize our pre- and post-training knowledge evaluation forms to assess trainee knowledge and comfort, and will conduct focus groups to evaluate provider perceptions of the program.<br /><br />Aim 2. Describe cancer detection rates among patients referred by participating health centers assess false positive rates and positive predictive value of CBE performed at the health center level.<br /><br />We will utilize routinely collected district hospital data, as well as pathologic diagnosis information gathered by the patient navigator, to identify the proportion of patients referred from health centers for positive CBE who are ultimately diagnosed with cancer.<br /><br />Aim 3. Examine rates of follow up and time to definitive diagnosis among women referred to other facilities by health centers and district hospitals.<br /><br />We will utilize health center data to identify the proportion of patients who have positive CBEs at health centers and are referred to the district hospital but do not go, and the proportion who receive a definitive diagnosis. We will also assess the proportion of patients referred to tertiary facilities who receive a definitive diagnosis and the proportion lost to follow up.<br /><br />Importance<br />This study will advance understanding of the feasibility of breast cancer early detection efforts in a rural limited-resource setting and help guide Rwanda and other low-income countries in planning future breast control efforts. In addition, it will lay the foundation for future work to compare early diagnosis programs targeting symptomatic women to programs focused on asymptomatic women. <br /><br />References<br />1.	Ferlay J, Soerjomataram I, Dikshit R, et al. Cancer incidence and mortality worldwide: sources, methods and major patterns in GLOBOCAN 2012. Int J Cancer. 2015;136(5):E359-386.<br />2.	Bray F, Jemal A, Grey N, Ferlay J, Forman D. Global cancer transitions according to the Human Development Index (2008-2030): a population-based study. Lancet Oncol. 2012;13(8):790-801.<br />3.	Yip CH, Smith RA, Anderson BO, et al. Guideline implementation for breast healthcare in low- and middle-income countries: early detection resource allocation. Cancer. 2008;113(8 Suppl):2244-2256.<br />4.	Pace LE, Shulman LN. Breast Cancer in Sub-Saharan Africa: Challenges and Opportunities to Reduce Mortality. Oncologist. 2016;21(6):739-744.<br />5.	Jedy-Agba E, McCormack V, Adebamowo C, dos-Santos-Silva I. Stage at diagnosis of breast cancer in sub-Saharan Africa: a systematic review and meta-analysis. The Lancet Global Health. 2016;4(12):e923-e935.<br />6.	Sankaranarayanan R, Ramadas K, Thara S, et al. Clinical breast examination: preliminary results from a cluster randomized controlled trial in India. J Natl Cancer Inst. 2011;103(19):1476-1480.<br />7.	Mittra I, Mishra GA, Singh S, et al. A cluster randomized, controlled trial of breast and cervix cancer screening in Mumbai, India: methodology and interim results after three rounds of screening. Int J Cancer. 2010;126(4):976-984.<br />8.	Pisani P, Parkin DM, Ngelangel C, et al. Outcome of screening by clinical examination of the breast in a trial in the Philippines. Int J Cancer. 2006;118(1):149-154.<br />9.	Gelband H, Sankaranarayanan R, Gauvreau CL, et al. Costs, affordability, and feasibility of an essential package of cancer control interventions in low-income and middle-income countries: key messages from Disease Control Priorities, 3rd edition. Lancet. 2015.<br />10.	Richards MA, Smith P, Ramirez AJ, Fentiman IS, Rubens RD. The influence on survival of delay in the presentation and treatment of symptomatic breast cancer. Br J Cancer. 1999;79(5-6):858-864.<br />11.	Pace LE, Mpunga T, Hategekimana V, et al. Delays in Breast Cancer Presentation and Diagnosis at Two Rural Cancer Referral Centers in Rwanda. Oncologist. 2015;20(7):780-788.<br />12.	Pace LE, Dusengimana J-MV, Keating NL, et al. Impact of Breast Cancer Early Detection Training on Rwandan Health Workers’ Knowledge and Skills. Journal of Global Oncology. 2018(4):1-10.<br />13.	Pace L, Keating N, Dusengimana J, et al. Promoting early detection of breast cancer in rural Rwanda: impact of a community health worker and health center nurse training program. Poster presented at the African Organization for Research and Training in Cancer meeting; 2017; Kigali, Rwanda, November 2017.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"0cbf3b3b3f56df94dfee4eb5dfc207ea";}s:4:"show";b:1;s:3:"cid";s:32:"85a6cf00af34e0b436e08ad03d0b6a28";}s:32:"25aae1b5d90cf58b1fbdee26a2e60c2b";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"wnorton";s:4:"name";s:12:"Wynne Norton";s:4:"mail";s:20:"wynne.norton@nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1535125817;}s:3:"raw";s:1048:"Sounds good! Nice opportunity to work with VISNs and address a critical gap in care delivery. 
A few comments/suggestions:
--The nurse-led phone-based intervention sounds like a great fit for increasing use of palliative care services while also reducing travel burden and eliminating the need for specialty consultation visit. Are nurses able to bill for this service (with implications for sustainability)? If they are paid from the grant to provide the palliative care service, you are more in the intervention 'efficacy' stage vs. 'effectiveness.' I'm assuming it's within their scope of work? Is there a stepped approach for patients who might need more intense or frequent palliative care that can or should be delivered in-person vs. phone?
--Consider assessing implementation outcomes (more in measurement/outcomes lecture) if you are testing strategies. 
--How many VISNs will receive the implementation strategy/strategies? Four seems low but depends on your study design--perhaps you are using a pre-post only? 
Overall, looks very good!";s:5:"xhtml";s:1103:"Sounds good! Nice opportunity to work with VISNs and address a critical gap in care delivery. <br />A few comments/suggestions:<br />--The nurse-led phone-based intervention sounds like a great fit for increasing use of palliative care services while also reducing travel burden and eliminating the need for specialty consultation visit. Are nurses able to bill for this service (with implications for sustainability)? If they are paid from the grant to provide the palliative care service, you are more in the intervention &#039;efficacy&#039; stage vs. &#039;effectiveness.&#039; I&#039;m assuming it&#039;s within their scope of work? Is there a stepped approach for patients who might need more intense or frequent palliative care that can or should be delivered in-person vs. phone?<br />--Consider assessing implementation outcomes (more in measurement/outcomes lecture) if you are testing strategies. <br />--How many VISNs will receive the implementation strategy/strategies? Four seems low but depends on your study design--perhaps you are using a pre-post only? <br />Overall, looks very good!";s:6:"parent";s:32:"268faf1f2f3e0c805e52e2868f86216a";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"25aae1b5d90cf58b1fbdee26a2e60c2b";}s:32:"fb23a554dd1c68396a9eceb74dd89ca8";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"wnorton";s:4:"name";s:12:"Wynne Norton";s:4:"mail";s:20:"wynne.norton@nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1535130770;}s:3:"raw";s:1581:"Good! Very thorough description and compelling argument for addressing this topic. 
A few comments/suggestions:
--The R21 PAR is now PAR-18-017, just FYI. It was reissued to indicate the 'clinical trials optional' designation. Link to PAR here: https://grants.nih.gov/grants/guide/pa-files/PAR-18-017.html
--I'm a little bit confused. It seems that you are arguing for a systematic way to identify cancer pts who could benefit from PC, and one way to do this is through CDS and ML techniques. But you also note that adoption of CDS tools is suboptimal, with nearly 96% of recommendations ignored by providers (I'm assuming this refers to recommendations made by CDS?). So, I think you need to make a strong argument for why the proposed CDS tool with ML is better that other CDS tools in other health areas, and therefore more likely to be used once you build it based on characteristics of x, y, and z. I think it would be hard for reviewers to understand why you'd be building another CDS tool (even if it's novel with ML) if CDS tools aren't generally adopted. Or, need to make argument that you are building it with end-user in mind (unlike other tools), and that it has different features that make it more likely to be adopted and appropriated used, and that you will test different implementation strategies to increase adoption and use in future studies. I would treat the CDS tool as the 'intervention' that you are seeking to implement vs. the CDS tool as the implementation strategy, since CDS tools alone are not used often (per the point above). Does this make sense? ";s:5:"xhtml";s:1640:"Good! Very thorough description and compelling argument for addressing this topic. <br />A few comments/suggestions:<br />--The R21 PAR is now PAR-18-017, just FYI. It was reissued to indicate the &#039;clinical trials optional&#039; designation. Link to PAR here: https://grants.nih.gov/grants/guide/pa-files/PAR-18-017.html<br />--I&#039;m a little bit confused. It seems that you are arguing for a systematic way to identify cancer pts who could benefit from PC, and one way to do this is through CDS and ML techniques. But you also note that adoption of CDS tools is suboptimal, with nearly 96% of recommendations ignored by providers (I&#039;m assuming this refers to recommendations made by CDS?). So, I think you need to make a strong argument for why the proposed CDS tool with ML is better that other CDS tools in other health areas, and therefore more likely to be used once you build it based on characteristics of x, y, and z. I think it would be hard for reviewers to understand why you&#039;d be building another CDS tool (even if it&#039;s novel with ML) if CDS tools aren&#039;t generally adopted. Or, need to make argument that you are building it with end-user in mind (unlike other tools), and that it has different features that make it more likely to be adopted and appropriated used, and that you will test different implementation strategies to increase adoption and use in future studies. I would treat the CDS tool as the &#039;intervention&#039; that you are seeking to implement vs. the CDS tool as the implementation strategy, since CDS tools alone are not used often (per the point above). Does this make sense?";s:6:"parent";s:32:"518a04dcb43f367baf3cf989cf607e7a";s:7:"replies";a:1:{i:0;s:32:"23300039eee4d126cd24a3abfe8cd0c9";}s:4:"show";b:1;s:3:"cid";s:32:"fb23a554dd1c68396a9eceb74dd89ca8";}s:32:"23300039eee4d126cd24a3abfe8cd0c9";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"wnorton";s:4:"name";s:12:"Wynne Norton";s:4:"mail";s:20:"wynne.norton@nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1535130848;}s:3:"raw";s:201:"...You might also consider reviewing the literature on EHR reminders and prompts. Some discussion of reminder overload and thus additional approaches may be needed to act on info provided in reminder. ";s:5:"xhtml";s:200:"...You might also consider reviewing the literature on EHR reminders and prompts. Some discussion of reminder overload and thus additional approaches may be needed to act on info provided in reminder.";s:6:"parent";s:32:"fb23a554dd1c68396a9eceb74dd89ca8";s:7:"replies";a:1:{i:0;s:32:"fefa50f552a3cce6e71f85076804145b";}s:4:"show";b:1;s:3:"cid";s:32:"23300039eee4d126cd24a3abfe8cd0c9";}s:32:"e49d84835f4358dbb9bec3651b0139ef";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"wnorton";s:4:"name";s:12:"Wynne Norton";s:4:"mail";s:20:"wynne.norton@nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:2:{s:7:"created";i:1535131649;s:8:"modified";i:1535728207;}s:3:"raw";s:1349:"Exciting project and important topic! Also sounds challenging to integrate program into community onc settings, but all the more reason to focus on this issue.
Comments/questions:
--Who opened/paid for the Exercise Medicine Unit? And who pays the salary of the exercise professional? Source of payment will have implications for sustainability within clinic and implementation in other clinics. 
--For your current study, could consider asking providers, clinic managers, and administrators what they think of the exercise medicine unit (pros/cons) and what it would take to sustain the program (cost, personnel, buy-in, competing priorities of patients and the clinic) post-study period. 
--Can you do some preliminary qualitative interviews with providers, clinic managers, and administrators at community onc clinics? This would help prepare you for how you might augment the exercise program in the future, and what strategies might be needed to facilitate implementation. 
--Do you have working, collaborative relationships with the proposed 8 community onc clinics?
--The lectures on measures and theories will help to answer some of your questions above, so good to revisit as the course progresses. 
--A hybrid type 1 might be a good fit if you are currently conducting an efficacy trial of the intervention. Just something to keep in mind. ";s:5:"xhtml";s:1383:"Exciting project and important topic! Also sounds challenging to integrate program into community onc settings, but all the more reason to focus on this issue.<br />Comments/questions:<br />--Who opened/paid for the Exercise Medicine Unit? And who pays the salary of the exercise professional? Source of payment will have implications for sustainability within clinic and implementation in other clinics. <br />--For your current study, could consider asking providers, clinic managers, and administrators what they think of the exercise medicine unit (pros/cons) and what it would take to sustain the program (cost, personnel, buy-in, competing priorities of patients and the clinic) post-study period. <br />--Can you do some preliminary qualitative interviews with providers, clinic managers, and administrators at community onc clinics? This would help prepare you for how you might augment the exercise program in the future, and what strategies might be needed to facilitate implementation. <br />--Do you have working, collaborative relationships with the proposed 8 community onc clinics?<br />--The lectures on measures and theories will help to answer some of your questions above, so good to revisit as the course progresses. <br />--A hybrid type 1 might be a good fit if you are currently conducting an efficacy trial of the intervention. Just something to keep in mind.";s:6:"parent";s:32:"055323f4e3078d397b25a124538e5173";s:7:"replies";a:1:{i:0;s:32:"e1904f5b9088f169b83340c5d65c7a85";}s:4:"show";b:1;s:3:"cid";s:32:"e49d84835f4358dbb9bec3651b0139ef";}s:32:"d2399894ebf59c5d84127371d9d96af5";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"wnorton";s:4:"name";s:12:"Wynne Norton";s:4:"mail";s:20:"wynne.norton@nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1535132855;}s:3:"raw";s:1076:"Very nice! Important topic and setting. 
A few comments:
--I agree with Gila's suggestion below. I was also expecting to see the proposed strategy (or likely strategy) to focus on the time constraints and competing demands on nurses for providing the phone-based intervention. This seems like quite a significant barrier, so would be good to get input from providers, nurses, and patients for how the program could be adapted but still effective. Maybe task-shifting, as Gila suggested, so the intervention is delivered by community health workers (if they exist) or peers? Or perhaps taking an inventory of what nurses are doing currently (time-in-motion study and/or content assessment of care provided) and see if there is a way to streamline it? 
--You might consider using a more rigorous study design, as the pre-post no control is pretty weak. 
--The lecture on measures and outcomes should help you refine your proposal to include more implementation measures and outcomes, if you are more focused on piloting or assessing implementation vs. intervention adaptations. ";s:5:"xhtml";s:1100:"Very nice! Important topic and setting. <br />A few comments:<br />--I agree with Gila&#039;s suggestion below. I was also expecting to see the proposed strategy (or likely strategy) to focus on the time constraints and competing demands on nurses for providing the phone-based intervention. This seems like quite a significant barrier, so would be good to get input from providers, nurses, and patients for how the program could be adapted but still effective. Maybe task-shifting, as Gila suggested, so the intervention is delivered by community health workers (if they exist) or peers? Or perhaps taking an inventory of what nurses are doing currently (time-in-motion study and/or content assessment of care provided) and see if there is a way to streamline it? <br />--You might consider using a more rigorous study design, as the pre-post no control is pretty weak. <br />--The lecture on measures and outcomes should help you refine your proposal to include more implementation measures and outcomes, if you are more focused on piloting or assessing implementation vs. intervention adaptations.";s:6:"parent";s:32:"b751b3e817966e08f2208079c5f3f68a";s:7:"replies";a:0:{}s:4:"show";b:0;s:3:"cid";s:32:"d2399894ebf59c5d84127371d9d96af5";}s:32:"85d50a05ef92dd0ede87f5daea878386";a:8:{s:4:"user";a:5:{s:2:"id";s:9:"aibraheem";s:4:"name";s:15:"Abiola Ibraheem";s:4:"mail";s:35:"aibraheem@medicine.bsd.uchicago.edu";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:2:{s:7:"created";i:1535160469;s:8:"modified";i:1535160693;}s:3:"raw";s:11708:"Ibraheem - Assignment #1a
My response to the questions and elements are : 

HEALTH PROBLEM: Cancer is fast becoming a common cause of death in low middle-income countries, in 2030, it has been postulated by WHO that 70% of cancer cases will be in the developing world. Over the last decade, there have been strategies to bring quality cancer care to underserved patients around the world. To bridge the cancer geographical divide and improve quality of cancer care at affordable costs, innovative approaches to implement quality cancer care must be extended to these parts of the world. 

EVIDENCED BASED INTERVENTION/GUIDELINES: To improve cancer care in the developing world, the global oncology consortium was formed over a decade ago with the goal of improving cancer care through education, capacity building and research. However, research in these parts of the world has been limited to observational research. Oncology clinical trials have traditionally been carried out in relatively wealthy locations such as North America, Western Europe and Oceania. However, in recent years, a shift in clinical trials sponsored by the biopharma industry to regions such as Eastern European, Latin American, Asian countries and South Africa has been noted. Reasons cited for this shift include the ability to reduce operational costs while recruiting a large number of patients in a timely manner, the rapid growth of market size, research capacity and regulatory authority in emerging regions. These factors will continue to be prominent drivers of the globalization of clinical trials, resulting in the solidification of trends and increased geographic dispersion of drug development operations.
West Africa, especially Nigeria has not been involved in oncology clinical trials and this may be due to lack of infrastructure, resources, medical expertise or simply the lack of incentive to Pharma. It is important to note that clinical trials in infectious diseases such as HIV/AIDS in Nigeria greatly impacted and improved care in people living with HIV and other infectious diseases. Therefore, globalization of oncology clinical trials in West Africa can lead to improvements in cancer care in the region and needs to be aggressively pursued as a strategy to increase health equity.
The global health community must take decisive action to bridge the cancer divide between wealthy and poor nations. To accelerate progress and advance global health equity, the global health team at University of Chicago has proposed an investigator initiated highly innovative clinical trial that combines highly effective hormonal therapy with a CDK4/6 inhibitor Ribociclib in hormone receptor positive breast cancer as a way to address the high risk of recurrence observed in Nigerians. Additionally, we have also been able to garner support from Pharmaceutical Companies interested in improving the quality of cancer care in Nigeria for a clinical trial for HER2 targeted therapy. This protocol entitled “Assessing the REsponse rate of neoadjuvant Taxotere and TrastuzumAb in Nigerian women with HER2-positive breast cancer (ARETTA) has received Ethics Committee approval at four sites in Nigeria under the sponsorship of the University of Chicago and the US based Breast Cancer Research Foundation. In addition to funding support, the physicians and institution enthusiastically provided basic infrastructures and manpower needed to execute this trial. 


DISSEMINATION AND IMPLEMENTATION GAP. Unfortunately, this is not the first interventional study in cancer patients. In 2007, the global health team at University of Chicago conducted a phase II feasibility open-label multicenter clinical trial of Neo-adjuvant capecitabine chemotherapy in women with newly diagnosed locally advanced breast cancer in Nigeria. There was very poor accrual as a total of 16 patients were recruited from August 2007 to April 2010 and the study was terminated as a result of slow accrual. Even though the reason for poor accrual in this study was not investigated, literature extensively reports on barriers to enrolling patients on clinical trials.
These barriers which has been well described have been grouped in a multileveled fashion namely:- (i) Provider level - time constraint, co-morbidities, poor perception about trials, (ii) Patient level - Mistrust, poor health literacy, socioeconomic status, concern of being used as guinea pig, (iii) Clinical trial system level- unnecessary exclusion criterion thereby excluding a large population of patients who may have benefitted. Due to these concerns we conducted a pilot study in one of the planned sites in Nigeria assessing the baseline perception of providers, concerning clinical trials. The concerns of most providers were
(i)	the use of patients as guinea pigs, (ii) inadequate clinic visit time to explain clinical trials to patients (iii) poor referral system and (iv) the use of clinical trial only when conventional therapy has failed. Using the lessons learned from our past and the known barriers preventing the execution of clinical trials in the Western world, we propose an intervention focused on improving knowledge, perception and attitude of Nigerian providers towards clinical trial. By enhancing providers’ understanding of trials and improving their perception and attitude towards trials, their role in informing patients about the possibility of trial participation may help to ameliorate some patient confusion and/or concern. 

IMPORTANCE TO FIELD: Previous research demonstrates that conducting outreach and education to providers can increase their capacity for referral to clinical trials; and educational programs targeted to providers have shown to increase their knowledge and positive attitudes about their role in clinical trial referrals. Therefore this pilot project has the potential of improving providers’ knowledge, perception and attitude towards cancer clinical trial. If successful, our intervention will prepare Nigeria for upcoming clinical trials and it can be modeled for other developing countries seeking to join the world in participating in clinical trials.

1.	Specific Aim #1: To  investigate  the  attitudes and  perceived  barriers of Nigerian  providers  towards enrolling patients on interventional clinical trials as they specifically relate to: (i) Assessing the baseline knowledge of Nigerian providers about interventional studies (ii) Evaluating the Nigerian providers’ attitude towards clinical trial (iii) gathering information on intention to enrolling patients on study. To accomplish this aim, I will carry out an observational study amongst providers’ using a validated survey developed at Memorial Sloan Kettering. Hypothesis 1: Nigerian physicians have low basic knowledge about randomized clinical trials and poor attitudes and perception towards randomized clinical trials.
Specific Aim #2: Using the results from Aim #1, I will conduct an intervention designed to improve providers’ knowledge about oncology randomized clinical trials and address attitudes and perceived barriers to enrolling patients on study. To accomplish this aim, (i) ground rounds impacting knowledge on randomized clinical trials will be carried out quarterly; (ii) Providers’ focused group will be carried out to ensure retention of information. Hypothesis 2: The tailored evidence-based intervention will improve knowledge, attitude and perception of providers towards clinical trial that will be measured by a post-intervention survey.
Design Overview and Stakeholders Engagement. This proposal will emulate the Community-Engaged Research method, which is a powerful vehicle for bringing about environmental and behavioral changes that will improve the health of the community and its members by involving local providers from the initiation to the execution of this proposal. I will build on my established relationship with the local providers at Lagos State University (LASUTH) who will meaningfully contribute to the proposed research by encouraging participation of all local providers to this research. Stakeholders will include leaders in the urology, family medicine, surgery, and radiation-oncology section of LASUTH. Beginning in Year 1, I will partner with stakeholders through a formal Memorandum of Understanding to formalize their role in the oversight of all study activities. Early and continuous engagement of the local providers will improve the relevance of my proposed interventions and likelihood of implementation. Stakeholders will (i) initially convene for their input towards the proposed adapted Memorial Sloan Kettering survey tool, (ii) thereafter will convene at least quarterly over the course of this award to collaboratively help design the intervention tool and (iii) ensure other providers’ attendance to proposed interventions. To evaluate the success of stakeholder engagement and ensure inclusion, I will elicit a quarterly feedback from stakeholders over the course of the award using an adapted Community Engagement Research Index (CERI)and open-ended questions to measure engagement.

A. Pre-intervention stage (Stage I, 2 months): I will identify local stakeholders representing all proposed departments at LASUTH. Upon our first meeting, I will introduce the proposed 65-item survey developed at Memorial Sloan Kettering which was developed based upon: (a) data from qualitative interviews conducted in an earlier phase of their study (b) review of the literature and previously developed instruments, (c) previously tested questionnaires by study investigators,(d) expert opinion, and (e) pilot testing with four physicians. The input of our local stakeholders to this survey will be acted upon. The newly adapted survey will be used to receive approval by the local IRB. Using the influence of our local stakeholders in addition to an incentive of 200 Naira (56cents) recharge card, I will approach local providers to respond to our survey. The survey instrument will be sent to our target participants as a link to their phones or emails, each participant will fill in their demographics including their names and an ID number will be allocated for proper identification. I will send reminders to their phones every 5 days for a maximum of 4 times.

B. The Intervention Stage: Following analysis of the observational study in Aim #1, with the involvement of the local stakeholders I will develop a one-hour presentation tailored to increase provider’s knowledge about clinical trials, address identified barriers, attitudes, and perceptions. This one-hour presentation will be given as a grand round quarterly. In addition to quarterly grand rounds, providers will be targeted in smaller groups according to their units for interactive and more personalized sessions. These sessions will be carried out every six months for one year. At six months since the commencement of intervention, two grand rounds, and one targeted session will have been conducted. We will reuse our survey for all our participants to assess for the change in knowledge, attitude, and perception of clinical trial. In addition to this survey, we will carry out a qualitative survey to assess for concerns otherwise not addressed in our survey. Using the results from mid evaluation of the providers, we will re-adapt our intervention. The adapted intervention will be implemented for the remaining 3 months through the 3rd grand round and the second targeted sessions.Subjects: Eligible requirements are all providers i.e physicians, nurses, pharmacists, lab technicians, who work in the following departments urology, general surgery, radiation oncology, family medicine, emergency room.


";s:5:"xhtml";s:11815:"Ibraheem - Assignment #1a<br />My response to the questions and elements are : <br /><br />HEALTH PROBLEM: Cancer is fast becoming a common cause of death in low middle-income countries, in 2030, it has been postulated by WHO that 70% of cancer cases will be in the developing world. Over the last decade, there have been strategies to bring quality cancer care to underserved patients around the world. To bridge the cancer geographical divide and improve quality of cancer care at affordable costs, innovative approaches to implement quality cancer care must be extended to these parts of the world. <br /><br />EVIDENCED BASED INTERVENTION/GUIDELINES: To improve cancer care in the developing world, the global oncology consortium was formed over a decade ago with the goal of improving cancer care through education, capacity building and research. However, research in these parts of the world has been limited to observational research. Oncology clinical trials have traditionally been carried out in relatively wealthy locations such as North America, Western Europe and Oceania. However, in recent years, a shift in clinical trials sponsored by the biopharma industry to regions such as Eastern European, Latin American, Asian countries and South Africa has been noted. Reasons cited for this shift include the ability to reduce operational costs while recruiting a large number of patients in a timely manner, the rapid growth of market size, research capacity and regulatory authority in emerging regions. These factors will continue to be prominent drivers of the globalization of clinical trials, resulting in the solidification of trends and increased geographic dispersion of drug development operations.<br />West Africa, especially Nigeria has not been involved in oncology clinical trials and this may be due to lack of infrastructure, resources, medical expertise or simply the lack of incentive to Pharma. It is important to note that clinical trials in infectious diseases such as HIV/AIDS in Nigeria greatly impacted and improved care in people living with HIV and other infectious diseases. Therefore, globalization of oncology clinical trials in West Africa can lead to improvements in cancer care in the region and needs to be aggressively pursued as a strategy to increase health equity.<br />The global health community must take decisive action to bridge the cancer divide between wealthy and poor nations. To accelerate progress and advance global health equity, the global health team at University of Chicago has proposed an investigator initiated highly innovative clinical trial that combines highly effective hormonal therapy with a CDK4/6 inhibitor Ribociclib in hormone receptor positive breast cancer as a way to address the high risk of recurrence observed in Nigerians. Additionally, we have also been able to garner support from Pharmaceutical Companies interested in improving the quality of cancer care in Nigeria for a clinical trial for HER2 targeted therapy. This protocol entitled “Assessing the REsponse rate of neoadjuvant Taxotere and TrastuzumAb in Nigerian women with HER2-positive breast cancer (ARETTA) has received Ethics Committee approval at four sites in Nigeria under the sponsorship of the University of Chicago and the US based Breast Cancer Research Foundation. In addition to funding support, the physicians and institution enthusiastically provided basic infrastructures and manpower needed to execute this trial. <br /><br /><br />DISSEMINATION AND IMPLEMENTATION GAP. Unfortunately, this is not the first interventional study in cancer patients. In 2007, the global health team at University of Chicago conducted a phase II feasibility open-label multicenter clinical trial of Neo-adjuvant capecitabine chemotherapy in women with newly diagnosed locally advanced breast cancer in Nigeria. There was very poor accrual as a total of 16 patients were recruited from August 2007 to April 2010 and the study was terminated as a result of slow accrual. Even though the reason for poor accrual in this study was not investigated, literature extensively reports on barriers to enrolling patients on clinical trials.<br />These barriers which has been well described have been grouped in a multileveled fashion namely:- (i) Provider level - time constraint, co-morbidities, poor perception about trials, (ii) Patient level - Mistrust, poor health literacy, socioeconomic status, concern of being used as guinea pig, (iii) Clinical trial system level- unnecessary exclusion criterion thereby excluding a large population of patients who may have benefitted. Due to these concerns we conducted a pilot study in one of the planned sites in Nigeria assessing the baseline perception of providers, concerning clinical trials. The concerns of most providers were<br />(i)	the use of patients as guinea pigs, (ii) inadequate clinic visit time to explain clinical trials to patients (iii) poor referral system and (iv) the use of clinical trial only when conventional therapy has failed. Using the lessons learned from our past and the known barriers preventing the execution of clinical trials in the Western world, we propose an intervention focused on improving knowledge, perception and attitude of Nigerian providers towards clinical trial. By enhancing providers’ understanding of trials and improving their perception and attitude towards trials, their role in informing patients about the possibility of trial participation may help to ameliorate some patient confusion and/or concern. <br /><br />IMPORTANCE TO FIELD: Previous research demonstrates that conducting outreach and education to providers can increase their capacity for referral to clinical trials; and educational programs targeted to providers have shown to increase their knowledge and positive attitudes about their role in clinical trial referrals. Therefore this pilot project has the potential of improving providers’ knowledge, perception and attitude towards cancer clinical trial. If successful, our intervention will prepare Nigeria for upcoming clinical trials and it can be modeled for other developing countries seeking to join the world in participating in clinical trials.<br /><br />1.	Specific Aim #1: To  investigate  the  attitudes and  perceived  barriers of Nigerian  providers  towards enrolling patients on interventional clinical trials as they specifically relate to: (i) Assessing the baseline knowledge of Nigerian providers about interventional studies (ii) Evaluating the Nigerian providers’ attitude towards clinical trial (iii) gathering information on intention to enrolling patients on study. To accomplish this aim, I will carry out an observational study amongst providers’ using a validated survey developed at Memorial Sloan Kettering. Hypothesis 1: Nigerian physicians have low basic knowledge about randomized clinical trials and poor attitudes and perception towards randomized clinical trials.<br />Specific Aim #2: Using the results from Aim #1, I will conduct an intervention designed to improve providers’ knowledge about oncology randomized clinical trials and address attitudes and perceived barriers to enrolling patients on study. To accomplish this aim, (i) ground rounds impacting knowledge on randomized clinical trials will be carried out quarterly; (ii) Providers’ focused group will be carried out to ensure retention of information. Hypothesis 2: The tailored evidence-based intervention will improve knowledge, attitude and perception of providers towards clinical trial that will be measured by a post-intervention survey.<br />Design Overview and Stakeholders Engagement. This proposal will emulate the Community-Engaged Research method, which is a powerful vehicle for bringing about environmental and behavioral changes that will improve the health of the community and its members by involving local providers from the initiation to the execution of this proposal. I will build on my established relationship with the local providers at Lagos State University (LASUTH) who will meaningfully contribute to the proposed research by encouraging participation of all local providers to this research. Stakeholders will include leaders in the urology, family medicine, surgery, and radiation-oncology section of LASUTH. Beginning in Year 1, I will partner with stakeholders through a formal Memorandum of Understanding to formalize their role in the oversight of all study activities. Early and continuous engagement of the local providers will improve the relevance of my proposed interventions and likelihood of implementation. Stakeholders will (i) initially convene for their input towards the proposed adapted Memorial Sloan Kettering survey tool, (ii) thereafter will convene at least quarterly over the course of this award to collaboratively help design the intervention tool and (iii) ensure other providers’ attendance to proposed interventions. To evaluate the success of stakeholder engagement and ensure inclusion, I will elicit a quarterly feedback from stakeholders over the course of the award using an adapted Community Engagement Research Index (CERI)and open-ended questions to measure engagement.<br /><br />A. Pre-intervention stage (Stage I, 2 months): I will identify local stakeholders representing all proposed departments at LASUTH. Upon our first meeting, I will introduce the proposed 65-item survey developed at Memorial Sloan Kettering which was developed based upon: (a) data from qualitative interviews conducted in an earlier phase of their study (b) review of the literature and previously developed instruments, (c) previously tested questionnaires by study investigators,(d) expert opinion, and (e) pilot testing with four physicians. The input of our local stakeholders to this survey will be acted upon. The newly adapted survey will be used to receive approval by the local IRB. Using the influence of our local stakeholders in addition to an incentive of 200 Naira (56cents) recharge card, I will approach local providers to respond to our survey. The survey instrument will be sent to our target participants as a link to their phones or emails, each participant will fill in their demographics including their names and an ID number will be allocated for proper identification. I will send reminders to their phones every 5 days for a maximum of 4 times.<br /><br />B. The Intervention Stage: Following analysis of the observational study in Aim #1, with the involvement of the local stakeholders I will develop a one-hour presentation tailored to increase provider’s knowledge about clinical trials, address identified barriers, attitudes, and perceptions. This one-hour presentation will be given as a grand round quarterly. In addition to quarterly grand rounds, providers will be targeted in smaller groups according to their units for interactive and more personalized sessions. These sessions will be carried out every six months for one year. At six months since the commencement of intervention, two grand rounds, and one targeted session will have been conducted. We will reuse our survey for all our participants to assess for the change in knowledge, attitude, and perception of clinical trial. In addition to this survey, we will carry out a qualitative survey to assess for concerns otherwise not addressed in our survey. Using the results from mid evaluation of the providers, we will re-adapt our intervention. The adapted intervention will be implemented for the remaining 3 months through the 3rd grand round and the second targeted sessions.Subjects: Eligible requirements are all providers i.e physicians, nurses, pharmacists, lab technicians, who work in the following departments urology, general surgery, radiation oncology, family medicine, emergency room.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"1df4759e1d8e582b7dae57b9c04127a3";}s:4:"show";b:1;s:3:"cid";s:32:"85d50a05ef92dd0ede87f5daea878386";}s:32:"993529b34e54e39b58e3d0aea8780653";a:8:{s:4:"user";a:5:{s:2:"id";s:8:"khuggins";s:4:"name";s:12:"Kate Huggins";s:4:"mail";s:23:"kate.huggins@monash.edu";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1535169112;}s:3:"raw";s:5574:"Huggins_Assignment 1a

Death from cancer is hastened with poor nutritional status. Between 10-20% of cancer deaths can be attributed to malnutrition rather than the cancer itself [1,2]. To maximise the benefit from cancer treatment, it is critical that we have a mechanism for moving the delivery of nutritional intervention to commence prior to the decline in nutritional status. For people with upper gastrointestinal (GI) cancer (oesophageal, stomach and pancreas) their prognosis is very poor with five-year survival of 7% for pancreatic, 16% for oesophageal and 26% for stomach cancers [3]. Weight loss is often the primary cause of concern, which drives people to seek medical advice. Prevalence of clinically significant weight loss (>10% body weight) is reported to range from 15-69% in people with these cancers [4,5]. Sustained weight loss eventually leads to malnutrition, which is a strong prognostic indicator of mortality, increased risk of post-operative morbidity and mortality, debility, compromised immunity, a higher rate of hospital readmission, a longer duration of hospital stay, and poorer quality of life [6-8]. It also has a negative impact on tolerance to withstand cancer treatment [6-9]. Not only is nutritional decline a hallmark of the disease but also a side effect of cancer treatment that results in acute or sustained declines in oral food intake [4].

We have developed a mechanism for delivering early nutrition intervention for people with cancers of the upper gastrointestinal tract. It is recognised internationally that nutrition intervention should commence at the time of diagnosis for people with cancer of the stomach, oesophagus and pancreas [10]. Tailored interventions are necessary because of the different treatment modalities, cancer type, tumour location, treatment side effects, food preferences, social circumstances and other co-morbidities these people may have [11]. Delay in treating malnutrition occurs frequently in practice because it is often unrecognised and may become established even prior to cancer diagnosis and exist within an obese phenotype [12, 13]. Moreover, current health service delivery involves face-to-face counselling with a hospital-based dietitian following medical referral at the commencement of surgical or chemo/radio therapy if the patient has been identified as being malnourished. Thus, the response to poor nutritional status is ‘reactive’ rather than planned and preventive. 

Our team of dietitians, nurse practitioners, surgeons, health services managers and University academics have been working together to develop a mechanism for the delivery of early and frequent nutrition care from the time of diagnosis to improve health outcomes for people with upper gastrointestinal cancer. Our pilot work demonstrates it is feasible to deliver early and frequent nutrition intervention, and it can have an impact on malnutrition that develops prior to the commencement of cancer treatment [14]. (Figure 1).  It is now important to develop a strategy for sustained implementation across broader settings.   

To achieve successful implementation of early and frequent nutrition care across broader settings we propose an initial study that will test the overarching hypothesis that our enhanced model of individualised nutrition care, which commences earlier and more frequently than usual, can effectively and cost-effectively improve quality of life, using novel service delivery models (synchronous tele-health and asynchronous mobile Health (mHealth)). The goal of this study is to determine what the delivery system needs to look like to 1) get practitioners and patients to engage with the service, and 2) health services to adopt a change in usual care practice to permit very early (prior to admission) and frequent nutrition care for people with upper gastrointestinal cancer. The specific aims are to: 

1)	Assess the effectiveness of early intervention using mobile Health (asynchronous) or telephone (synchronous) vs. usual care (face-to-face in hospital), to improve patient outcomes including quality of life and nutritional status.
2)	To evaluate the cost-effectiveness of using mHealth or telephone for the delivery of nutrition care compared with usual care.
3)	Examine the contextual factors and intervention characteristics to support and/or inhibit successful implementation.
4)	Develop a blue print for broader implementation across a larger number of health services.

Home-based therapies need to be more than just oral nutritional supplements however, Health Services are constrained by limited resources including practitioners’ time. Dietary advice plus nutritional supplements is the most effective way of stopping weight loss with illness-related malnutrition. Accessing community dietetics services is time consuming and often burdensome for patients who are already juggling several appointments leading up to their commencement of treatment. People need to be able to access a service that delivers patient-centred care, at home and at their demand

Summary of outcomes: 1) Improved pre-hospital nutrition care for patients with upper gastrointestinal cancer; 2) a model for the integration of mHealth into cancer supportive care; 3) a plan for broad dissemination and implementation of mHealth in cancer supportive care and recommendations of how this enhanced nutrition care may extend to treatment in other cancer types; and 4) this project will transform me from an mid-career researcher to an independent and leading Victorian health researcher.
";s:5:"xhtml";s:5661:"Huggins_Assignment 1a<br /><br />Death from cancer is hastened with poor nutritional status. Between 10-20% of cancer deaths can be attributed to malnutrition rather than the cancer itself [1,2]. To maximise the benefit from cancer treatment, it is critical that we have a mechanism for moving the delivery of nutritional intervention to commence prior to the decline in nutritional status. For people with upper gastrointestinal (GI) cancer (oesophageal, stomach and pancreas) their prognosis is very poor with five-year survival of 7% for pancreatic, 16% for oesophageal and 26% for stomach cancers [3]. Weight loss is often the primary cause of concern, which drives people to seek medical advice. Prevalence of clinically significant weight loss (&gt;10% body weight) is reported to range from 15-69% in people with these cancers [4,5]. Sustained weight loss eventually leads to malnutrition, which is a strong prognostic indicator of mortality, increased risk of post-operative morbidity and mortality, debility, compromised immunity, a higher rate of hospital readmission, a longer duration of hospital stay, and poorer quality of life [6-8]. It also has a negative impact on tolerance to withstand cancer treatment [6-9]. Not only is nutritional decline a hallmark of the disease but also a side effect of cancer treatment that results in acute or sustained declines in oral food intake [4].<br /><br />We have developed a mechanism for delivering early nutrition intervention for people with cancers of the upper gastrointestinal tract. It is recognised internationally that nutrition intervention should commence at the time of diagnosis for people with cancer of the stomach, oesophagus and pancreas [10]. Tailored interventions are necessary because of the different treatment modalities, cancer type, tumour location, treatment side effects, food preferences, social circumstances and other co-morbidities these people may have [11]. Delay in treating malnutrition occurs frequently in practice because it is often unrecognised and may become established even prior to cancer diagnosis and exist within an obese phenotype [12, 13]. Moreover, current health service delivery involves face-to-face counselling with a hospital-based dietitian following medical referral at the commencement of surgical or chemo/radio therapy if the patient has been identified as being malnourished. Thus, the response to poor nutritional status is ‘reactive’ rather than planned and preventive. <br /><br />Our team of dietitians, nurse practitioners, surgeons, health services managers and University academics have been working together to develop a mechanism for the delivery of early and frequent nutrition care from the time of diagnosis to improve health outcomes for people with upper gastrointestinal cancer. Our pilot work demonstrates it is feasible to deliver early and frequent nutrition intervention, and it can have an impact on malnutrition that develops prior to the commencement of cancer treatment [14]. (Figure 1).  It is now important to develop a strategy for sustained implementation across broader settings.   <br /><br />To achieve successful implementation of early and frequent nutrition care across broader settings we propose an initial study that will test the overarching hypothesis that our enhanced model of individualised nutrition care, which commences earlier and more frequently than usual, can effectively and cost-effectively improve quality of life, using novel service delivery models (synchronous tele-health and asynchronous mobile Health (mHealth)). The goal of this study is to determine what the delivery system needs to look like to 1) get practitioners and patients to engage with the service, and 2) health services to adopt a change in usual care practice to permit very early (prior to admission) and frequent nutrition care for people with upper gastrointestinal cancer. The specific aims are to: <br /><br />1)	Assess the effectiveness of early intervention using mobile Health (asynchronous) or telephone (synchronous) vs. usual care (face-to-face in hospital), to improve patient outcomes including quality of life and nutritional status.<br />2)	To evaluate the cost-effectiveness of using mHealth or telephone for the delivery of nutrition care compared with usual care.<br />3)	Examine the contextual factors and intervention characteristics to support and/or inhibit successful implementation.<br />4)	Develop a blue print for broader implementation across a larger number of health services.<br /><br />Home-based therapies need to be more than just oral nutritional supplements however, Health Services are constrained by limited resources including practitioners’ time. Dietary advice plus nutritional supplements is the most effective way of stopping weight loss with illness-related malnutrition. Accessing community dietetics services is time consuming and often burdensome for patients who are already juggling several appointments leading up to their commencement of treatment. People need to be able to access a service that delivers patient-centred care, at home and at their demand<br /><br />Summary of outcomes: 1) Improved pre-hospital nutrition care for patients with upper gastrointestinal cancer; 2) a model for the integration of mHealth into cancer supportive care; 3) a plan for broad dissemination and implementation of mHealth in cancer supportive care and recommendations of how this enhanced nutrition care may extend to treatment in other cancer types; and 4) this project will transform me from an mid-career researcher to an independent and leading Victorian health researcher.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"bde78ba07dfb6ea63c39109c9850742c";}s:4:"show";b:1;s:3:"cid";s:32:"993529b34e54e39b58e3d0aea8780653";}s:32:"e1904f5b9088f169b83340c5d65c7a85";a:8:{s:4:"user";a:5:{s:2:"id";s:8:"kschmitz";s:4:"name";s:15:"Kathryn Schmitz";s:4:"mail";s:20:"kschmitz@phs.psu.edu";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:2:{s:7:"created";i:1535475256;s:8:"modified";i:1535475546;}s:3:"raw";s:1483:"Hi Wynne - 
Thank you so much for the feedback!
To answer:  The EMU was paid for by my start-up, as is the exercise professional.  I seek some help with spinning this.  As *I* see it (not sure if this will fly), establishing that I can get this to work and collecting data on costs is a first step toward getting folks to pay for it.  Figuring out how to get past this is really important to me.  Exercise will NOT be paid for until we can show that implementation is possible.  If tests of implementation are impossible until we can show that it will be paid for, I'm in a loop.  Help?
We are doing the qualitative work right now - exactly as described above.  Whuhuu!  Very validating to get your feedback on this.
NO, I do not have collaborative relationships with 8 other clinics.  I am going to try to open an EMU at a second location this fall, to show that it is not a 'one off'... I seek help on the see saw balance of 'cherry picking' clinics by already having heavy buy in versus having written agreement that they are willing to work with me and allowing the implementation to be more 'real world'.  Help?
One more thing about the 8 sites:  I have no idea how many sites I need. I also have no idea how to figure out how many sites I need.... I'm used to a straight up Efficacy RCT design... give you suggest a Type 1 hybrid, should I power on an efficacy outcome of interest?  If yes, I can figure that out now!
Last 2 points are really helpful.  Can't wait to read on!  ";s:5:"xhtml";s:1556:"Hi Wynne - <br />Thank you so much for the feedback!<br />To answer:  The EMU was paid for by my start-up, as is the exercise professional.  I seek some help with spinning this.  As *I* see it (not sure if this will fly), establishing that I can get this to work and collecting data on costs is a first step toward getting folks to pay for it.  Figuring out how to get past this is really important to me.  Exercise will NOT be paid for until we can show that implementation is possible.  If tests of implementation are impossible until we can show that it will be paid for, I&#039;m in a loop.  Help?<br />We are doing the qualitative work right now - exactly as described above.  Whuhuu!  Very validating to get your feedback on this.<br />NO, I do not have collaborative relationships with 8 other clinics.  I am going to try to open an EMU at a second location this fall, to show that it is not a &#039;one off&#039;... I seek help on the see saw balance of &#039;cherry picking&#039; clinics by already having heavy buy in versus having written agreement that they are willing to work with me and allowing the implementation to be more &#039;real world&#039;.  Help?<br />One more thing about the 8 sites:  I have no idea how many sites I need. I also have no idea how to figure out how many sites I need.... I&#039;m used to a straight up Efficacy RCT design... give you suggest a Type 1 hybrid, should I power on an efficacy outcome of interest?  If yes, I can figure that out now!<br />Last 2 points are really helpful.  Can&#039;t wait to read on!";s:6:"parent";s:32:"e49d84835f4358dbb9bec3651b0139ef";s:7:"replies";a:1:{i:0;s:32:"3a2426805ebf1adf28ddbc8be6b5a434";}s:4:"show";b:1;s:3:"cid";s:32:"e1904f5b9088f169b83340c5d65c7a85";}s:32:"bde78ba07dfb6ea63c39109c9850742c";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"wnorton";s:4:"name";s:12:"Wynne Norton";s:4:"mail";s:20:"wynne.norton@nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1535740105;}s:3:"raw";s:427:"Sounds good--very important area! 
Couple of thoughts:
--This sounds like a hybrid type 1 design, so will be good to take a look at that specific type of design in future lectures. 
--Will be good to think about how to involve stakeholders throughout this study and inform your next proposal to possibly test strategies to encourage us of this program at other sites.
--Will you be using a randomized or non-randomized design? ";s:5:"xhtml";s:446:"Sounds good--very important area! <br />Couple of thoughts:<br />--This sounds like a hybrid type 1 design, so will be good to take a look at that specific type of design in future lectures. <br />--Will be good to think about how to involve stakeholders throughout this study and inform your next proposal to possibly test strategies to encourage us of this program at other sites.<br />--Will you be using a randomized or non-randomized design?";s:6:"parent";s:32:"993529b34e54e39b58e3d0aea8780653";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"bde78ba07dfb6ea63c39109c9850742c";}s:32:"1df4759e1d8e582b7dae57b9c04127a3";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"wnorton";s:4:"name";s:12:"Wynne Norton";s:4:"mail";s:20:"wynne.norton@nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1535740960;}s:3:"raw";s:1732:"Interesting topic and sounds like a significant impediment toward advancing the evidence base for interventions and treatments. 

This proposal is a bit different from others in that you are seeking to increase practitioners' engagement in clinical trial research vs. practitioners' use of an evidence-based practice, program, intervention, drug, etc. Certainly many of the principles of implementation science can be applicable here, but it may be worthwhile to discuss potential funding opportunities for this work as it may be a bit outside the scope of some of the more common opportunities. Happy to discuss, of course. 

Comments:
--I'd strongly encourage reducing the number of items on the survey--65 seems like a lot. Can you try to remove some of the items that aren't essential to answering your research question? Maybe involve stakeholders in that decision-making process or look at previous studies that have used the survey and see if some items could be removed because they overlap a lot?
--Consider doing some qualitative research in addition to the quantitative survey to better understand the barriers that providers face in enrolling patients in clinical trials. This type of information may be particularly helpful in informing what type of strategies you may decide to use to change their behavior. 
--The idea of grand rounds and sessions is good, but you'll likely want to use other strategies to try to change provider behavior. The last lecture on implementation strategies might be particularly relevant to your study. If you collect qualitative data in addition to your survey, that may help identify potential strategies you could use to change provider behavior, too. 

Look forward to learning more! ";s:5:"xhtml";s:1801:"Interesting topic and sounds like a significant impediment toward advancing the evidence base for interventions and treatments. <br /><br />This proposal is a bit different from others in that you are seeking to increase practitioners&#039; engagement in clinical trial research vs. practitioners&#039; use of an evidence-based practice, program, intervention, drug, etc. Certainly many of the principles of implementation science can be applicable here, but it may be worthwhile to discuss potential funding opportunities for this work as it may be a bit outside the scope of some of the more common opportunities. Happy to discuss, of course. <br /><br />Comments:<br />--I&#039;d strongly encourage reducing the number of items on the survey--65 seems like a lot. Can you try to remove some of the items that aren&#039;t essential to answering your research question? Maybe involve stakeholders in that decision-making process or look at previous studies that have used the survey and see if some items could be removed because they overlap a lot?<br />--Consider doing some qualitative research in addition to the quantitative survey to better understand the barriers that providers face in enrolling patients in clinical trials. This type of information may be particularly helpful in informing what type of strategies you may decide to use to change their behavior. <br />--The idea of grand rounds and sessions is good, but you&#039;ll likely want to use other strategies to try to change provider behavior. The last lecture on implementation strategies might be particularly relevant to your study. If you collect qualitative data in addition to your survey, that may help identify potential strategies you could use to change provider behavior, too. <br /><br />Look forward to learning more!";s:6:"parent";s:32:"85d50a05ef92dd0ede87f5daea878386";s:7:"replies";a:2:{i:0;s:32:"7215d425ea49db2ede9e8c51493291fd";i:1;s:32:"49751a4e356ccb965d86d332c353006a";}s:4:"show";b:1;s:3:"cid";s:32:"1df4759e1d8e582b7dae57b9c04127a3";}s:32:"0cbf3b3b3f56df94dfee4eb5dfc207ea";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"wnorton";s:4:"name";s:12:"Wynne Norton";s:4:"mail";s:20:"wynne.norton@nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1535741739;}s:3:"raw";s:1766:"Great opportunity to partner with MOH on this important project and extend some of your earlier work. 

A few suggestions:
--Do you have hypotheses (either confirmatory or exploratory) for your overall study or by specific aim? It's not necessary, of course, but you may want to think about it and how that relates to the type of data you collect. 
--Consider narrowing in on your research question(s) a bit more. Is there literature from similar programs in other countries that would suggest the proposed approach will work? How can you build on existing literature regarding how best to deliver services in resource-limited settings? It might not be unique to cancer--could be integration of TB and HIV services in South Africa, for example--but would be good to get a sense of how other systems have expanded services given limited resources, and what strategies they have used in addition to training to facilitate this expansion.
--Consider collecting a bit more qualitative data as the study gets underway to better understand what barriers providers and clinics face before, during, and after they receive training. It may suggest that they need additional support over time (e.g., coaching, cross-clinic communication or support) to implement the program. 
--Consider collecting more data at the provider and clinic or system level, since that is really much of the focus of implementation science (i.e., how to get providers/systems/clinics to adopt and integrate evidence-based health practices, programs, interventions into routine care). I think it's good that you are focusing on patient-level data, but if you can collect additional data at the other levels of care, that may help inform how best to scale-up the program in future studies nationwide. ";s:5:"xhtml";s:1805:"Great opportunity to partner with MOH on this important project and extend some of your earlier work. <br /><br />A few suggestions:<br />--Do you have hypotheses (either confirmatory or exploratory) for your overall study or by specific aim? It&#039;s not necessary, of course, but you may want to think about it and how that relates to the type of data you collect. <br />--Consider narrowing in on your research question(s) a bit more. Is there literature from similar programs in other countries that would suggest the proposed approach will work? How can you build on existing literature regarding how best to deliver services in resource-limited settings? It might not be unique to cancer--could be integration of TB and HIV services in South Africa, for example--but would be good to get a sense of how other systems have expanded services given limited resources, and what strategies they have used in addition to training to facilitate this expansion.<br />--Consider collecting a bit more qualitative data as the study gets underway to better understand what barriers providers and clinics face before, during, and after they receive training. It may suggest that they need additional support over time (e.g., coaching, cross-clinic communication or support) to implement the program. <br />--Consider collecting more data at the provider and clinic or system level, since that is really much of the focus of implementation science (i.e., how to get providers/systems/clinics to adopt and integrate evidence-based health practices, programs, interventions into routine care). I think it&#039;s good that you are focusing on patient-level data, but if you can collect additional data at the other levels of care, that may help inform how best to scale-up the program in future studies nationwide.";s:6:"parent";s:32:"85a6cf00af34e0b436e08ad03d0b6a28";s:7:"replies";a:1:{i:0;s:32:"912f44568b5a795387dc0813bf23b75d";}s:4:"show";b:1;s:3:"cid";s:32:"0cbf3b3b3f56df94dfee4eb5dfc207ea";}s:32:"3a2426805ebf1adf28ddbc8be6b5a434";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"wnorton";s:4:"name";s:12:"Wynne Norton";s:4:"mail";s:20:"wynne.norton@nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1535742884;}s:3:"raw";s:3146:"Thanks for the reply! A couple of thoughts:
--Who pays for what is always a challenging question. One of the types of distinctions between efficacy research and effectiveness research is who pays for what--is the person delivering the intervention being paid from the grant or from their organization/clinic? If the grant (or your start-up funds) are paying for the person, you are more in the efficacy realm. If the clinic is paying for someone on staff to deliver the service, you are more in the effectiveness realm. So, might consider who will be able to deliver the intervention w/o grant support for their salary. Anyone in clinic who has the skill set and available FTE? Could it be peer-based perhaps or rely on patient navigators to deliver it? Just a few things to consider as you move from efficacy to effectiveness. 
--Consider establishing relationships with the other 8 clinics now. In an application, you'll need to demonstrate that you have working relationships with them and they are interested and committed to participating in the study. There are various ways to go about doing this--check out the literature on partnership development or participatory research. Always good to leverage personal connections, too. Could try to do a few interviews per clinic to anticipate barriers to implementation in addition to the data you've already collected. 
--Power analysis and sample size calculations are done in the same way but usually need to take into account the intraclass correlation since you have patients nested within clinics, and will likely need to do a cluster trial or stratify by clinic vs. patient. As you go through the course, try to narrow down your primary hypothesis and primary outcome, which will drive your expected effect size, power analysis, and ultimately your sample size for clinics and patients within clinics. Always a good idea to lean on statistical/methodological experts for input. 
--We'll get into this later in the course, but the hybrids are really just a way of articulating your primary and secondary objectives of the study. You can have randomized hybrids, non-randomized hybrids, etc. study designs, although most hybrid designs are indeed randomized. If you are doing a hybrid type 1, your primary objective is to look at effectiveness of the intervention--so that should be your primary outcome (i.e., does intervention change outcomes among patients as hypothesized) and then inform your power calculations.
--I'd select clinics that are engaged and eager to work with you at this point in time, and then circle back to others that may be less ready to engage later. For pilot work, I think this is a good starting point, but you're right in that you'll need to address the cherry-picking issue later (likely brought up during study section review).
--Could build in cost-effectiveness of intervention to study, but clinic managers/systems are usually more interested in return on investment as metric for assessing potential implementation and long-term sustainability (either to continue program or to adopt program). Good to involve health economist as part of your study team. ";s:5:"xhtml";s:3205:"Thanks for the reply! A couple of thoughts:<br />--Who pays for what is always a challenging question. One of the types of distinctions between efficacy research and effectiveness research is who pays for what--is the person delivering the intervention being paid from the grant or from their organization/clinic? If the grant (or your start-up funds) are paying for the person, you are more in the efficacy realm. If the clinic is paying for someone on staff to deliver the service, you are more in the effectiveness realm. So, might consider who will be able to deliver the intervention w/o grant support for their salary. Anyone in clinic who has the skill set and available FTE? Could it be peer-based perhaps or rely on patient navigators to deliver it? Just a few things to consider as you move from efficacy to effectiveness. <br />--Consider establishing relationships with the other 8 clinics now. In an application, you&#039;ll need to demonstrate that you have working relationships with them and they are interested and committed to participating in the study. There are various ways to go about doing this--check out the literature on partnership development or participatory research. Always good to leverage personal connections, too. Could try to do a few interviews per clinic to anticipate barriers to implementation in addition to the data you&#039;ve already collected. <br />--Power analysis and sample size calculations are done in the same way but usually need to take into account the intraclass correlation since you have patients nested within clinics, and will likely need to do a cluster trial or stratify by clinic vs. patient. As you go through the course, try to narrow down your primary hypothesis and primary outcome, which will drive your expected effect size, power analysis, and ultimately your sample size for clinics and patients within clinics. Always a good idea to lean on statistical/methodological experts for input. <br />--We&#039;ll get into this later in the course, but the hybrids are really just a way of articulating your primary and secondary objectives of the study. You can have randomized hybrids, non-randomized hybrids, etc. study designs, although most hybrid designs are indeed randomized. If you are doing a hybrid type 1, your primary objective is to look at effectiveness of the intervention--so that should be your primary outcome (i.e., does intervention change outcomes among patients as hypothesized) and then inform your power calculations.<br />--I&#039;d select clinics that are engaged and eager to work with you at this point in time, and then circle back to others that may be less ready to engage later. For pilot work, I think this is a good starting point, but you&#039;re right in that you&#039;ll need to address the cherry-picking issue later (likely brought up during study section review).<br />--Could build in cost-effectiveness of intervention to study, but clinic managers/systems are usually more interested in return on investment as metric for assessing potential implementation and long-term sustainability (either to continue program or to adopt program). Good to involve health economist as part of your study team.";s:6:"parent";s:32:"e1904f5b9088f169b83340c5d65c7a85";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"3a2426805ebf1adf28ddbc8be6b5a434";}s:32:"523b22af7ab009fcc1996ae91d4cd02c";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"wnorton";s:4:"name";s:12:"Wynne Norton";s:4:"mail";s:20:"wynne.norton@nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1535743219;}s:3:"raw";s:351:"Thanks for completing assignment #1! Sounds like we have a lot of very interesting and important projects in our group. As always, feel free to provide feedback on each other's proposals--questions, comments, suggestions, etc. Great to leverage our group's expertise, especially since everyone is working in the area of cancer prevention and control. ";s:5:"xhtml";s:360:"Thanks for completing assignment #1! Sounds like we have a lot of very interesting and important projects in our group. As always, feel free to provide feedback on each other&#039;s proposals--questions, comments, suggestions, etc. Great to leverage our group&#039;s expertise, especially since everyone is working in the area of cancer prevention and control.";s:6:"parent";N;s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"523b22af7ab009fcc1996ae91d4cd02c";}s:32:"ed730bf9bdc77b17872967a8be5d644b";a:8:{s:4:"user";a:5:{s:2:"id";s:8:"kschmitz";s:4:"name";s:15:"Kathryn Schmitz";s:4:"mail";s:20:"kschmitz@phs.psu.edu";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1535744009;}s:3:"raw";s:1247:"Hi gang - 

I've had feedback from Wynne (thank you for the feedback!)... and others before Wynne... that for research to move into effectiveness or straight up implementation research, the salary of the interventionists should not come from the grant.  
My conundrum arises over a 2 part problem:  1) the need for specialty training to deliver the intervention and 2) the lack of any reimbursement model for exercise specialists in clinical settings.  I think that if we could document that it is possible and effective, that we could get health systems and / or payers to cover the cost.  So there is a catch 22 loop:  payers/health systems need to see that the interventions are  possible and effective and to know the cost.  We can't find that out without the implementation research.  But implementation research means not paying interventionists.  
If it was a walking program, I would develop a 1 hour training for the nursing staff... but it's progressive resistance exercise, which isn't really something you can teach nurses to deliver in an hour-long training program.

I feel certain there is an answer to this riddle that I've just not thought of yet... If anyone else has ideas, I'm all ears!

Looking forward to a call soon...
Katie";s:5:"xhtml";s:1322:"Hi gang - <br /><br />I&#039;ve had feedback from Wynne (thank you for the feedback!)... and others before Wynne... that for research to move into effectiveness or straight up implementation research, the salary of the interventionists should not come from the grant.  <br />My conundrum arises over a 2 part problem:  1) the need for specialty training to deliver the intervention and 2) the lack of any reimbursement model for exercise specialists in clinical settings.  I think that if we could document that it is possible and effective, that we could get health systems and / or payers to cover the cost.  So there is a catch 22 loop:  payers/health systems need to see that the interventions are  possible and effective and to know the cost.  We can&#039;t find that out without the implementation research.  But implementation research means not paying interventionists.  <br />If it was a walking program, I would develop a 1 hour training for the nursing staff... but it&#039;s progressive resistance exercise, which isn&#039;t really something you can teach nurses to deliver in an hour-long training program.<br /><br />I feel certain there is an answer to this riddle that I&#039;ve just not thought of yet... If anyone else has ideas, I&#039;m all ears!<br /><br />Looking forward to a call soon...<br />Katie";s:6:"parent";N;s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"ed730bf9bdc77b17872967a8be5d644b";}s:32:"6573837ac1e57b944b50fef5e8b7cb14";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"lreinke";s:4:"name";s:11:"Lynn Reinke";s:4:"mail";s:19:"Lynn.Reinke1@va.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1535747737;}s:3:"raw";s:114:"Question re: assignment 1b.
Do you want us to upload our 3 PP slides for the elevator pitch?

Thanks, 
Lynn Reinke";s:5:"xhtml";s:134:"Question re: assignment 1b.<br />Do you want us to upload our 3 PP slides for the elevator pitch?<br /><br />Thanks, <br />Lynn Reinke";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"27a6ae6c3dc953145a2e7914a7547950";}s:4:"show";b:1;s:3:"cid";s:32:"6573837ac1e57b944b50fef5e8b7cb14";}s:32:"27a6ae6c3dc953145a2e7914a7547950";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"wnorton";s:4:"name";s:12:"Wynne Norton";s:4:"mail";s:20:"wynne.norton@nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1536090653;}s:3:"raw";s:221:"I don't think there's an option to upload docs to this site, but let me double check. We'll send out an email later this week or early next week asking for copies of PPTs for next week's elevator pitch call, too. Thanks. ";s:5:"xhtml";s:240:"I don&#039;t think there&#039;s an option to upload docs to this site, but let me double check. We&#039;ll send out an email later this week or early next week asking for copies of PPTs for next week&#039;s elevator pitch call, too. Thanks.";s:6:"parent";s:32:"6573837ac1e57b944b50fef5e8b7cb14";s:7:"replies";a:1:{i:0;s:32:"438d270d9faefa479c2829a017a34ec0";}s:4:"show";b:1;s:3:"cid";s:32:"27a6ae6c3dc953145a2e7914a7547950";}s:32:"438d270d9faefa479c2829a017a34ec0";a:8:{s:4:"user";a:5:{s:2:"id";s:8:"dbdemner";s:4:"name";s:20:"Dara Blachman-Demner";s:4:"mail";s:28:"dara.blachman-demner@nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1536177675;}s:3:"raw";s:562:"Hi all! Thanks for your engagement with the content thus far and for your completion of assignments. Sorry for the confusion, but there is no option to upload. Most groups are just sending the slides over email. Thanks for checking.

I will take this chance to also encourage you all to respond to each other's posts in order to get some cross-talk among trainees. Also, as questions emerge that you think would be best addressed by the full group, please email them to me at TIDIRH@nih.gov and I will keep them for our group call on October 9th. 

Thanks!
Dara ";s:5:"xhtml";s:591:"Hi all! Thanks for your engagement with the content thus far and for your completion of assignments. Sorry for the confusion, but there is no option to upload. Most groups are just sending the slides over email. Thanks for checking.<br /><br />I will take this chance to also encourage you all to respond to each other&#039;s posts in order to get some cross-talk among trainees. Also, as questions emerge that you think would be best addressed by the full group, please email them to me at TIDIRH@nih.gov and I will keep them for our group call on October 9th. <br /><br />Thanks!<br />Dara";s:6:"parent";s:32:"27a6ae6c3dc953145a2e7914a7547950";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"438d270d9faefa479c2829a017a34ec0";}s:32:"912f44568b5a795387dc0813bf23b75d";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"lpace";s:4:"name";s:10:"Lydia Pace";s:4:"mail";s:21:"LPACE@BWH.HARVARD.EDU";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1536201114;}s:3:"raw";s:123:"Thanks so much for these great comments - I really agree with all and am working on pulling together more thoughts. Thanks!";s:5:"xhtml";s:123:"Thanks so much for these great comments - I really agree with all and am working on pulling together more thoughts. Thanks!";s:6:"parent";s:32:"0cbf3b3b3f56df94dfee4eb5dfc207ea";s:7:"replies";a:1:{i:0;s:32:"9fc6437d9a00380a70900947c9194d49";}s:4:"show";b:1;s:3:"cid";s:32:"912f44568b5a795387dc0813bf23b75d";}s:32:"fefa50f552a3cce6e71f85076804145b";a:8:{s:4:"user";a:5:{s:2:"id";s:10:"ldimartino";s:4:"name";s:14:"Lisa DiMartino";s:4:"mail";s:18:"ldimartino@rti.org";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1536245862;}s:3:"raw";s:187:"Wynne, 
Thank you so much for your helpful feedback.  This all does make sense and I have been looking into the literature more on alert fatigue/overload.  Thanks for the suggestion.
Lisa";s:5:"xhtml";s:197:"Wynne, <br />Thank you so much for your helpful feedback.  This all does make sense and I have been looking into the literature more on alert fatigue/overload.  Thanks for the suggestion.<br />Lisa";s:6:"parent";s:32:"23300039eee4d126cd24a3abfe8cd0c9";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"fefa50f552a3cce6e71f85076804145b";}s:32:"8499f0cb4f6dec804bdbe8b4026a1aef";a:8:{s:4:"user";a:5:{s:2:"id";s:10:"moluwasanu";s:4:"name";s:18:"Mojisola Oluwasanu";s:4:"mail";s:15:"ope3m@yahoo.com";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:2:{s:7:"created";i:1536248773;s:8:"modified";i:1536257783;}s:3:"raw";s:437:"Many thanks Wynne,
 Your comments on the implementation research hybrid and health behaviour model are well taken. Thanks! 
I am reading studies in the Research- Tested Intervention Programs (RTIP) to determine the most suitable multi-component intervention for this study. I am contemplating the Witness Project/ Life is Precious - Hmong Breast Health Study.  I will be providing updates during subsequent interactions/ posts.

Thanks!
";s:5:"xhtml";s:456:"Many thanks Wynne,<br /> Your comments on the implementation research hybrid and health behaviour model are well taken. Thanks! <br />I am reading studies in the Research- Tested Intervention Programs (RTIP) to determine the most suitable multi-component intervention for this study. I am contemplating the Witness Project/ Life is Precious - Hmong Breast Health Study.  I will be providing updates during subsequent interactions/ posts.<br /><br />Thanks!";s:6:"parent";s:32:"766a61ec4c9064968e79ae092faeabd5";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"8499f0cb4f6dec804bdbe8b4026a1aef";}s:32:"a51c255a9ca36a046d1b80d9991b14ca";a:8:{s:4:"user";a:5:{s:2:"id";s:6:"klyons";s:4:"name";s:14:"Kathleen Lyons";s:4:"mail";s:30:"Kathleen.D.Lyons@dartmouth.edu";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1536278480;}s:3:"raw";s:6262:"Lyons- Assignment #2
1.	Will you be measuring and monitoring the fidelity with which the evidence-based intervention is delivered? If so, how? If not, why not? To what degree is there evidence that associates level of fidelity with individual level outcomes?
Response: In the original ENABLE RCTs, we audiorecorded the telephone calls and concurrently conducted fidelity monitoring (via worksheet with feedback provision to nurse interventionists) on a random sample of audiorecordings each month. We did not use the fidelity ratings to conduct any moderation or mediation analyses, so we are unsure as to the degree to which fidelity to treatment is correlated with individual level outcomes. 
When we conducted a demonstration project of the intervention in Honduras (i.e., a pilot study, if you will, for the proposed implementation science study that I am currently designing), our local collaborators did not feel that audiorecording would be acceptable to the patients and the nurses. The collaborators thought the nurses would feel like they were being judged and the patients would have a hard time understanding why it was necessary, though I believe we could have reduced those concerns with explanation. We decided that we would use the documentation logs to get a sense of the degree to which the steps of the intervention procedures were completed. The documentation logs did give us a sense of what happened in the telephone sessions/conversations but they did not help us assess the level of quality with which the intervention was delivered. 
I need to talk with the collaborators to determine what our options will be for fidelity monitoring going forward. One member of the research team felt that the nurses were staying on the telephone longer than was necessary, so they might have more interest in audiorecording next time so that we could discuss possible streamlining of the calls (e.g., if they needed more training in limiting off-topic conversation). Sorting out these issues would be helpful, since lack of nurse time to make the telephone calls is a barrier to further implementation.
2.	Will adaptations need to be made to your evidence-based intervention? If so, what aspects might need to be adapted? If applicable, what process would you use to guide those adaptations? Will you be considering how the intervention is likely to be adapted as it is delivered?
Response: In our demonstration project, we adapted the intervention in the following ways:
a)	Intervention recipients (population): The original program was developed (in the United States) for patients living with advanced cancer. In the proposal (and our pilot demonstration project) we worked in Honduras with people undergoing chemotherapy to treat cancer for the first time. 
b)	Dose/schedule: Instead of 4- weekly telephone calls followed by monthly phone calls, the nurses attempted to call patients twice a week during chemotherapy. This was difficult to sustain and some of the nurses suggested that going forward we consider calling only during the days when symptoms were expected to increase after chemo cycles. This may constitute a shift in philosophy from the original ENABLE intervention where we were trying to provide proactive support and education before problems arose, however, it is similar to other symptom management interventions that intervene at more targeted times when problems occur. We will need to hash this out with the team because some patients and nurses suggested fewer calls would be better and other patients and nurses felt that more contact allowed for building of rapport and well-being. I am afraid it will likely be determined by pragmatic considerations (what is most feasible to implement).
c)	Format: In the original ENABLE intervention, we sent the symptom management materials to the patients, who then followed along with the nurses as they discussed the workbook over the telephone. In our pilot project in Honduras, we only gave the workbook to the nurses. During training, we made sure that the symptom management strategies utilized resources and options that were typically available in San Pedro Sula, Honduras. We used the workbook to structure the nurse education regarding symptom management (because that was a reported priority of Honduran nurses for continuing education, both in the literature and according to our local collaborators) and did not send it to the patients (because we were told that they were not used to receiving written information, there were concerns about the literacy and comprehension, and they were not used to adopting a self-management approach to their medical care). I have mixed feelings about this adaptation and will revisit it with our collaborators as we plan the proposal. 
d)	We added a step to the telephone sessions in which the nurses asked if the patients had their orders and schedule for the next chemo appointment. There is no reminder system at the clinic and the nurses felt it was a helpful opportunity to make sure patients understood what would happen next during the calls. That adaptation will continue and is consistent with the goal of the intervention.
As I look at the readings (particularly the Stirman article), I am having a little trouble deciding how to “code” or describe these adaptations. The first three were decided upon prospectively by the research team (which included 2 investigators involved in the original ENABLE studies). We had an intervention that we were trained in, for which we had the materials, and could rapidly deploy it in a new context (patients undergoing chemotherapy in another country). The first three adaptations seem to reflect context adaptions- changing the population and the format). I could argue that the third adaptation was also a cultural adaptation as the local collaborators did not think that patients would welcome or utilize the workbook. The fourth adaptation could perhaps be called a local adaptation, as it was identified during the training of the nurse interventionists. Perhaps in the Stirman et al. framework it would be a content modification of adding an element.
This module was very interesting- looking forward to discussion and seeing everyone's thoughts and feedback. Thanks!
Kathy

";s:5:"xhtml";s:6330:"Lyons- Assignment #2<br />1.	Will you be measuring and monitoring the fidelity with which the evidence-based intervention is delivered? If so, how? If not, why not? To what degree is there evidence that associates level of fidelity with individual level outcomes?<br />Response: In the original ENABLE RCTs, we audiorecorded the telephone calls and concurrently conducted fidelity monitoring (via worksheet with feedback provision to nurse interventionists) on a random sample of audiorecordings each month. We did not use the fidelity ratings to conduct any moderation or mediation analyses, so we are unsure as to the degree to which fidelity to treatment is correlated with individual level outcomes. <br />When we conducted a demonstration project of the intervention in Honduras (i.e., a pilot study, if you will, for the proposed implementation science study that I am currently designing), our local collaborators did not feel that audiorecording would be acceptable to the patients and the nurses. The collaborators thought the nurses would feel like they were being judged and the patients would have a hard time understanding why it was necessary, though I believe we could have reduced those concerns with explanation. We decided that we would use the documentation logs to get a sense of the degree to which the steps of the intervention procedures were completed. The documentation logs did give us a sense of what happened in the telephone sessions/conversations but they did not help us assess the level of quality with which the intervention was delivered. <br />I need to talk with the collaborators to determine what our options will be for fidelity monitoring going forward. One member of the research team felt that the nurses were staying on the telephone longer than was necessary, so they might have more interest in audiorecording next time so that we could discuss possible streamlining of the calls (e.g., if they needed more training in limiting off-topic conversation). Sorting out these issues would be helpful, since lack of nurse time to make the telephone calls is a barrier to further implementation.<br />2.	Will adaptations need to be made to your evidence-based intervention? If so, what aspects might need to be adapted? If applicable, what process would you use to guide those adaptations? Will you be considering how the intervention is likely to be adapted as it is delivered?<br />Response: In our demonstration project, we adapted the intervention in the following ways:<br />a)	Intervention recipients (population): The original program was developed (in the United States) for patients living with advanced cancer. In the proposal (and our pilot demonstration project) we worked in Honduras with people undergoing chemotherapy to treat cancer for the first time. <br />b)	Dose/schedule: Instead of 4- weekly telephone calls followed by monthly phone calls, the nurses attempted to call patients twice a week during chemotherapy. This was difficult to sustain and some of the nurses suggested that going forward we consider calling only during the days when symptoms were expected to increase after chemo cycles. This may constitute a shift in philosophy from the original ENABLE intervention where we were trying to provide proactive support and education before problems arose, however, it is similar to other symptom management interventions that intervene at more targeted times when problems occur. We will need to hash this out with the team because some patients and nurses suggested fewer calls would be better and other patients and nurses felt that more contact allowed for building of rapport and well-being. I am afraid it will likely be determined by pragmatic considerations (what is most feasible to implement).<br />c)	Format: In the original ENABLE intervention, we sent the symptom management materials to the patients, who then followed along with the nurses as they discussed the workbook over the telephone. In our pilot project in Honduras, we only gave the workbook to the nurses. During training, we made sure that the symptom management strategies utilized resources and options that were typically available in San Pedro Sula, Honduras. We used the workbook to structure the nurse education regarding symptom management (because that was a reported priority of Honduran nurses for continuing education, both in the literature and according to our local collaborators) and did not send it to the patients (because we were told that they were not used to receiving written information, there were concerns about the literacy and comprehension, and they were not used to adopting a self-management approach to their medical care). I have mixed feelings about this adaptation and will revisit it with our collaborators as we plan the proposal. <br />d)	We added a step to the telephone sessions in which the nurses asked if the patients had their orders and schedule for the next chemo appointment. There is no reminder system at the clinic and the nurses felt it was a helpful opportunity to make sure patients understood what would happen next during the calls. That adaptation will continue and is consistent with the goal of the intervention.<br />As I look at the readings (particularly the Stirman article), I am having a little trouble deciding how to “code” or describe these adaptations. The first three were decided upon prospectively by the research team (which included 2 investigators involved in the original ENABLE studies). We had an intervention that we were trained in, for which we had the materials, and could rapidly deploy it in a new context (patients undergoing chemotherapy in another country). The first three adaptations seem to reflect context adaptions- changing the population and the format). I could argue that the third adaptation was also a cultural adaptation as the local collaborators did not think that patients would welcome or utilize the workbook. The fourth adaptation could perhaps be called a local adaptation, as it was identified during the training of the nurse interventionists. Perhaps in the Stirman et al. framework it would be a content modification of adding an element.<br />This module was very interesting- looking forward to discussion and seeing everyone&#039;s thoughts and feedback. Thanks!<br />Kathy";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"d6be43fd06b46e48d53ae4f1235bccb4";}s:4:"show";b:1;s:3:"cid";s:32:"a51c255a9ca36a046d1b80d9991b14ca";}s:32:"cd8668154ae5e28e0402edf10763f5e2";a:8:{s:4:"user";a:5:{s:2:"id";s:10:"ldimartino";s:4:"name";s:14:"Lisa DiMartino";s:4:"mail";s:18:"ldimartino@rti.org";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1536332467;}s:3:"raw";s:4443:"DiMartino - Assignment #2
Question #1: Will you be measuring and monitoring the fidelity with which the evidence-based intervention is delivered? If so, how? If not, why not? To what degree is there evidence that associates level of fidelity with individual level outcomes?

My response:I would include a measure of fidelity as a part of a larger implementation trial of the CDS tool (evidence-based intervention).  I would measure fidelity by assessing at least one core element - whether providers override/adhere to the reminder identifying if the patient meets criteria for palliative care (PC) and if some providers are not using them as intended. High override rates of clinical reminders are a major concern in CDS tools.  Prior research indicates overrides of CDS-generated reminders can be associated with serious adverse events, and even death.  However, the majority of this research has been done in the context of medication safety/drug alerts. In the implementation trial, measuring fidelity may help explain if effects of the tool (i.e. impact on delivery of appropriate care and clinical outcomes) are due to the tool or some other external factor.  

Another indicator of overriding/adherence could be whether the provider reported discussing PC with patients after the reminder was generated.  Data on fidelity could obtained from the EHR, in-person observation, or self-report, and collected midway through the study to provide a feedback-loop to providers on adherence to the study protocol. 

Question #2: Will adaptations need to be made to your evidence-based intervention? If so, what aspects might need to be adapted? If applicable, what process would you use to guide those adaptations? Will you be considering how the intervention is likely to be adapted as it is delivered?

My response: Adaptation will be incorporated into my research in several ways.  First, in my study, the CDS is the evidence-based intervention.  As such, I would consider development of a CDS tool using machine learning techniques to be an adaptation in and of itself.  Machine learning can be conceptualized as an adaptation because it is being introduced to improve tool adoption by tailoring PC services and access to match patient needs.  The rationale for this is demonstrated by prior research which shows personalized and patient-specific recommendations are associated with healthcare providers’ greater compliance with guideline-recommended practices generated by CDS.  

Despite its potential benefits for improving patient care, machine learning has been slow to incorporate into healthcare settings for use in CDS. To address this gap, adaptation would occur early on in the process after the machine learning algorithms have been developed in Aim 1, where I will present findings to stakeholders from several hospitals and gather data on the barriers and facilitators to how the algorithm could potentially be incorporated into an actual CDS tool.  One of the challenges in implementing a machine learning based CDS tool using the EHR will be the ability to more broadly generalize the tool and its algorithms beyond the setting in which it was developed.  Therefore, it will be critical to understand how the algorithms underlying the tool can be adapted to work with other institutions’ EHRs and workflows.

Once the tool has been developed, but prior to implementation, I would obtain further feedback from stakeholders on how the tool could be locally adapted to improve fit within the context of each hospital. During implementation, following the Stirman et al framework, I would gather data on by whom the modifications were made and context modifications, particularly the personnel involved in delivering the intervention.  However, obtaining feedback from stakeholders’ pre-implementation will help to ensure the tool is designed to be delivered by a variety of personnel.  Content modifications may also occur at multiple levels (individual, provider, hospital).  For example, hospitals may choose to add different elements or strategies alongside the tool (e.g., training programs, champions). The algorithm behind the tool and workflow integration may also continue to be refined.  I would monitor these adaptations in real-time using a tracking form, interviews, and site visits.  Gathering this information will help to interpret study findings and provide guidance for future dissemination of the tool. 

";s:5:"xhtml";s:4505:"DiMartino - Assignment #2<br />Question #1: Will you be measuring and monitoring the fidelity with which the evidence-based intervention is delivered? If so, how? If not, why not? To what degree is there evidence that associates level of fidelity with individual level outcomes?<br /><br />My response:I would include a measure of fidelity as a part of a larger implementation trial of the CDS tool (evidence-based intervention).  I would measure fidelity by assessing at least one core element - whether providers override/adhere to the reminder identifying if the patient meets criteria for palliative care (PC) and if some providers are not using them as intended. High override rates of clinical reminders are a major concern in CDS tools.  Prior research indicates overrides of CDS-generated reminders can be associated with serious adverse events, and even death.  However, the majority of this research has been done in the context of medication safety/drug alerts. In the implementation trial, measuring fidelity may help explain if effects of the tool (i.e. impact on delivery of appropriate care and clinical outcomes) are due to the tool or some other external factor.  <br /><br />Another indicator of overriding/adherence could be whether the provider reported discussing PC with patients after the reminder was generated.  Data on fidelity could obtained from the EHR, in-person observation, or self-report, and collected midway through the study to provide a feedback-loop to providers on adherence to the study protocol. <br /><br />Question #2: Will adaptations need to be made to your evidence-based intervention? If so, what aspects might need to be adapted? If applicable, what process would you use to guide those adaptations? Will you be considering how the intervention is likely to be adapted as it is delivered?<br /><br />My response: Adaptation will be incorporated into my research in several ways.  First, in my study, the CDS is the evidence-based intervention.  As such, I would consider development of a CDS tool using machine learning techniques to be an adaptation in and of itself.  Machine learning can be conceptualized as an adaptation because it is being introduced to improve tool adoption by tailoring PC services and access to match patient needs.  The rationale for this is demonstrated by prior research which shows personalized and patient-specific recommendations are associated with healthcare providers’ greater compliance with guideline-recommended practices generated by CDS.  <br /><br />Despite its potential benefits for improving patient care, machine learning has been slow to incorporate into healthcare settings for use in CDS. To address this gap, adaptation would occur early on in the process after the machine learning algorithms have been developed in Aim 1, where I will present findings to stakeholders from several hospitals and gather data on the barriers and facilitators to how the algorithm could potentially be incorporated into an actual CDS tool.  One of the challenges in implementing a machine learning based CDS tool using the EHR will be the ability to more broadly generalize the tool and its algorithms beyond the setting in which it was developed.  Therefore, it will be critical to understand how the algorithms underlying the tool can be adapted to work with other institutions’ EHRs and workflows.<br /><br />Once the tool has been developed, but prior to implementation, I would obtain further feedback from stakeholders on how the tool could be locally adapted to improve fit within the context of each hospital. During implementation, following the Stirman et al framework, I would gather data on by whom the modifications were made and context modifications, particularly the personnel involved in delivering the intervention.  However, obtaining feedback from stakeholders’ pre-implementation will help to ensure the tool is designed to be delivered by a variety of personnel.  Content modifications may also occur at multiple levels (individual, provider, hospital).  For example, hospitals may choose to add different elements or strategies alongside the tool (e.g., training programs, champions). The algorithm behind the tool and workflow integration may also continue to be refined.  I would monitor these adaptations in real-time using a tracking form, interviews, and site visits.  Gathering this information will help to interpret study findings and provide guidance for future dissemination of the tool.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"ae96feee91ca517f6b76b73babfcd529";}s:4:"show";b:1;s:3:"cid";s:32:"cd8668154ae5e28e0402edf10763f5e2";}s:32:"1950d8a8eefe00c695b0278c4623fc90";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"lreinke";s:4:"name";s:11:"Lynn Reinke";s:4:"mail";s:19:"Lynn.Reinke1@va.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1536349558;}s:3:"raw";s:3420:"Reinke, Assignment #2

Question #1: Will you be measuring and monitoring the fidelity with which the evidence-based intervention is delivered? If so, how? If not, why not? To what degree is there evidence that associates level of fidelity with individual level outcomes?

Response: Yes, I will measure and monitor fidelity at each study site (4 VISNs) by use of self-report from the interventionist (nurse) and by audio-recording approx. 10% of the delivered intervention. Self-report by the nurse will focus on which components on the EBP were covered or not covered versus a rating of the level of fidelity. Audio-recording a specific number of telephone calls the nurse conducts to deliver the intervention will assess fidelity from an objective perspective – complementing the self-report. Collectively this information will inform adaptability of the intervention due to different VA contexts, e.g. the EBP may be integrated into existing cancer care programs.

In our pilot study, we measured fidelity of intervention by determining how many sessions the nurse conducted over a 3-month period compared to the protocol and found the nurse made 6.7 (2.5 SD) out of the 8 planned calls (84%).  The PI listened to 25 of the phone calls to monitor fidelity and found the nurse only completed part of the intervention on 15 of those calls – this was due to patients’ request such as they were too tired or expressed other needs. For our full RCT, we adapted the protocol based on this information and developed “intervention boosters” offered quarterly.  Other RCTs investigating the effects of early palliative care for patients with newly diagnosed lung cancer demonstrate adherence to the protocol was high – building the evidence that the interventions had a positive impact on patient level outcomes (quality of life, decreased symptom burden.)       

Question #2: Will adaptations need to be made to your evidence-based intervention? If so, what aspects might need to be adapted? If applicable, what process would you use to guide those adaptations? Will you be considering how the intervention is likely to be adapted as it is delivered?

Response: Adaptations to the EB intervention will be necessary due to the goal of integrating the intervention in 4 different contexts. For example, if a VA/VISN has an existing nurse navigator team, we will develop a plan to integrate our existing protocols into their infrastructure. We will need to gain an understanding of their workflow and existing protocols to assess overlap.  The format may also require adaptation. Currently the intervention is designed to be delivered via telephone, however they may be times when patients have in -person visits allowing the nurse to deliver the intervention face to face. The nature of the content may require modification.  For example, module 4 focuses on initiating goals of care conversations. If the patient has recently engaged in this conversation with their provider, a complete review of this topic may be unnecessary thus the nurse may need to tailor the module to the patient.  
To guide adaptations, a framework will be used by the investigative team. Input from stakeholders is critical as well as monitoring protocol drift and offering “boosters.” Sustainability (short term) will be important to monitor, such as in the case of fund re-allocation resulting in loss of the nurse navigator team. 
";s:5:"xhtml";s:3473:"Reinke, Assignment #2<br /><br />Question #1: Will you be measuring and monitoring the fidelity with which the evidence-based intervention is delivered? If so, how? If not, why not? To what degree is there evidence that associates level of fidelity with individual level outcomes?<br /><br />Response: Yes, I will measure and monitor fidelity at each study site (4 VISNs) by use of self-report from the interventionist (nurse) and by audio-recording approx. 10% of the delivered intervention. Self-report by the nurse will focus on which components on the EBP were covered or not covered versus a rating of the level of fidelity. Audio-recording a specific number of telephone calls the nurse conducts to deliver the intervention will assess fidelity from an objective perspective – complementing the self-report. Collectively this information will inform adaptability of the intervention due to different VA contexts, e.g. the EBP may be integrated into existing cancer care programs.<br /><br />In our pilot study, we measured fidelity of intervention by determining how many sessions the nurse conducted over a 3-month period compared to the protocol and found the nurse made 6.7 (2.5 SD) out of the 8 planned calls (84%).  The PI listened to 25 of the phone calls to monitor fidelity and found the nurse only completed part of the intervention on 15 of those calls – this was due to patients’ request such as they were too tired or expressed other needs. For our full RCT, we adapted the protocol based on this information and developed “intervention boosters” offered quarterly.  Other RCTs investigating the effects of early palliative care for patients with newly diagnosed lung cancer demonstrate adherence to the protocol was high – building the evidence that the interventions had a positive impact on patient level outcomes (quality of life, decreased symptom burden.)       <br /><br />Question #2: Will adaptations need to be made to your evidence-based intervention? If so, what aspects might need to be adapted? If applicable, what process would you use to guide those adaptations? Will you be considering how the intervention is likely to be adapted as it is delivered?<br /><br />Response: Adaptations to the EB intervention will be necessary due to the goal of integrating the intervention in 4 different contexts. For example, if a VA/VISN has an existing nurse navigator team, we will develop a plan to integrate our existing protocols into their infrastructure. We will need to gain an understanding of their workflow and existing protocols to assess overlap.  The format may also require adaptation. Currently the intervention is designed to be delivered via telephone, however they may be times when patients have in -person visits allowing the nurse to deliver the intervention face to face. The nature of the content may require modification.  For example, module 4 focuses on initiating goals of care conversations. If the patient has recently engaged in this conversation with their provider, a complete review of this topic may be unnecessary thus the nurse may need to tailor the module to the patient.  <br />To guide adaptations, a framework will be used by the investigative team. Input from stakeholders is critical as well as monitoring protocol drift and offering “boosters.” Sustainability (short term) will be important to monitor, such as in the case of fund re-allocation resulting in loss of the nurse navigator team.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"230a1fdb2c92a55199fcd6b9bf73fb77";}s:4:"show";b:1;s:3:"cid";s:32:"1950d8a8eefe00c695b0278c4623fc90";}s:32:"771ade22d2948a6398c1fc4c1c7b0e31";a:8:{s:4:"user";a:5:{s:2:"id";s:10:"moluwasanu";s:4:"name";s:18:"Mojisola Oluwasanu";s:4:"mail";s:15:"ope3m@yahoo.com";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:2:{s:7:"created";i:1536349924;s:8:"modified";i:1536350123;}s:3:"raw";s:4219:"Oluwasanu- Assignment #2
1.Will you be measuring and monitoring the fidelity with which the evidence-based intervention is delivered? If so, how? If not, why not? 

The proposed study will integrate two evidence based interventions for the delivery of integrated, multi-component HIV and breast cancer risk reduction intervention. For the HIV component, the study will adopt the Combination Prevention Approach and for breast cancer, the Life is Precious - Hmong Breast Health Study will be used. The intervention will be delivered by trained laypersons (trained artisans peer educators). I will measure and monitor the fidelity of both evidence based interventions through audio-recording of all the sessions conducted by the trained artisans/peer educators. This will be coded for fidelity using a checklist. Key measures of fidelity which will be assessed are: number of training sessions held using the stipulated curricula, duration of the training sessions, No. of participants (artisans) who attend at least 90% of the sessions, quality of engagement of participants and feedback etc. A complementary approach will be the live observations of some selected training sessions (especially sessions which require the transfer of skills for breast health examination). 

2.	To what degree is there evidence that associates level of fidelity with individual level outcomes?

The sessions will be delivered by trained artisans/peer educators to a cohort of women who are also artisans. Each trained artisan will deliver the session to 10 women during their statutory meetings over a 6-months period. The level of fidelity can be measured for each trained artisan/peer educator and associated with individual outcomes within the cohort (knowledge of HIV, breast health and breast cancer preventive actions, subjective norms and attitudes regarding these diseases, perceived behavioural control to adopt HIV and BC preventive practices and behavioural intentions to screen for HIV and BC).

3.	Will adaptations need to be made to your evidence-based intervention? If so, what aspects might need to be adapted? If applicable, what process would you use to guide those adaptations? Will you be considering how the intervention is likely to be adapted as it is delivered?
Adaption will occur before and during the study. The adaption will be determined by a coalition of stakeholders (artisans, researchers and other experts including officials of the Ministries of Health, Women Affairs and Trade and Industry). Their inputs will be obtained through focus group discussions and interviews. The Stirman framework and coding system will be used to document adaptations before and during the lifetime of the project. The Combination Prevention Approach (also known nationally as the Minimum Prevention Package Intervention (MPPI) has already been adapted by the Nigeria National Agency for the Control of HIV and AIDS to suit the Nigerian context. However, the Life is Precious - Hmong Breast Health Study will be adapted because it was originally designed for Hmong women in the US. Adaptations which will be done prior to the conduct of study are outlined below:
(i)	Population/location: The study was designed for Hmong Women aged 40 years and above. For this study, younger women in Nigeria will be recruited.
(ii)	Format: Key delivery methods were one-on-one sessions, group sessions using culturally, graphically and linguistically relevant flipcharts/ materials, inclusion of Hmong men in the outreach and the use of a video which described the screening/tests. For this study, an additional component which will be incorporated is the dissemination of the videos through Whatsapp which is becoming very popular in Nigeria. With this, the women can always watch the videos to reinforce the information provided. However, men will not be included in the outreach since we will be engaging the female artisan groups.
(iii)	Content:  There will be a slight tailoring/tweaking of the content to ensure cultural and language relevance. In addition, there will an integration of HIV and breast cancer intervention which will result in an extension of the period for the training and completion of the intervention phase. 
.
";s:5:"xhtml";s:4288:"Oluwasanu- Assignment #2<br />1.Will you be measuring and monitoring the fidelity with which the evidence-based intervention is delivered? If so, how? If not, why not? <br /><br />The proposed study will integrate two evidence based interventions for the delivery of integrated, multi-component HIV and breast cancer risk reduction intervention. For the HIV component, the study will adopt the Combination Prevention Approach and for breast cancer, the Life is Precious - Hmong Breast Health Study will be used. The intervention will be delivered by trained laypersons (trained artisans peer educators). I will measure and monitor the fidelity of both evidence based interventions through audio-recording of all the sessions conducted by the trained artisans/peer educators. This will be coded for fidelity using a checklist. Key measures of fidelity which will be assessed are: number of training sessions held using the stipulated curricula, duration of the training sessions, No. of participants (artisans) who attend at least 90% of the sessions, quality of engagement of participants and feedback etc. A complementary approach will be the live observations of some selected training sessions (especially sessions which require the transfer of skills for breast health examination). <br /><br />2.	To what degree is there evidence that associates level of fidelity with individual level outcomes?<br /><br />The sessions will be delivered by trained artisans/peer educators to a cohort of women who are also artisans. Each trained artisan will deliver the session to 10 women during their statutory meetings over a 6-months period. The level of fidelity can be measured for each trained artisan/peer educator and associated with individual outcomes within the cohort (knowledge of HIV, breast health and breast cancer preventive actions, subjective norms and attitudes regarding these diseases, perceived behavioural control to adopt HIV and BC preventive practices and behavioural intentions to screen for HIV and BC).<br /><br />3.	Will adaptations need to be made to your evidence-based intervention? If so, what aspects might need to be adapted? If applicable, what process would you use to guide those adaptations? Will you be considering how the intervention is likely to be adapted as it is delivered?<br />Adaption will occur before and during the study. The adaption will be determined by a coalition of stakeholders (artisans, researchers and other experts including officials of the Ministries of Health, Women Affairs and Trade and Industry). Their inputs will be obtained through focus group discussions and interviews. The Stirman framework and coding system will be used to document adaptations before and during the lifetime of the project. The Combination Prevention Approach (also known nationally as the Minimum Prevention Package Intervention (MPPI) has already been adapted by the Nigeria National Agency for the Control of HIV and AIDS to suit the Nigerian context. However, the Life is Precious - Hmong Breast Health Study will be adapted because it was originally designed for Hmong women in the US. Adaptations which will be done prior to the conduct of study are outlined below:<br />(i)	Population/location: The study was designed for Hmong Women aged 40 years and above. For this study, younger women in Nigeria will be recruited.<br />(ii)	Format: Key delivery methods were one-on-one sessions, group sessions using culturally, graphically and linguistically relevant flipcharts/ materials, inclusion of Hmong men in the outreach and the use of a video which described the screening/tests. For this study, an additional component which will be incorporated is the dissemination of the videos through Whatsapp which is becoming very popular in Nigeria. With this, the women can always watch the videos to reinforce the information provided. However, men will not be included in the outreach since we will be engaging the female artisan groups.<br />(iii)	Content:  There will be a slight tailoring/tweaking of the content to ensure cultural and language relevance. In addition, there will an integration of HIV and breast cancer intervention which will result in an extension of the period for the training and completion of the intervention phase. <br />.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"c6c21dcd9d6e691f6a75baffa6fa1206";}s:4:"show";b:1;s:3:"cid";s:32:"771ade22d2948a6398c1fc4c1c7b0e31";}s:32:"7215d425ea49db2ede9e8c51493291fd";a:8:{s:4:"user";a:5:{s:2:"id";s:9:"aibraheem";s:4:"name";s:15:"Abiola Ibraheem";s:4:"mail";s:35:"aibraheem@medicine.bsd.uchicago.edu";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1536362946;}s:3:"raw";s:850:"Hi Wynne, thanks so much for your comments. 
Yes, this project is a little different because I am not seeking to improve the use of an intervention for a product. 
Instead, my intervention is to put in a clinical trial accrual plan in place. 
We are planning to conduct an investigator-initiated clinical trial and the goal of this trial is to show feasibility of being able to carry our ethical clinical trials in Nigeria. 
However, I was able to pre-identify barriers from the last trial we attempted 10 years ago and what is known in the literature. For the purpose of this project, I am proactively working on improving patient accrual to our study (as we failed woefully and even in the U.S.A upto 40% of studies dont accrue).

- Concerning the survey: I am just worried that building and validating a survey for this purpose may take time. 


 ";s:5:"xhtml";s:875:"Hi Wynne, thanks so much for your comments. <br />Yes, this project is a little different because I am not seeking to improve the use of an intervention for a product. <br />Instead, my intervention is to put in a clinical trial accrual plan in place. <br />We are planning to conduct an investigator-initiated clinical trial and the goal of this trial is to show feasibility of being able to carry our ethical clinical trials in Nigeria. <br />However, I was able to pre-identify barriers from the last trial we attempted 10 years ago and what is known in the literature. For the purpose of this project, I am proactively working on improving patient accrual to our study (as we failed woefully and even in the U.S.A upto 40% of studies dont accrue).<br /><br />- Concerning the survey: I am just worried that building and validating a survey for this purpose may take time.";s:6:"parent";s:32:"1df4759e1d8e582b7dae57b9c04127a3";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"7215d425ea49db2ede9e8c51493291fd";}s:32:"49751a4e356ccb965d86d332c353006a";a:8:{s:4:"user";a:5:{s:2:"id";s:9:"aibraheem";s:4:"name";s:15:"Abiola Ibraheem";s:4:"mail";s:35:"aibraheem@medicine.bsd.uchicago.edu";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1536367400;}s:3:"raw";s:1716:"Modified specific aims. 
To ensure that we have reached our accrual goal (which is 4 HER2+ breast cancers monthly) I need to involve the stakeholders (the surgeons, pathologists, oncologists) to refer patients to us for clinical trials. 	

Specific Aim #1: To identify and involve stakeholders in our upcoming clinical trials by educating them about clinical trials and assessing their attitudes and concerns about referring patients for clinical trials. To better define the barriers that may be peculiar to this region, I will conduct a qualitative research design using focus groups according to their specialties. 
 Hypothesis 1: Nigerian physicians have low basic knowledge about randomized clinical trials and poor attitudes and perception towards randomized clinical trials.

Specific Aim #2: Using the results from Aim #1, I will conduct an intervention designed to improve providers’ knowledge about oncology randomized clinical trials and address attitudes and perceived barriers to enrolling patients on study. To accomplish this aim, (i) Education through ground rounds impacting knowledge on randomized clinical trials will be carried out quarterly and Specialities’ focused group will be carried out to ensure retention of information. 
(ii) The already established clinical trial team will identify and bring to the attention of the treating physicians, new patients who may be eligible for our study.
(iii) Reminders will be sent to our stakeholders about the progress of the clinical trial. 
Hypothesis 2: The tailored evidence-based intervention will improve knowledge, attitude and perception of providers towards clinical trial. 

The outcome of our intervention is to reach our accrual goal ";s:5:"xhtml";s:1770:"Modified specific aims. <br />To ensure that we have reached our accrual goal (which is 4 HER2+ breast cancers monthly) I need to involve the stakeholders (the surgeons, pathologists, oncologists) to refer patients to us for clinical trials. 	<br /><br />Specific Aim #1: To identify and involve stakeholders in our upcoming clinical trials by educating them about clinical trials and assessing their attitudes and concerns about referring patients for clinical trials. To better define the barriers that may be peculiar to this region, I will conduct a qualitative research design using focus groups according to their specialties. <br /> Hypothesis 1: Nigerian physicians have low basic knowledge about randomized clinical trials and poor attitudes and perception towards randomized clinical trials.<br /><br />Specific Aim #2: Using the results from Aim #1, I will conduct an intervention designed to improve providers’ knowledge about oncology randomized clinical trials and address attitudes and perceived barriers to enrolling patients on study. To accomplish this aim, (i) Education through ground rounds impacting knowledge on randomized clinical trials will be carried out quarterly and Specialities’ focused group will be carried out to ensure retention of information. <br />(ii) The already established clinical trial team will identify and bring to the attention of the treating physicians, new patients who may be eligible for our study.<br />(iii) Reminders will be sent to our stakeholders about the progress of the clinical trial. <br />Hypothesis 2: The tailored evidence-based intervention will improve knowledge, attitude and perception of providers towards clinical trial. <br /><br />The outcome of our intervention is to reach our accrual goal";s:6:"parent";s:32:"1df4759e1d8e582b7dae57b9c04127a3";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"49751a4e356ccb965d86d332c353006a";}s:32:"d3736a399680ad630f37100e17e42753";a:8:{s:4:"user";a:5:{s:2:"id";s:9:"aibraheem";s:4:"name";s:15:"Abiola Ibraheem";s:4:"mail";s:35:"aibraheem@medicine.bsd.uchicago.edu";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1536370943;}s:3:"raw";s:1602:"Ibraheem Abiola Assignment #2


Question #1: Will you be measuring and monitoring the fidelity with which the evidence-based intervention is delivered? If so, how? If not, why not? To what degree is there evidence that associates level of fidelity with individual level outcomes?

Response: Yes, I will be measuring fidelity and monitoring fidelity. To measure fidelity, I will use the data self-report and observation method after my proposed qualitative survey and after educational intervention. Data will be collected anonymously from all participants of this intervention. 
I will adopt a new fidelity measure to assess the effect of our established clinical trial team actively recruiting new patients who may be eligible for our study.


Question #2: Will adaptations need to be made to your evidence-based intervention? If so, what aspects might need to be adapted? If applicable, what process would you use to guide those adaptations? Will you be considering how the intervention is likely to be adapted as it is delivered?

Response: After our intervention, if after 2 months, we do not meet our accrual of 4 patients monthly, we will adapt our implementation to improve our accrual rate.  
First, we will rediscuss with our stakeholders to identify if there are new barriers which can be addressed. We will also address the time it takes to diagnose the receptor subtype of newly diagnosed breast cancer patients. I will access and address the clinical trial team to see if we can be effective in identifying new patients. We may have to expand to local hospitals to accrue new patients.   
";s:5:"xhtml";s:1658:"Ibraheem Abiola Assignment #2<br /><br /><br />Question #1: Will you be measuring and monitoring the fidelity with which the evidence-based intervention is delivered? If so, how? If not, why not? To what degree is there evidence that associates level of fidelity with individual level outcomes?<br /><br />Response: Yes, I will be measuring fidelity and monitoring fidelity. To measure fidelity, I will use the data self-report and observation method after my proposed qualitative survey and after educational intervention. Data will be collected anonymously from all participants of this intervention. <br />I will adopt a new fidelity measure to assess the effect of our established clinical trial team actively recruiting new patients who may be eligible for our study.<br /><br /><br />Question #2: Will adaptations need to be made to your evidence-based intervention? If so, what aspects might need to be adapted? If applicable, what process would you use to guide those adaptations? Will you be considering how the intervention is likely to be adapted as it is delivered?<br /><br />Response: After our intervention, if after 2 months, we do not meet our accrual of 4 patients monthly, we will adapt our implementation to improve our accrual rate.  <br />First, we will rediscuss with our stakeholders to identify if there are new barriers which can be addressed. We will also address the time it takes to diagnose the receptor subtype of newly diagnosed breast cancer patients. I will access and address the clinical trial team to see if we can be effective in identifying new patients. We may have to expand to local hospitals to accrue new patients.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"d31b7ad9fc98e6e0ce93ef2e9c089ced";}s:4:"show";b:1;s:3:"cid";s:32:"d3736a399680ad630f37100e17e42753";}s:32:"017843a132767dd3c692daaf16180fc2";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"lpace";s:4:"name";s:10:"Lydia Pace";s:4:"mail";s:21:"LPACE@BWH.HARVARD.EDU";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1536371131;}s:3:"raw";s:4027:"Pace, Assignment #2

1.	Will you be measuring and monitoring the fidelity with which the evidence-based intervention is delivered? If so, how? If not, why not? To what degree is there evidence that associates level of fidelity with individual level outcomes?

I want to mention first that in the case of my proposed study, the intervention that we are scaling up in 2 new districts is one that we piloted successfully in a single district, and not truly a global evidence-based standard. The only breast cancer screening modality shown to reduce breast cancer mortality is screening mammography, though screening CBE has shown some promise in downstaging in some studies. However, many experts do think that starting with an early diagnosis approach (targeting symptomatic women) is the logical first step to take in a low income country.  And, there is consensus about the components of high-quality CBE, though the data linking fidelity to high-quality CBE with improved patient outcomes are limited. Further, how these services should be delivered in a rural primary care setting in a low-income country is not known. 

I also want to mention that I think there are a LOT of questions that can be asked from the current scale-up project that is the core of my proposed study. In the future, I would really like to do a cluster randomized trial comparing the impact and benefit of a CBE screening versus CBE early diagnosis approach. But that’s for another day.

The aspects of fidelity that I’ve planned to investigate so far are: a) how often breast clinics are held in the trained health centers and district hospital (using self-report from “focal points” designated at the health centers and hospital); b) how well clinical breast exams are performed by trainees (using mentors as observers, and already-developed clinical checklists).

2. Will adaptations need to be made to your evidence-based intervention? If so, what aspects might need to be adapted? If applicable, what process would you use to guide those adaptations? Will you be considering how the intervention is likely to be adapted as it is delivered?

Adaptations have already been made to our original intervention to make it less expensive, as follows: a) the training has been an “on the job” training where nurses do their regular jobs in the mornings and then come to lectures in the afternoon at their place of work; b) we have not trained community health workers to raise breast health awareness in a formal way; c) we have combined our breast health intervention with a cervical cancer screening training program and made the weekly clinics into breast and cervical cancer screening clinics; d) we have had more of a focus on screening of asymptomatic women rather than earlier diagnosis of symptomatic cancer. The main way that this has been manifest is that the clinics are doing screening CBE on every woman who comes in for cervical cancer screening (30-50 years old and due for screening).

I have had little control over these adaptations because they were largely made by the Ministry of Health. Our current plan (made with the MOH when I was in Rwanda last week) is to study the impact of the current version of the intervention in 2 districts, and use the information gathered to inform further scaleup. For example, if the referral rates and cancer detection rates are extremely low, and much lower than in our pilot district, that may suggest that it would be more practical and cost-effective to adopt a symptom-based approach or to screen higher-risk women only (for example older women). Or, if trained clinicians do not perform well on post-tests and checklists, the “on the job” style training may not work well.
I am thinking about how to examine the proportion of women who receive CBE in health centers who had symptoms versus women who were asymptomatic and screened. We could add a box to our paper documentation form asking this, but I’m not sure if we’ll be able to enter and analyze all of those data. 
";s:5:"xhtml";s:4100:"Pace, Assignment #2<br /><br />1.	Will you be measuring and monitoring the fidelity with which the evidence-based intervention is delivered? If so, how? If not, why not? To what degree is there evidence that associates level of fidelity with individual level outcomes?<br /><br />I want to mention first that in the case of my proposed study, the intervention that we are scaling up in 2 new districts is one that we piloted successfully in a single district, and not truly a global evidence-based standard. The only breast cancer screening modality shown to reduce breast cancer mortality is screening mammography, though screening CBE has shown some promise in downstaging in some studies. However, many experts do think that starting with an early diagnosis approach (targeting symptomatic women) is the logical first step to take in a low income country.  And, there is consensus about the components of high-quality CBE, though the data linking fidelity to high-quality CBE with improved patient outcomes are limited. Further, how these services should be delivered in a rural primary care setting in a low-income country is not known. <br /><br />I also want to mention that I think there are a LOT of questions that can be asked from the current scale-up project that is the core of my proposed study. In the future, I would really like to do a cluster randomized trial comparing the impact and benefit of a CBE screening versus CBE early diagnosis approach. But that’s for another day.<br /><br />The aspects of fidelity that I’ve planned to investigate so far are: a) how often breast clinics are held in the trained health centers and district hospital (using self-report from “focal points” designated at the health centers and hospital); b) how well clinical breast exams are performed by trainees (using mentors as observers, and already-developed clinical checklists).<br /><br />2. Will adaptations need to be made to your evidence-based intervention? If so, what aspects might need to be adapted? If applicable, what process would you use to guide those adaptations? Will you be considering how the intervention is likely to be adapted as it is delivered?<br /><br />Adaptations have already been made to our original intervention to make it less expensive, as follows: a) the training has been an “on the job” training where nurses do their regular jobs in the mornings and then come to lectures in the afternoon at their place of work; b) we have not trained community health workers to raise breast health awareness in a formal way; c) we have combined our breast health intervention with a cervical cancer screening training program and made the weekly clinics into breast and cervical cancer screening clinics; d) we have had more of a focus on screening of asymptomatic women rather than earlier diagnosis of symptomatic cancer. The main way that this has been manifest is that the clinics are doing screening CBE on every woman who comes in for cervical cancer screening (30-50 years old and due for screening).<br /><br />I have had little control over these adaptations because they were largely made by the Ministry of Health. Our current plan (made with the MOH when I was in Rwanda last week) is to study the impact of the current version of the intervention in 2 districts, and use the information gathered to inform further scaleup. For example, if the referral rates and cancer detection rates are extremely low, and much lower than in our pilot district, that may suggest that it would be more practical and cost-effective to adopt a symptom-based approach or to screen higher-risk women only (for example older women). Or, if trained clinicians do not perform well on post-tests and checklists, the “on the job” style training may not work well.<br />I am thinking about how to examine the proportion of women who receive CBE in health centers who had symptoms versus women who were asymptomatic and screened. We could add a box to our paper documentation form asking this, but I’m not sure if we’ll be able to enter and analyze all of those data.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"2bf37fadf57e2c010f17112922ae105a";}s:4:"show";b:1;s:3:"cid";s:32:"017843a132767dd3c692daaf16180fc2";}s:32:"9056e948a00d67f6c9d9634359977604";a:8:{s:4:"user";a:5:{s:2:"id";s:8:"kschmitz";s:4:"name";s:15:"Kathryn Schmitz";s:4:"mail";s:20:"kschmitz@phs.psu.edu";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1536516706;}s:3:"raw";s:3387:"Schmitz.  Assignment 2.

1.	Will you be measuring and monitoring the fidelity with which the evidence-based intervention is delivered? If so, how? If not, why not? To what degree is there evidence that associates level of fidelity with individual level outcomes?

Yes, we will measure and monitor the fidelity with which the evidence based intervention is delivered.  Fidelity will be assess with measures of adherence of interventionists to the adapted intervention protocol, dosage (elements of protocol delivered), quality of delivery (assessed by observation with a standardized theoretically grounded checklist), recording interventionist adaptations to the program, and engagement of patients to the intervention (% of prescribed exercise sessions completed).  
Prior evidence based interventions indicate that the elements of interventions that predict physiologic benefit from an exercise program include the frequency of interventionist contact with participants, quality of delivery (sense by patients of unconditional positive regard from the interventionist), and engagement (% prescribed sessions completed) are all associated with individual level outcomes.

2.	Will adaptations need to be made to your evidence-based intervention? If so, what aspects might need to be adapted? If applicable, what process would you use to guide those adaptations? Will you be considering how the intervention is likely to be adapted as it is delivered?

Yes, adaptations need to be made to the evidence based intervention.  The primary adaptations are intervention personnel (exercise professionals in EBI, nursing staff in adapted intervention), exercise equipment (adaptable dumbbells in EBI, resistance exercise bands in adapted intervention), and setting (academic medical center in EBI, community oncology in adapted intervention).  Methods originally described in Stirman et al 2013 and updated by Hall et al. 2017 will be used to assess adaptations.
To accomplish the personnel adaptation, we will enlist nursing stakeholders to co-develop an adapted training for intervention delivery.  This will require cultural adaptation, as both the culture and skill set of nursing is distinct from that of exercise professionals.  
To accomplish the exercise equipment adaptation will require the oncology clinic leadership to be willing to spend $250 per year for resistance exercise bands (less for smaller clinics).  Semi-structured interviews with practice managers and managing partner physicians of oncology clinics will be used to better understand the culture of that setting.  It is hypothesized that better understanding of the value system for these leaders will facilitate development of an effective approach to requesting that the clinic take on this financial burden.
To accomplish the setting adaptation, we will enlist the assistance of the nursing stakeholders, practice managers, and managing partner physician to review and discuss intervention elements and decide together what alterations will be needed and how best to make them to increase the likelihood of high fidelity to core elements of the intervention.
Finally, we recognize that there are likely to be unplanned adaptations that occur as the intervention is being delivered.  We will record these and evaluate whether these can be considered a positive versus a negative deviation from the original protocol.
";s:5:"xhtml";s:3451:"Schmitz.  Assignment 2.<br /><br />1.	Will you be measuring and monitoring the fidelity with which the evidence-based intervention is delivered? If so, how? If not, why not? To what degree is there evidence that associates level of fidelity with individual level outcomes?<br /><br />Yes, we will measure and monitor the fidelity with which the evidence based intervention is delivered.  Fidelity will be assess with measures of adherence of interventionists to the adapted intervention protocol, dosage (elements of protocol delivered), quality of delivery (assessed by observation with a standardized theoretically grounded checklist), recording interventionist adaptations to the program, and engagement of patients to the intervention (% of prescribed exercise sessions completed).  <br />Prior evidence based interventions indicate that the elements of interventions that predict physiologic benefit from an exercise program include the frequency of interventionist contact with participants, quality of delivery (sense by patients of unconditional positive regard from the interventionist), and engagement (% prescribed sessions completed) are all associated with individual level outcomes.<br /><br />2.	Will adaptations need to be made to your evidence-based intervention? If so, what aspects might need to be adapted? If applicable, what process would you use to guide those adaptations? Will you be considering how the intervention is likely to be adapted as it is delivered?<br /><br />Yes, adaptations need to be made to the evidence based intervention.  The primary adaptations are intervention personnel (exercise professionals in EBI, nursing staff in adapted intervention), exercise equipment (adaptable dumbbells in EBI, resistance exercise bands in adapted intervention), and setting (academic medical center in EBI, community oncology in adapted intervention).  Methods originally described in Stirman et al 2013 and updated by Hall et al. 2017 will be used to assess adaptations.<br />To accomplish the personnel adaptation, we will enlist nursing stakeholders to co-develop an adapted training for intervention delivery.  This will require cultural adaptation, as both the culture and skill set of nursing is distinct from that of exercise professionals.  <br />To accomplish the exercise equipment adaptation will require the oncology clinic leadership to be willing to spend $250 per year for resistance exercise bands (less for smaller clinics).  Semi-structured interviews with practice managers and managing partner physicians of oncology clinics will be used to better understand the culture of that setting.  It is hypothesized that better understanding of the value system for these leaders will facilitate development of an effective approach to requesting that the clinic take on this financial burden.<br />To accomplish the setting adaptation, we will enlist the assistance of the nursing stakeholders, practice managers, and managing partner physician to review and discuss intervention elements and decide together what alterations will be needed and how best to make them to increase the likelihood of high fidelity to core elements of the intervention.<br />Finally, we recognize that there are likely to be unplanned adaptations that occur as the intervention is being delivered.  We will record these and evaluate whether these can be considered a positive versus a negative deviation from the original protocol.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"496167704743c420894405991251d87b";}s:4:"show";b:1;s:3:"cid";s:32:"9056e948a00d67f6c9d9634359977604";}s:32:"44b268627af3c8fe0c72e138960955f2";a:8:{s:4:"user";a:5:{s:2:"id";s:8:"khuggins";s:4:"name";s:12:"Kate Huggins";s:4:"mail";s:23:"kate.huggins@monash.edu";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:2:{s:7:"created";i:1536635818;s:8:"modified";i:1536635847;}s:3:"raw";s:2901:"Huggins Assignment 2

1. As noted in Wynne’s feedback, this study is best described as a hybrid design: effectiveness-implementation design.  The aim is to determine if early and intensive nutrition care that is provided in addition to usual care is effective (improved quality of life) and cost effective. The nutrition intervention is delivered by a dietitian and is underpinned by behaviour change techniques. The study is comparing two modes of delivery for the intervention: 1) via the telephone and 2) via mHealth (a mobile application).

Fidelity will be captured in the audio recordings and in the written communication between the dietitian and the participant. A comparison of what was delivered compared with what was prescribed in the standard operating procedure will be undertaken (content analysis and also a thematic analysis).  We will also look at temporal factors such as time to commencing the intervention, the number of sessions completed (dietitian attempts to contact vs. engagement). The relationship between intervention components and individual outcomes will be explored in modelling analyses. Together this will help to generate the evidence that associates level of fidelity with individual level outcomes, which will be useful when we extend from the research setting (which this study is currently best described as) to the practice setting.

2. We have one standard operating procedure for how the nutrition care should be provided during the intervention (e.g based on behaviour change theory) and this has been designed based on how nutrition care was delivered over the telephone in our pilot study. This is the first time that we will be delivering the intervention using mHealth – via a mobile application that participants will download onto an iPad or iPhone.  We will have a range of quantitative and qualitative data that will enable an analysis of the adaptations made to allow the intervention to be delivered or that were necessary to enable engagement.  In particular I hypothesise that the communication/language will need to be adapted between the telephone and mHealth groups. The intervention delivery records will be analysed to examine this.  What we expect this analysis to tell us is, whether specific communication training for clinical staff communicating via mHealth is required prior to broader implementation of the intervention. Post-intervention interviews will be conducted with participants and with Health service staff to gain their perspectives of necessary adaptations for moving from the research setting to the practice setting. Participants wil be able to tell us if there are adaptations to the technology platform that will make the communication easier/smoother. The modelling analysis will also inform whether the frequency and duration of the intervention can be adapted and how this might impact on individual outcomes. 
";s:5:"xhtml";s:2929:"Huggins Assignment 2<br /><br />1. As noted in Wynne’s feedback, this study is best described as a hybrid design: effectiveness-implementation design.  The aim is to determine if early and intensive nutrition care that is provided in addition to usual care is effective (improved quality of life) and cost effective. The nutrition intervention is delivered by a dietitian and is underpinned by behaviour change techniques. The study is comparing two modes of delivery for the intervention: 1) via the telephone and 2) via mHealth (a mobile application).<br /><br />Fidelity will be captured in the audio recordings and in the written communication between the dietitian and the participant. A comparison of what was delivered compared with what was prescribed in the standard operating procedure will be undertaken (content analysis and also a thematic analysis).  We will also look at temporal factors such as time to commencing the intervention, the number of sessions completed (dietitian attempts to contact vs. engagement). The relationship between intervention components and individual outcomes will be explored in modelling analyses. Together this will help to generate the evidence that associates level of fidelity with individual level outcomes, which will be useful when we extend from the research setting (which this study is currently best described as) to the practice setting.<br /><br />2. We have one standard operating procedure for how the nutrition care should be provided during the intervention (e.g based on behaviour change theory) and this has been designed based on how nutrition care was delivered over the telephone in our pilot study. This is the first time that we will be delivering the intervention using mHealth – via a mobile application that participants will download onto an iPad or iPhone.  We will have a range of quantitative and qualitative data that will enable an analysis of the adaptations made to allow the intervention to be delivered or that were necessary to enable engagement.  In particular I hypothesise that the communication/language will need to be adapted between the telephone and mHealth groups. The intervention delivery records will be analysed to examine this.  What we expect this analysis to tell us is, whether specific communication training for clinical staff communicating via mHealth is required prior to broader implementation of the intervention. Post-intervention interviews will be conducted with participants and with Health service staff to gain their perspectives of necessary adaptations for moving from the research setting to the practice setting. Participants wil be able to tell us if there are adaptations to the technology platform that will make the communication easier/smoother. The modelling analysis will also inform whether the frequency and duration of the intervention can be adapted and how this might impact on individual outcomes.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"ddff19282a459762a6fe2ade6cdd65d9";}s:4:"show";b:1;s:3:"cid";s:32:"44b268627af3c8fe0c72e138960955f2";}s:32:"9fc6437d9a00380a70900947c9194d49";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"lpace";s:4:"name";s:10:"Lydia Pace";s:4:"mail";s:21:"LPACE@BWH.HARVARD.EDU";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1536686629;}s:3:"raw";s:1519:"Thanks again for these comments. Thinking about hypotheses makes me confront the fact that presenting the sheer numbers of patients seen and referred, and then the number of cancers diagnosed, doesn't permit conclusions about feasibility (or, of course, cost-effectiveness). We can use them in a few ways - a) to generate a sense among providers about the health system burden (for example, in Burera, we only increased volume by about 10 patients/ month/ health center, which ended up being pretty manageable for a given health center, though we admittedly didn't ask anyone that directly); b)  to compare to other studies (for example, prior studies of CBE test characteristics, or cancer detection rates in other CBE programs eg India); c) to compare to the Burera pilot, where we adopted a symptom-focused approach to early diagnosis. Our rate of referrals from HCs to the hospital in Burera was 20%, whereas so far in our 2 new districts it has only been about 5%, consistent with the fact that we've been screening asymptomatic women so fewer should have positive CBE. I could generate hypotheses for any of those, though they don't feel like the most rigorous approaches for specific aims. Does that seem like a reasonable way to think about this? I do think that examining fidelity and adaptation and doing some interviews with providers could give a better sense of implementation and feasibility.....even though it feels harder, and newer, and the hypotheses aren't entirely clear to me in that domain either.";s:5:"xhtml";s:1544:"Thanks again for these comments. Thinking about hypotheses makes me confront the fact that presenting the sheer numbers of patients seen and referred, and then the number of cancers diagnosed, doesn&#039;t permit conclusions about feasibility (or, of course, cost-effectiveness). We can use them in a few ways - a) to generate a sense among providers about the health system burden (for example, in Burera, we only increased volume by about 10 patients/ month/ health center, which ended up being pretty manageable for a given health center, though we admittedly didn&#039;t ask anyone that directly); b)  to compare to other studies (for example, prior studies of CBE test characteristics, or cancer detection rates in other CBE programs eg India); c) to compare to the Burera pilot, where we adopted a symptom-focused approach to early diagnosis. Our rate of referrals from HCs to the hospital in Burera was 20%, whereas so far in our 2 new districts it has only been about 5%, consistent with the fact that we&#039;ve been screening asymptomatic women so fewer should have positive CBE. I could generate hypotheses for any of those, though they don&#039;t feel like the most rigorous approaches for specific aims. Does that seem like a reasonable way to think about this? I do think that examining fidelity and adaptation and doing some interviews with providers could give a better sense of implementation and feasibility.....even though it feels harder, and newer, and the hypotheses aren&#039;t entirely clear to me in that domain either.";s:6:"parent";s:32:"912f44568b5a795387dc0813bf23b75d";s:7:"replies";a:1:{i:0;s:32:"87a7e1694392fa1fb687f53011317cf2";}s:4:"show";b:1;s:3:"cid";s:32:"9fc6437d9a00380a70900947c9194d49";}s:32:"ddff19282a459762a6fe2ade6cdd65d9";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"wnorton";s:4:"name";s:12:"Wynne Norton";s:4:"mail";s:20:"wynne.norton@nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1536947884;}s:3:"raw";s:524:"Good! I like your use of both qualitative and quantitative data to assess fidelity and adaptation, and linking it back to the original theory of behavior change. Logistically, it may be quite difficult to audio-record all of the conversations--you might consider select a random sample of x-number of conversations at different time points in the study to record (blocked by the nutritionist) and transcribe and code those conversations as a fidelity assessment. 
Just curious--what type of modeling analyses do you plan? 

";s:5:"xhtml";s:526:"Good! I like your use of both qualitative and quantitative data to assess fidelity and adaptation, and linking it back to the original theory of behavior change. Logistically, it may be quite difficult to audio-record all of the conversations--you might consider select a random sample of x-number of conversations at different time points in the study to record (blocked by the nutritionist) and transcribe and code those conversations as a fidelity assessment. <br />Just curious--what type of modeling analyses do you plan?";s:6:"parent";s:32:"44b268627af3c8fe0c72e138960955f2";s:7:"replies";a:1:{i:0;s:32:"00726a03a6cceaf39c0b0fca8682cd06";}s:4:"show";b:1;s:3:"cid";s:32:"ddff19282a459762a6fe2ade6cdd65d9";}s:32:"496167704743c420894405991251d87b";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"wnorton";s:4:"name";s:12:"Wynne Norton";s:4:"mail";s:20:"wynne.norton@nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1536948440;}s:3:"raw";s:1292:"Very well described and thoughtful. A couple comments:
--Measurement of fidelity and adaptation is in its infancy. This sounds like a nice opportunity to develop, pilot, and potentially validate some brief measures of adaptation and fidelity that, while unique to your study, might be generalizable to other studies, especially if you are relying on the Wiltsey-Stirman article for adaptation classifications. You want to balance the need to assess fidelity and adaptation with time constraints and logistically challenges of doing so, but this might be a nice opportunity to advance the science of measurement in adaptation and fidelity (i.e., innovative!).
--Any chance that the onc clinics work with (or refer to/from) physical therapy practices...who might be willing to donate some of the supplies? 
--You'll need to make sure that delivering the intervention is within the scope of practice for nurses--that it is consistent with their job responsibilities and that their provision of the intervention is covered under the practice's liability (in case a patient is injured for whatever reason when exercising). These are some nitty-gritty details that you'll want to figure out sooner rather than later, to make sure that a nurse-delivered intervention is in fact an viable adaptation.";s:5:"xhtml";s:1322:"Very well described and thoughtful. A couple comments:<br />--Measurement of fidelity and adaptation is in its infancy. This sounds like a nice opportunity to develop, pilot, and potentially validate some brief measures of adaptation and fidelity that, while unique to your study, might be generalizable to other studies, especially if you are relying on the Wiltsey-Stirman article for adaptation classifications. You want to balance the need to assess fidelity and adaptation with time constraints and logistically challenges of doing so, but this might be a nice opportunity to advance the science of measurement in adaptation and fidelity (i.e., innovative!).<br />--Any chance that the onc clinics work with (or refer to/from) physical therapy practices...who might be willing to donate some of the supplies? <br />--You&#039;ll need to make sure that delivering the intervention is within the scope of practice for nurses--that it is consistent with their job responsibilities and that their provision of the intervention is covered under the practice&#039;s liability (in case a patient is injured for whatever reason when exercising). These are some nitty-gritty details that you&#039;ll want to figure out sooner rather than later, to make sure that a nurse-delivered intervention is in fact an viable adaptation.";s:6:"parent";s:32:"9056e948a00d67f6c9d9634359977604";s:7:"replies";a:1:{i:0;s:32:"01898a27cad6cc4a41082d6cc7a8e90d";}s:4:"show";b:1;s:3:"cid";s:32:"496167704743c420894405991251d87b";}s:32:"01898a27cad6cc4a41082d6cc7a8e90d";a:8:{s:4:"user";a:5:{s:2:"id";s:8:"kschmitz";s:4:"name";s:15:"Kathryn Schmitz";s:4:"mail";s:20:"kschmitz@phs.psu.edu";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1536948740;}s:3:"raw";s:472:"Thank you Wynne! 
I am also exploring having a 3rd party payer pay for the exercise specialists to deliver the intervention.... so that would cover the scope of work issue... but nursing staff have been delivering exercise programming to cancer patients since the 70's, so we're good either way.  

As to PT - we did that before (Beidas et al 2014), and found that patients won't go to a different location to learn the exercise.  But donations of equipment ... cool idea!";s:5:"xhtml";s:502:"Thank you Wynne! <br />I am also exploring having a 3rd party payer pay for the exercise specialists to deliver the intervention.... so that would cover the scope of work issue... but nursing staff have been delivering exercise programming to cancer patients since the 70&#039;s, so we&#039;re good either way.  <br /><br />As to PT - we did that before (Beidas et al 2014), and found that patients won&#039;t go to a different location to learn the exercise.  But donations of equipment ... cool idea!";s:6:"parent";s:32:"496167704743c420894405991251d87b";s:7:"replies";a:1:{i:0;s:32:"6663bf7530d985d3115f8435aec75261";}s:4:"show";b:1;s:3:"cid";s:32:"01898a27cad6cc4a41082d6cc7a8e90d";}s:32:"d6be43fd06b46e48d53ae4f1235bccb4";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"gneta";s:4:"name";s:9:"Gila Neta";s:4:"mail";s:20:"netagil@mail.nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1536948771;}s:3:"raw";s:1225:"Very nicely described! And clearly well thought through. A few thoughts/questions come to mind:
1) For fidelity monitoring, is it an option, or did you already do this, to have blinded fidelity monitoring so that nurses do not know whether they will be monitored (and thus their behavior would be less affected presumably), but all nurses and patients understand that monitoring *may* occur? Not sure how this works with IRB/ethics issues, but something to the effect of "this call may be monitored for quality assurance" type of thing?
2) Regarding adaptation of dose/schedule: might you consider an adaptation strategy that would allow you to identify those who need a higher dose vs. those for whom weekly calls will suffice, and thus tailor the intervention to be flexible to accommodate those different needs?
3) Regarding format, is there a patient-tailored format that could be further adapted to serve the San Pedro Sula population? So the format wouldn't be the same as for nurses, but would follow a similar narrative - just the interface would look quite different. Curious if there are other public health education materials in the community upon which this could be modeled? A dissemination research question...";s:5:"xhtml";s:1255:"Very nicely described! And clearly well thought through. A few thoughts/questions come to mind:<br />1) For fidelity monitoring, is it an option, or did you already do this, to have blinded fidelity monitoring so that nurses do not know whether they will be monitored (and thus their behavior would be less affected presumably), but all nurses and patients understand that monitoring *may* occur? Not sure how this works with IRB/ethics issues, but something to the effect of &quot;this call may be monitored for quality assurance&quot; type of thing?<br />2) Regarding adaptation of dose/schedule: might you consider an adaptation strategy that would allow you to identify those who need a higher dose vs. those for whom weekly calls will suffice, and thus tailor the intervention to be flexible to accommodate those different needs?<br />3) Regarding format, is there a patient-tailored format that could be further adapted to serve the San Pedro Sula population? So the format wouldn&#039;t be the same as for nurses, but would follow a similar narrative - just the interface would look quite different. Curious if there are other public health education materials in the community upon which this could be modeled? A dissemination research question...";s:6:"parent";s:32:"a51c255a9ca36a046d1b80d9991b14ca";s:7:"replies";a:1:{i:0;s:32:"2562091dbc47fcc06b1d996148b3e713";}s:4:"show";b:1;s:3:"cid";s:32:"d6be43fd06b46e48d53ae4f1235bccb4";}s:32:"ae96feee91ca517f6b76b73babfcd529";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"gneta";s:4:"name";s:9:"Gila Neta";s:4:"mail";s:20:"netagil@mail.nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1536949758;}s:3:"raw";s:447:"A very interesting project, Lisa! And such an important area: to identify strategies to be able to best tailor interventions to patient needs. Machine learning seems like a very innovative approach to this.  One question, with the caveat that I know quite little about machine learning: Is it possible that the overrides by the physicians can effect the algorithm of the CDS, or will the algorithm be fixed once the CDS is implemented in a trial? ";s:5:"xhtml";s:446:"A very interesting project, Lisa! And such an important area: to identify strategies to be able to best tailor interventions to patient needs. Machine learning seems like a very innovative approach to this.  One question, with the caveat that I know quite little about machine learning: Is it possible that the overrides by the physicians can effect the algorithm of the CDS, or will the algorithm be fixed once the CDS is implemented in a trial?";s:6:"parent";s:32:"cd8668154ae5e28e0402edf10763f5e2";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"ae96feee91ca517f6b76b73babfcd529";}s:32:"2bf37fadf57e2c010f17112922ae105a";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"wnorton";s:4:"name";s:12:"Wynne Norton";s:4:"mail";s:20:"wynne.norton@nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1536949900;}s:3:"raw";s:947:"Good to be thinking about future studies ahead of time!
--I like the two aspects you plan to use for fidelity, and always a good idea to use observation and clinical checklists, when available and feasible.
--Sounds like a nice opportunity to be able to (or try to) measure adaptations as they occur, even if they are mostly made by the MOH vs. your research team. If you keep track of what adaptations are made, when they are made, and why they are made, it could help inform what type of adapted intervention may be most applicable to other sites as you scale to more clinics. 
--Can you add 1-2 booster sessions for training clinicians to enhance fidelity? 
--Do you have access to why adaptations are made by MOH personnel or ability to sit in on those decision-making meetings? Even if you don't have control over the adaptations per se, would be nice to document how/why stakeholders (MOH) are making adaptations and under what conditions. 
";s:5:"xhtml";s:970:"Good to be thinking about future studies ahead of time!<br />--I like the two aspects you plan to use for fidelity, and always a good idea to use observation and clinical checklists, when available and feasible.<br />--Sounds like a nice opportunity to be able to (or try to) measure adaptations as they occur, even if they are mostly made by the MOH vs. your research team. If you keep track of what adaptations are made, when they are made, and why they are made, it could help inform what type of adapted intervention may be most applicable to other sites as you scale to more clinics. <br />--Can you add 1-2 booster sessions for training clinicians to enhance fidelity? <br />--Do you have access to why adaptations are made by MOH personnel or ability to sit in on those decision-making meetings? Even if you don&#039;t have control over the adaptations per se, would be nice to document how/why stakeholders (MOH) are making adaptations and under what conditions.";s:6:"parent";s:32:"017843a132767dd3c692daaf16180fc2";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"2bf37fadf57e2c010f17112922ae105a";}s:32:"d31b7ad9fc98e6e0ce93ef2e9c089ced";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"wnorton";s:4:"name";s:12:"Wynne Norton";s:4:"mail";s:20:"wynne.norton@nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1536950270;}s:3:"raw";s:646:"Thanks Abiola! Just a few comments:
--The intervention is the educational sessions that you propose to hold with the clinical trial team, correct? If possible, you might consider some additional ways to encourage clinical team members to increase engagement in clinical trials. Can you identify a champion or natural opinion leader who could serve as a role model for supporting and endorsing engagement in trial recruitment and participation? 
--Can you clarify how you will be measuring the fidelity with which the intervention is delivered? And what adaptations you plan to make to the intervention? I think I'm a little bit confused. Thanks. ";s:5:"xhtml";s:660:"Thanks Abiola! Just a few comments:<br />--The intervention is the educational sessions that you propose to hold with the clinical trial team, correct? If possible, you might consider some additional ways to encourage clinical team members to increase engagement in clinical trials. Can you identify a champion or natural opinion leader who could serve as a role model for supporting and endorsing engagement in trial recruitment and participation? <br />--Can you clarify how you will be measuring the fidelity with which the intervention is delivered? And what adaptations you plan to make to the intervention? I think I&#039;m a little bit confused. Thanks.";s:6:"parent";s:32:"d3736a399680ad630f37100e17e42753";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"d31b7ad9fc98e6e0ce93ef2e9c089ced";}s:32:"6663bf7530d985d3115f8435aec75261";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"wnorton";s:4:"name";s:12:"Wynne Norton";s:4:"mail";s:20:"wynne.norton@nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1536950460;}s:3:"raw";s:408:"Good! There might be a patient advisory board (larger clinics) that you could consider engaging...they might be a good advocate for the program and be able to make a strong argument for why the clinic should invest the time and money into the program. To the extent that the clinic markets itself as treating the patient with a holistic approach, that could be a hook to get managers on board, too, perhaps. ";s:5:"xhtml";s:407:"Good! There might be a patient advisory board (larger clinics) that you could consider engaging...they might be a good advocate for the program and be able to make a strong argument for why the clinic should invest the time and money into the program. To the extent that the clinic markets itself as treating the patient with a holistic approach, that could be a hook to get managers on board, too, perhaps.";s:6:"parent";s:32:"01898a27cad6cc4a41082d6cc7a8e90d";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"6663bf7530d985d3115f8435aec75261";}s:32:"230a1fdb2c92a55199fcd6b9bf73fb77";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"gneta";s:4:"name";s:9:"Gila Neta";s:4:"mail";s:20:"netagil@mail.nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1536951469;}s:3:"raw";s:551:"Good. And interesting to hear how the intervention was tailored based on fidelity monitoring! In terms of recording calls, will the nurse be blinded to which calls are recorded and monitored, to make sure this doesn't change nurses' behavior?

And glad to see you are thinking about the various ways in which adaptations may be needed. If the format changes substantially, would you assess the relative effectiveness of, for example, in person vs. telephone conversations? And curious which framework might guide the team's thinking about adaptations?";s:5:"xhtml";s:576:"Good. And interesting to hear how the intervention was tailored based on fidelity monitoring! In terms of recording calls, will the nurse be blinded to which calls are recorded and monitored, to make sure this doesn&#039;t change nurses&#039; behavior?<br /><br />And glad to see you are thinking about the various ways in which adaptations may be needed. If the format changes substantially, would you assess the relative effectiveness of, for example, in person vs. telephone conversations? And curious which framework might guide the team&#039;s thinking about adaptations?";s:6:"parent";s:32:"1950d8a8eefe00c695b0278c4623fc90";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"230a1fdb2c92a55199fcd6b9bf73fb77";}s:32:"c6c21dcd9d6e691f6a75baffa6fa1206";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"gneta";s:4:"name";s:9:"Gila Neta";s:4:"mail";s:20:"netagil@mail.nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1536956361;}s:3:"raw";s:906:"Great to see this project, taking advantage of existing primary prevention programs to increase both HIV and breast cancer screening. A few thoughts/questions below...
1) Nice to see you are using two strategies to monitor fidelity, and good to use observation when feasible. Are the checklists you mentioned clinical checklists? If so, great.
2) Will you be able to access data about the adaptations that were already made the MPPI? Understanding the reasons for the MPPI adaptations may be useful when thinking about adaptations to the breast screening intv.
3) In terms of the breast screening adaptations, you have a nice opportunity to try to measure adaptations as they occur. As Wynne noted below, if you keep track of what adaptations are made, when they are made, and why they are made, it could help inform what type of adapted intervention may be most applicable to other sites as you scale up. ";s:5:"xhtml";s:920:"Great to see this project, taking advantage of existing primary prevention programs to increase both HIV and breast cancer screening. A few thoughts/questions below...<br />1) Nice to see you are using two strategies to monitor fidelity, and good to use observation when feasible. Are the checklists you mentioned clinical checklists? If so, great.<br />2) Will you be able to access data about the adaptations that were already made the MPPI? Understanding the reasons for the MPPI adaptations may be useful when thinking about adaptations to the breast screening intv.<br />3) In terms of the breast screening adaptations, you have a nice opportunity to try to measure adaptations as they occur. As Wynne noted below, if you keep track of what adaptations are made, when they are made, and why they are made, it could help inform what type of adapted intervention may be most applicable to other sites as you scale up.";s:6:"parent";s:32:"771ade22d2948a6398c1fc4c1c7b0e31";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"c6c21dcd9d6e691f6a75baffa6fa1206";}s:32:"2562091dbc47fcc06b1d996148b3e713";a:8:{s:4:"user";a:5:{s:2:"id";s:6:"klyons";s:4:"name";s:14:"Kathleen Lyons";s:4:"mail";s:30:"Kathleen.D.Lyons@dartmouth.edu";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1537369280;}s:3:"raw";s:851:"Thank you, Gila, that helps to get me thinking! 
1) Yes, that approach to fidelity is what I've done in my other research. All sessions are recorded so that they don't know which are going to be selected. if they can get comfortable with the recording part that is what I would prefer to do. 
2) I love the idea of developing an algorithm that allows some tailoring in terms of frequency of the call. I've done a similar thing in an exercise study where we use the device data to determine who gets a call, a text, etc. but it never occurred to me to think about tailoring in this application. I will mull it over, thanks for suggesting!
3) I will definitely do some more legwork to see if there is anything out there or if whether the collaborators want to come up with a parallel workbook for patients. Thank you for encouraging me to revisit that. ";s:5:"xhtml";s:880:"Thank you, Gila, that helps to get me thinking! <br />1) Yes, that approach to fidelity is what I&#039;ve done in my other research. All sessions are recorded so that they don&#039;t know which are going to be selected. if they can get comfortable with the recording part that is what I would prefer to do. <br />2) I love the idea of developing an algorithm that allows some tailoring in terms of frequency of the call. I&#039;ve done a similar thing in an exercise study where we use the device data to determine who gets a call, a text, etc. but it never occurred to me to think about tailoring in this application. I will mull it over, thanks for suggesting!<br />3) I will definitely do some more legwork to see if there is anything out there or if whether the collaborators want to come up with a parallel workbook for patients. Thank you for encouraging me to revisit that.";s:6:"parent";s:32:"d6be43fd06b46e48d53ae4f1235bccb4";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"2562091dbc47fcc06b1d996148b3e713";}s:32:"5bf81e7a37b39241336e259f8ea2ca0a";a:8:{s:4:"user";a:5:{s:2:"id";s:6:"klyons";s:4:"name";s:14:"Kathleen Lyons";s:4:"mail";s:30:"Kathleen.D.Lyons@dartmouth.edu";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1537369434;}s:3:"raw";s:5503:"Lyons_Assignment #3a - Models:
1.	Which model or combination of models is most applicable to your proposed study and why?
At this moment, I would like to use an implementation theory and an evaluation framework in my proposal. I would like to use an implementation theory because I need some guidance as to how to actually optimize my intervention for implementation. In my pilot study, I used CFIR to categorize what I was learning from field notes and interviews, but I am leaning away from CFIR and towards an implementation theory because CFIR tells me what to consider but does not tell me what to do (i.e., descriptive but not prescriptive). Incidentally, I have always been slightly daunted by the size of CFIR. I know sometimes people pick and choose aspects of CFIR to focus upon, but then I don’t understand what guides the choosing. This reaction to my limited knowledge of CFIR makes me yearn for a parsimonious implementation theory. From the Martinez et al. paper (2014), I was lead to May’s general theory of implementation. I have not fully digested it yet, but I am motivated to see how it relates to my study (below).

I would also like to use an evaluation framework to structure my thinking about outcomes assessment and make sure I am being thorough. I was initially drawn to RE-AIM but the section about adoption seems less relevant because I am focusing on one site and not a number of practices. The implementation outcomes framework by Proctor et al., 2011 is another article that I had studied in a previous class that seems somewhat accessible and comprehensible, so I am leaning towards trying to use that framework to ensure that I measure some outcomes at the levels of implementation, service, and client.

2.	How might your selected model(s) guide or inform other aspects of your study (e.g., hypotheses, measures, outcomes, processes, selection of strategies, etc.)? 
I feel like the general theory of implementation can help me in two ways: a) help me identify some preliminary work that I can do in advance of the study and b) help focus my implementation efforts on the weak links that the theory helps me to identify. For example, I can do some more pilot work to understand the potential and capacity parts of the theory (to make sure we have selected the right intervention) and then I can target the capability parts of the theory as I identify implementation strategies.

Proctor’s framework of outcomes will guide my selection of outcomes and measures. I can use the resources in the webinar to identify at least 2 relevant measures for each of the implementation, service, and client levels.

Lyons_ Assignment #3b - Measures & Evaluations:
1.	What outcomes (both clinical/system/public health and dissemination/implementation) are you measuring in your study, how are you measuring them, and why are you measuring them?
At this moment, the outcomes I would like to measure are acceptability, appropriateness, microcosts, feasibility, fidelity, and penetration (implementation outcomes); efficiency, safety, patient-centeredness (service outcomes); and symptomatology and healthcare utilization (client outcomes). I have initially selected them from Proctor’s model because I think I can have access to data that allow me evaluate these constructs, whereas some things, like equity, I’m not sure I will be able to obtain information about this. I think they will paint a picture of the degree to which the intervention is able to be implemented in the setting and whether it has a signal of effectiveness for this group.

I’m not going to lie- I am not at all certain which instruments I will adopt to measures these constructs. It seems like it’s going to be my new full-time job to tour the all the websites and articles to weigh the pros and cons of all of the choices. It’s like trying to take a drink from a fire hose right now. I truly appreciate these resources and the enormous work it is taken to synthesize the options, but it’s a lot to sift through. 

2.	What processes are you measuring in your study, how are you measuring them, and why are you measuring them?
In terms of processes, I know that I want to explore the degree to which symptoms are assessed, strategies identified, how they are recommended to patients, and how often the nurses need to communicate with the provider. I see these as communication processes that I might be able to explore within the bounds of fidelity monitoring (either by exploring treatment logs or listening to audio recordings if they decide to allow that). 

3.	Will you be assessing any potential co-benefits or unintended consequences of the implementation? If so, what outcomes will you assess and how will you measure this? If not, why not? 
In our pilot study we did stumble upon a “co-benefit” in the qualitative data: the nurses felt that the phone calls were helpful for people who had symptoms (expected) but they were helpful for everyone whether they had symptoms or not because it clarified when they were supposed to come back for treatment (unexpected co-benefit that was important because they didn’t have a system to remind people by mail or by phone). I’m not exactly sure how in advance to plan to measure unintended consequences or benefits. I imagine they might fall in the realm of healthcare utilization… or efficiency… or symptomatology. I appreciate the prompt to consider possible unintended consequences or co-benefits as I explore various instruments.
";s:5:"xhtml";s:5611:"Lyons_Assignment #3a - Models:<br />1.	Which model or combination of models is most applicable to your proposed study and why?<br />At this moment, I would like to use an implementation theory and an evaluation framework in my proposal. I would like to use an implementation theory because I need some guidance as to how to actually optimize my intervention for implementation. In my pilot study, I used CFIR to categorize what I was learning from field notes and interviews, but I am leaning away from CFIR and towards an implementation theory because CFIR tells me what to consider but does not tell me what to do (i.e., descriptive but not prescriptive). Incidentally, I have always been slightly daunted by the size of CFIR. I know sometimes people pick and choose aspects of CFIR to focus upon, but then I don’t understand what guides the choosing. This reaction to my limited knowledge of CFIR makes me yearn for a parsimonious implementation theory. From the Martinez et al. paper (2014), I was lead to May’s general theory of implementation. I have not fully digested it yet, but I am motivated to see how it relates to my study (below).<br /><br />I would also like to use an evaluation framework to structure my thinking about outcomes assessment and make sure I am being thorough. I was initially drawn to RE-AIM but the section about adoption seems less relevant because I am focusing on one site and not a number of practices. The implementation outcomes framework by Proctor et al., 2011 is another article that I had studied in a previous class that seems somewhat accessible and comprehensible, so I am leaning towards trying to use that framework to ensure that I measure some outcomes at the levels of implementation, service, and client.<br /><br />2.	How might your selected model(s) guide or inform other aspects of your study (e.g., hypotheses, measures, outcomes, processes, selection of strategies, etc.)? <br />I feel like the general theory of implementation can help me in two ways: a) help me identify some preliminary work that I can do in advance of the study and b) help focus my implementation efforts on the weak links that the theory helps me to identify. For example, I can do some more pilot work to understand the potential and capacity parts of the theory (to make sure we have selected the right intervention) and then I can target the capability parts of the theory as I identify implementation strategies.<br /><br />Proctor’s framework of outcomes will guide my selection of outcomes and measures. I can use the resources in the webinar to identify at least 2 relevant measures for each of the implementation, service, and client levels.<br /><br />Lyons_ Assignment #3b - Measures &amp; Evaluations:<br />1.	What outcomes (both clinical/system/public health and dissemination/implementation) are you measuring in your study, how are you measuring them, and why are you measuring them?<br />At this moment, the outcomes I would like to measure are acceptability, appropriateness, microcosts, feasibility, fidelity, and penetration (implementation outcomes); efficiency, safety, patient-centeredness (service outcomes); and symptomatology and healthcare utilization (client outcomes). I have initially selected them from Proctor’s model because I think I can have access to data that allow me evaluate these constructs, whereas some things, like equity, I’m not sure I will be able to obtain information about this. I think they will paint a picture of the degree to which the intervention is able to be implemented in the setting and whether it has a signal of effectiveness for this group.<br /><br />I’m not going to lie- I am not at all certain which instruments I will adopt to measures these constructs. It seems like it’s going to be my new full-time job to tour the all the websites and articles to weigh the pros and cons of all of the choices. It’s like trying to take a drink from a fire hose right now. I truly appreciate these resources and the enormous work it is taken to synthesize the options, but it’s a lot to sift through. <br /><br />2.	What processes are you measuring in your study, how are you measuring them, and why are you measuring them?<br />In terms of processes, I know that I want to explore the degree to which symptoms are assessed, strategies identified, how they are recommended to patients, and how often the nurses need to communicate with the provider. I see these as communication processes that I might be able to explore within the bounds of fidelity monitoring (either by exploring treatment logs or listening to audio recordings if they decide to allow that). <br /><br />3.	Will you be assessing any potential co-benefits or unintended consequences of the implementation? If so, what outcomes will you assess and how will you measure this? If not, why not? <br />In our pilot study we did stumble upon a “co-benefit” in the qualitative data: the nurses felt that the phone calls were helpful for people who had symptoms (expected) but they were helpful for everyone whether they had symptoms or not because it clarified when they were supposed to come back for treatment (unexpected co-benefit that was important because they didn’t have a system to remind people by mail or by phone). I’m not exactly sure how in advance to plan to measure unintended consequences or benefits. I imagine they might fall in the realm of healthcare utilization… or efficiency… or symptomatology. I appreciate the prompt to consider possible unintended consequences or co-benefits as I explore various instruments.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"b6a01a941960b49e439c74b0538867e4";}s:4:"show";b:1;s:3:"cid";s:32:"5bf81e7a37b39241336e259f8ea2ca0a";}s:32:"d82a1b4b58773ae36467c58ed8251efc";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"lreinke";s:4:"name";s:11:"Lynn Reinke";s:4:"mail";s:19:"Lynn.Reinke1@va.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1537484178;}s:3:"raw";s:5118:"Reinke_Assignment #3a – Models

1. Which model or combination of models is most applicable to your proposed study and why?

My study is a hybrid effectiveness/implementation, Type 2 design, to determine the clinical effectiveness of the a palliative care intervention while simultaneously testing implementation strategies in 4 Veterans Integrated Service Networks (VISNs). One model that seems appropriate for this study design is Proctor’s Implementation Framework (Evaluation framework) because it includes both intervention strategies for EBP (nurse-led protocol intervention) and implementation strategies for the environment/context, organizational factors which vary from VA to VA, clinician education of the intervention/delivery model by nurses, supervision (monitoring the intervention delivery) and providers and consumers perspectives (clinicians and patients.)   The 3 major outcome measures of this framework 1. Implementation – e.g. feasibility, acceptability; 2. Service – efficiency, effectiveness and 3. Client outcomes – patient satisfaction, decreased symptom burden will inform the study’s outcomes.  

2. How might your selected model(s) guide or inform other aspects of your study (e.g., hypotheses, measures, outcomes, processes, selection of strategies, etc.)? 
Proctor’s framework will inform the outcomes of the 2 main study aims:
1.	determine the effectiveness of a nurse-led, telephone-based palliative care intervention for patients newly diagnosed with lung cancer on clinical outcomes including quality of life, symptom burden and patient satisfaction of care (Client outcomes) 

2.	Among 4 VISNs, test an implementation strategy of a nurse-led palliative care intervention on provider education, champion engagement, marketing and cost estimates to facilitate adoption, fidelity and sustainability of the palliative care intervention (Implementation and Service.)  

#3b - Measures & Evaluations:

1. What outcomes (both clinical/system/public health and dissemination/implementation) are you measuring in your study, how are you measuring them, and why are you measuring them?

As mention above the effectiveness outcomes are patient-centered - quality of life, symptom burden and patient satisfaction of care. These will be measured using validated surveys (FACT-L and FAMCARE.) These are important to measure to determine if the intervention is effective in larger, more generalized populations across various settings. The outcomes measures for the implementation aim (provider education, champion engagement, marketing and cost estimates to facilitate adoption, fidelity and sustainability of the palliative care intervention) were selected to determine if the EBP will be adopted across the VISN test sites and sustained over time.  “How” to measure the implementation outcomes is an area I need to learn more about.   One thought re: time to deliver the intervention (% of nurses clinical duties) and the cost of nurses FTE to deliver the intervention based on their salaries. This information will be important for leadership buy-in to incorporate this intervention into routine clinical practice. For provider education, pre-post tests can be administered.  


2. What processes are you measuring in your study, how are you measuring them, and why are you measuring them?

In our pilot study we collected several process measures re: protocol adherence, number of recommendations RNs made to MDs that were accepted, the time to conduct the telephone calls, etc., thus I am uncertain if all of these processes need to be measured in this study design. I know it will be important to measure the fidelity of the intervention since the intervention will be adapted depending on the setting and existing infrastructure. I will measure specific implementation approaches such as taking an iterative, bidirectional approach to implementing the intervention at different VA sites by considering contextual variables and soliciting continuous feedback to the implementation process however these measures may translate to outcome measures – it the intervention adopted or not. Suggestions for other process measures is appreciated!


3. Will you be assessing any potential co-benefits or unintended consequences of the implementation? If so, what outcomes will you assess and how will you measure this? If not, why not? 

We will assess if the intervention improves the “timeliness” of patients receiving responses from their providers to their requests, such as suboptimally managed symptoms. We will assess this through patient interviews as well as collecting data from the time a nurse enters a “recommendation note” in the EHR until the time the note is acknowledged and acted upon by the provider. Provider-clinician communication is an important factor of patient-centered care that often goes unmeasured and contributes to patient and family satisfaction with the health care system.  Another potential co-benefit may be the expansion of this lung CA intervention to other highly prevalent cancers in the Veteran population, e.g., head/neck or GI.
";s:5:"xhtml";s:5251:"Reinke_Assignment #3a – Models<br /><br />1. Which model or combination of models is most applicable to your proposed study and why?<br /><br />My study is a hybrid effectiveness/implementation, Type 2 design, to determine the clinical effectiveness of the a palliative care intervention while simultaneously testing implementation strategies in 4 Veterans Integrated Service Networks (VISNs). One model that seems appropriate for this study design is Proctor’s Implementation Framework (Evaluation framework) because it includes both intervention strategies for EBP (nurse-led protocol intervention) and implementation strategies for the environment/context, organizational factors which vary from VA to VA, clinician education of the intervention/delivery model by nurses, supervision (monitoring the intervention delivery) and providers and consumers perspectives (clinicians and patients.)   The 3 major outcome measures of this framework 1. Implementation – e.g. feasibility, acceptability; 2. Service – efficiency, effectiveness and 3. Client outcomes – patient satisfaction, decreased symptom burden will inform the study’s outcomes.  <br /><br />2. How might your selected model(s) guide or inform other aspects of your study (e.g., hypotheses, measures, outcomes, processes, selection of strategies, etc.)? <br />Proctor’s framework will inform the outcomes of the 2 main study aims:<br />1.	determine the effectiveness of a nurse-led, telephone-based palliative care intervention for patients newly diagnosed with lung cancer on clinical outcomes including quality of life, symptom burden and patient satisfaction of care (Client outcomes) <br /><br />2.	Among 4 VISNs, test an implementation strategy of a nurse-led palliative care intervention on provider education, champion engagement, marketing and cost estimates to facilitate adoption, fidelity and sustainability of the palliative care intervention (Implementation and Service.)  <br /><br />#3b - Measures &amp; Evaluations:<br /><br />1. What outcomes (both clinical/system/public health and dissemination/implementation) are you measuring in your study, how are you measuring them, and why are you measuring them?<br /><br />As mention above the effectiveness outcomes are patient-centered - quality of life, symptom burden and patient satisfaction of care. These will be measured using validated surveys (FACT-L and FAMCARE.) These are important to measure to determine if the intervention is effective in larger, more generalized populations across various settings. The outcomes measures for the implementation aim (provider education, champion engagement, marketing and cost estimates to facilitate adoption, fidelity and sustainability of the palliative care intervention) were selected to determine if the EBP will be adopted across the VISN test sites and sustained over time.  “How” to measure the implementation outcomes is an area I need to learn more about.   One thought re: time to deliver the intervention (% of nurses clinical duties) and the cost of nurses FTE to deliver the intervention based on their salaries. This information will be important for leadership buy-in to incorporate this intervention into routine clinical practice. For provider education, pre-post tests can be administered.  <br /><br /><br />2. What processes are you measuring in your study, how are you measuring them, and why are you measuring them?<br /><br />In our pilot study we collected several process measures re: protocol adherence, number of recommendations RNs made to MDs that were accepted, the time to conduct the telephone calls, etc., thus I am uncertain if all of these processes need to be measured in this study design. I know it will be important to measure the fidelity of the intervention since the intervention will be adapted depending on the setting and existing infrastructure. I will measure specific implementation approaches such as taking an iterative, bidirectional approach to implementing the intervention at different VA sites by considering contextual variables and soliciting continuous feedback to the implementation process however these measures may translate to outcome measures – it the intervention adopted or not. Suggestions for other process measures is appreciated!<br /><br /><br />3. Will you be assessing any potential co-benefits or unintended consequences of the implementation? If so, what outcomes will you assess and how will you measure this? If not, why not? <br /><br />We will assess if the intervention improves the “timeliness” of patients receiving responses from their providers to their requests, such as suboptimally managed symptoms. We will assess this through patient interviews as well as collecting data from the time a nurse enters a “recommendation note” in the EHR until the time the note is acknowledged and acted upon by the provider. Provider-clinician communication is an important factor of patient-centered care that often goes unmeasured and contributes to patient and family satisfaction with the health care system.  Another potential co-benefit may be the expansion of this lung CA intervention to other highly prevalent cancers in the Veteran population, e.g., head/neck or GI.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"bb7477cdb83af07b99d421ade11a49eb";}s:4:"show";b:1;s:3:"cid";s:32:"d82a1b4b58773ae36467c58ed8251efc";}s:32:"eb6ff85355433be22964ebbb1682c9cc";a:8:{s:4:"user";a:5:{s:2:"id";s:10:"ldimartino";s:4:"name";s:14:"Lisa DiMartino";s:4:"mail";s:18:"ldimartino@rti.org";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1537542024;}s:3:"raw";s:6641:"DiMartino_Assignment #3a – Models:

1.	Which model or combination of models is most applicable to your proposed study and why?
2.	How might your selected model(s) guide or inform other aspects of your study (e.g., hypotheses, measures, outcomes, processes, selection of strategies, etc.)? 

A pilot test of the CDS tool will be primarily guided a determinant framework, the Theoretical Domains Framework.  This framework has been used extensively to understand the influences of health care provider behavior (e.g. how providers make decisions about adoption of a CDS tool) on implementation outcomes and to develop strategies that could support implementation and address these determinants to ensure patients receive evidence-based care.  For example, the TDF has been used to understand the mechanisms underlying providers’ use of electronic audit and feedback, medication management systems, and clinical decision aids. In addition, although the majority of the TDF domains pertain to individual determinants, two domains pertain specifically to organizational determinants (external environment and social influence), which will allow for measuring multi-level influences of CDS tool implementation.  

The pilot study will also draw on the Proctor et al evaluation framework.  This framework seems applicable because it distinguishes implementation outcomes (e.g. adoption, acceptability, appropriateness, and feasibility) from service and clinical outcomes, and it clearly operationalizes the implementation constructs/measures from the literature that have an underlying theoretical basis.  Although RE-AIM may also be an option, I may not have access to data that would allow for measuring all the RE-AIM domains, particularly maintenance.  I could see using RE-AIM in a multi-site implementation trial of the tool.  Applying the Proctor et al. framework would allow for clarifying if the CDS was ineffective or if it was implemented incorrectly and it also allows for hypothesizing the relationships between implementation and service/clinical outcomes.  

DiMartino_Assignment #3b - Measures & Evaluations:

1.	What outcomes (both clinical/system/public health and dissemination/implementation) are you measuring in your study, how are you measuring them, and why are you measuring them?

A brief survey will be administered to key stakeholders after pilot testing the CDS tool to assess the acceptability, appropriateness and feasibility of the tool.  A 12-item survey developed by Weiner et al. (2017) will be administered to providers at the end of the pilot.  The survey includes 4 items assessing acceptability (Acceptability of Intervention Measure (AIM)), 4 items assessing appropriateness (Intervention Appropriateness Measure (IAM)) and 4 items assessing feasibility.  The psychometric properties of these measures have been previously established.  Each item is scored on a 5-point Likert scale ranging from 1 (strongly disagree) to 5 (strongly agree).  These proximal measured implementation processes are often used in formative evaluations as predictors of future implementation success and can ensure that the tool is developed to optimize fit with the end-user’s preferences prior to assessing the tool in a larger implementation trial.  Adoption, or uptake of the tool will also be an important outcome to assess. This could be measured using EHR data by calculating the number of providers who were exposed to the recommendations generated by the tool, and of those, the number of patients who were referred to receive PC services. Whether implementation of the tool ultimately effects clinical outcomes, such as symptomatology or hospice use among cancer inpatients, would also be examined.  

2.	What processes are you measuring in your study, how are you measuring them, and why are you measuring them?

Processes measured would relate back to the TDF domains and will be measured through semi-structured qualitative interviews with providers in the medical oncology service and other individuals who would potentially interact with the tool (including specialty PC service staff).  For example, the interview guide will elicit information regarding current knowledge about identifying patients who need PC; skills identifying patients who need PC; whether using CDS tools to identify patients who need PC is aligned with health-care professionals’ social/professional role and identity; beliefs about consequences to using a CDS tools to identify patients who need PC; and environmental context and resources for using CDS tools to identifying patients who need PC.  This information will provide the backdrop to understanding barriers and facilitators to healthcare providers’ tool adoption.  

However, I’m not entirely clear if the above truly reflect process measures.  I would also want to know about how any strategies were used in the service along with the tool. As indicated in Module 2, fidelity to the intervention (e.g., whether the provider discussed PC with patients after the reminder was generated) would be important measure, through examining medical charts, self-report of providers or direct observation. The number of patients who received a referral to the PC service from the provider who actually got a PC consult would be another important process to measure.

Will you be assessing any potential co-benefits or unintended consequences of the implementation? If so, what outcomes will you assess and how will you measure this? If not, why not? 

In terms of a potential co-benefit, in my previous research I examined whether triggered palliative care consultation improved the timeliness (service outcome) of consultation.  I was unable to detect any significant findings because most patients received a PC consult fairly early on during hospitalization (within 2 days), but it would be interesting to examining this as an outcome in a larger sample and at other institutions.

In terms of unintended consequences of the tool, it is possible that too many consults are initiated and overwhelm the resources of the PC service.  This is a very real possibility given existing workforce shortages in that profession.  To account for this, as indicated above, I intend to also do interviews with the PC service to understand more about their experience with tool implementation.  Specifically, I would gather process data on whether the service was ever unable to respond to a PC referral due to staff shortages/lack of resources.  I would also ask oncology providers if they ever decided to not make a referral for a specialty PC due to staff shortages/lack of resources.  
";s:5:"xhtml";s:6767:"DiMartino_Assignment #3a – Models:<br /><br />1.	Which model or combination of models is most applicable to your proposed study and why?<br />2.	How might your selected model(s) guide or inform other aspects of your study (e.g., hypotheses, measures, outcomes, processes, selection of strategies, etc.)? <br /><br />A pilot test of the CDS tool will be primarily guided a determinant framework, the Theoretical Domains Framework.  This framework has been used extensively to understand the influences of health care provider behavior (e.g. how providers make decisions about adoption of a CDS tool) on implementation outcomes and to develop strategies that could support implementation and address these determinants to ensure patients receive evidence-based care.  For example, the TDF has been used to understand the mechanisms underlying providers’ use of electronic audit and feedback, medication management systems, and clinical decision aids. In addition, although the majority of the TDF domains pertain to individual determinants, two domains pertain specifically to organizational determinants (external environment and social influence), which will allow for measuring multi-level influences of CDS tool implementation.  <br /><br />The pilot study will also draw on the Proctor et al evaluation framework.  This framework seems applicable because it distinguishes implementation outcomes (e.g. adoption, acceptability, appropriateness, and feasibility) from service and clinical outcomes, and it clearly operationalizes the implementation constructs/measures from the literature that have an underlying theoretical basis.  Although RE-AIM may also be an option, I may not have access to data that would allow for measuring all the RE-AIM domains, particularly maintenance.  I could see using RE-AIM in a multi-site implementation trial of the tool.  Applying the Proctor et al. framework would allow for clarifying if the CDS was ineffective or if it was implemented incorrectly and it also allows for hypothesizing the relationships between implementation and service/clinical outcomes.  <br /><br />DiMartino_Assignment #3b - Measures &amp; Evaluations:<br /><br />1.	What outcomes (both clinical/system/public health and dissemination/implementation) are you measuring in your study, how are you measuring them, and why are you measuring them?<br /><br />A brief survey will be administered to key stakeholders after pilot testing the CDS tool to assess the acceptability, appropriateness and feasibility of the tool.  A 12-item survey developed by Weiner et al. (2017) will be administered to providers at the end of the pilot.  The survey includes 4 items assessing acceptability (Acceptability of Intervention Measure (AIM)), 4 items assessing appropriateness (Intervention Appropriateness Measure (IAM)) and 4 items assessing feasibility.  The psychometric properties of these measures have been previously established.  Each item is scored on a 5-point Likert scale ranging from 1 (strongly disagree) to 5 (strongly agree).  These proximal measured implementation processes are often used in formative evaluations as predictors of future implementation success and can ensure that the tool is developed to optimize fit with the end-user’s preferences prior to assessing the tool in a larger implementation trial.  Adoption, or uptake of the tool will also be an important outcome to assess. This could be measured using EHR data by calculating the number of providers who were exposed to the recommendations generated by the tool, and of those, the number of patients who were referred to receive PC services. Whether implementation of the tool ultimately effects clinical outcomes, such as symptomatology or hospice use among cancer inpatients, would also be examined.  <br /><br />2.	What processes are you measuring in your study, how are you measuring them, and why are you measuring them?<br /><br />Processes measured would relate back to the TDF domains and will be measured through semi-structured qualitative interviews with providers in the medical oncology service and other individuals who would potentially interact with the tool (including specialty PC service staff).  For example, the interview guide will elicit information regarding current knowledge about identifying patients who need PC; skills identifying patients who need PC; whether using CDS tools to identify patients who need PC is aligned with health-care professionals’ social/professional role and identity; beliefs about consequences to using a CDS tools to identify patients who need PC; and environmental context and resources for using CDS tools to identifying patients who need PC.  This information will provide the backdrop to understanding barriers and facilitators to healthcare providers’ tool adoption.  <br /><br />However, I’m not entirely clear if the above truly reflect process measures.  I would also want to know about how any strategies were used in the service along with the tool. As indicated in Module 2, fidelity to the intervention (e.g., whether the provider discussed PC with patients after the reminder was generated) would be important measure, through examining medical charts, self-report of providers or direct observation. The number of patients who received a referral to the PC service from the provider who actually got a PC consult would be another important process to measure.<br /><br />Will you be assessing any potential co-benefits or unintended consequences of the implementation? If so, what outcomes will you assess and how will you measure this? If not, why not? <br /><br />In terms of a potential co-benefit, in my previous research I examined whether triggered palliative care consultation improved the timeliness (service outcome) of consultation.  I was unable to detect any significant findings because most patients received a PC consult fairly early on during hospitalization (within 2 days), but it would be interesting to examining this as an outcome in a larger sample and at other institutions.<br /><br />In terms of unintended consequences of the tool, it is possible that too many consults are initiated and overwhelm the resources of the PC service.  This is a very real possibility given existing workforce shortages in that profession.  To account for this, as indicated above, I intend to also do interviews with the PC service to understand more about their experience with tool implementation.  Specifically, I would gather process data on whether the service was ever unable to respond to a PC referral due to staff shortages/lack of resources.  I would also ask oncology providers if they ever decided to not make a referral for a specialty PC due to staff shortages/lack of resources.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"f1dca38429923b681f76a4a5d31468ee";}s:4:"show";b:1;s:3:"cid";s:32:"eb6ff85355433be22964ebbb1682c9cc";}s:32:"00726a03a6cceaf39c0b0fca8682cd06";a:8:{s:4:"user";a:5:{s:2:"id";s:8:"khuggins";s:4:"name";s:12:"Kate Huggins";s:4:"mail";s:23:"kate.huggins@monash.edu";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1537707173;}s:3:"raw";s:654:"Thanks Wynne. Yes I agree that a random selection of the recordings is going to be most practical. We havean enourmous amount of recorded material now and it doesn't seem like a good use of resources to transcribe them all. The modeling analyses will be a combination of Poisson or negative binomial regression depending on the data form and distribution. E.g We will build a multiple regression model (Poisson or negative binomial regression dependent on the data distribution) that predicts the number of sessions completed by the participant with the research dietitian. We will use the model building approach described by Hosmer and Lemeshow (2013).";s:5:"xhtml";s:659:"Thanks Wynne. Yes I agree that a random selection of the recordings is going to be most practical. We havean enourmous amount of recorded material now and it doesn&#039;t seem like a good use of resources to transcribe them all. The modeling analyses will be a combination of Poisson or negative binomial regression depending on the data form and distribution. E.g We will build a multiple regression model (Poisson or negative binomial regression dependent on the data distribution) that predicts the number of sessions completed by the participant with the research dietitian. We will use the model building approach described by Hosmer and Lemeshow (2013).";s:6:"parent";s:32:"ddff19282a459762a6fe2ade6cdd65d9";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"00726a03a6cceaf39c0b0fca8682cd06";}s:32:"7dcdf7ee37ee89e2a0c0880e6044f43e";a:8:{s:4:"user";a:5:{s:2:"id";s:8:"khuggins";s:4:"name";s:12:"Kate Huggins";s:4:"mail";s:23:"kate.huggins@monash.edu";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1537707350;}s:3:"raw";s:3896:"Huggins_Assignment 3

1.	As identified in earlier posts, my study is best characterised as a Type 1 hybrid effectiveness- implementation design. Therefore then next step from this study, assuming effectiveness is demonstrated, would be to implement the nutrition intervention more broadly and into the health care setting rather than the research setting. Therefore I have selected models that I think are useful in the design of implementation studies. By doing this I hope that I will collect relevant data from the current study to develop a strong implementation strategy. There are two determinant frameworks that I will explore for this: The Consolidated Framework for Implementation Research and the i-PARIHS framework. 

CFIR - because it can guide a formative evaluation of the implementation knowledge i-PARIHS – As it’s targeted for Health Services.
Finally I will use Rogers Diffusion of Innovation Theory to guide dissemination after the RCT is complete. This will include dissemination of both the effectiveness outcomes (i.e health outcomes), as well as the implementation outcomes.

2.	Both CFIR and i-PARIHS consider the context and the process. It is expected that by using these frameworks to guide data collection and interpretation of the findings this will inform the plan for the implementation process. 

Assignment #3b - Measures & Evaluations:
1.	The primary outcome is health-related quality of life. A cost-effectiveness evaluation will also be undertaken by converting to quality-adjusted life years. Health-related quality of life is a patient-reported outcome, which we consider a better indicator of effectiveness than the specific nutrition assessment outcomes. Thus, anthropometric measures are secondary outcomes in this study. 
Implementation outcomes include: i) assessing characteristics of the nutrition intervention to identify adaptations that are tolerated – measured through content analysis of audio recorded nutrition consultations (phone group) and through the written communication (mHealth group); and ii) assessing the readiness of the ‘actors’ who may impact the success or failure of implementation (the people receiving the nutrition intervention, the health professionals and the health service providers) – measured through semi-structured interviews. These are being measured to develop the implementation strategy across broader settings.

2.	An important process to measure will be the referral process from the surgeon/oncologist to the dietetics team to initiate the nutrition intervention. This is important in the RCT, and will also need to be monitored in the broader implementation
The reach at the patient level will analysed by: 
a)	the number of eligible participants who actually consented into the study vs. declined;
b)	the number of participants who consented into the study and commenced the intervention; 
c)	the number of participants who consented into the study and completed.

The reach at the health professional level will be analysed by:
a)	tracking the number of patients who were suitable for referral but were not referred; 
b)	if the time between diagnosis and commencement of nutrition intervention is reduced (i.e compared with the control in the RCT);
c)	exploring the perceptions of health professionals to determine if they believe that the evidence-practice gap is getting smaller (this informs acceptance and readiness for adoption).

3.	A potential co-benefit is improved communication between the surgeons/oncologists and the dietetics team. I hadn’t thought about assessing this specifically but could consider having questions related to communication in the semi-structured interviews and then conduct some interviews prior to implementation and then later after the intervention has been implemented. This could be triangulated with the data on referrals as described in item 2 above.

";s:5:"xhtml";s:4018:"Huggins_Assignment 3<br /><br />1.	As identified in earlier posts, my study is best characterised as a Type 1 hybrid effectiveness- implementation design. Therefore then next step from this study, assuming effectiveness is demonstrated, would be to implement the nutrition intervention more broadly and into the health care setting rather than the research setting. Therefore I have selected models that I think are useful in the design of implementation studies. By doing this I hope that I will collect relevant data from the current study to develop a strong implementation strategy. There are two determinant frameworks that I will explore for this: The Consolidated Framework for Implementation Research and the i-PARIHS framework. <br /><br />CFIR - because it can guide a formative evaluation of the implementation knowledge i-PARIHS – As it’s targeted for Health Services.<br />Finally I will use Rogers Diffusion of Innovation Theory to guide dissemination after the RCT is complete. This will include dissemination of both the effectiveness outcomes (i.e health outcomes), as well as the implementation outcomes.<br /><br />2.	Both CFIR and i-PARIHS consider the context and the process. It is expected that by using these frameworks to guide data collection and interpretation of the findings this will inform the plan for the implementation process. <br /><br />Assignment #3b - Measures &amp; Evaluations:<br />1.	The primary outcome is health-related quality of life. A cost-effectiveness evaluation will also be undertaken by converting to quality-adjusted life years. Health-related quality of life is a patient-reported outcome, which we consider a better indicator of effectiveness than the specific nutrition assessment outcomes. Thus, anthropometric measures are secondary outcomes in this study. <br />Implementation outcomes include: i) assessing characteristics of the nutrition intervention to identify adaptations that are tolerated – measured through content analysis of audio recorded nutrition consultations (phone group) and through the written communication (mHealth group); and ii) assessing the readiness of the ‘actors’ who may impact the success or failure of implementation (the people receiving the nutrition intervention, the health professionals and the health service providers) – measured through semi-structured interviews. These are being measured to develop the implementation strategy across broader settings.<br /><br />2.	An important process to measure will be the referral process from the surgeon/oncologist to the dietetics team to initiate the nutrition intervention. This is important in the RCT, and will also need to be monitored in the broader implementation<br />The reach at the patient level will analysed by: <br />a)	the number of eligible participants who actually consented into the study vs. declined;<br />b)	the number of participants who consented into the study and commenced the intervention; <br />c)	the number of participants who consented into the study and completed.<br /><br />The reach at the health professional level will be analysed by:<br />a)	tracking the number of patients who were suitable for referral but were not referred; <br />b)	if the time between diagnosis and commencement of nutrition intervention is reduced (i.e compared with the control in the RCT);<br />c)	exploring the perceptions of health professionals to determine if they believe that the evidence-practice gap is getting smaller (this informs acceptance and readiness for adoption).<br /><br />3.	A potential co-benefit is improved communication between the surgeons/oncologists and the dietetics team. I hadn’t thought about assessing this specifically but could consider having questions related to communication in the semi-structured interviews and then conduct some interviews prior to implementation and then later after the intervention has been implemented. This could be triangulated with the data on referrals as described in item 2 above.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"483d368291c99113a9babfe0047e8bf9";}s:4:"show";b:1;s:3:"cid";s:32:"7dcdf7ee37ee89e2a0c0880e6044f43e";}s:32:"05f748362d110269df4e9ae6003154f4";a:8:{s:4:"user";a:5:{s:2:"id";s:10:"moluwasanu";s:4:"name";s:18:"Mojisola Oluwasanu";s:4:"mail";s:15:"ope3m@yahoo.com";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:2:{s:7:"created";i:1537725778;s:8:"modified";i:1538125171;}s:3:"raw";s:6450:"Oluwasanu_Assignment #3a - Models
1.	Which model or combination of models is most applicable to your proposed study and why? How might your selected model(s) guide or inform other aspects of your study (e.g., hypotheses, measures, outcomes, processes, selection of strategies, etc.)? 
The Practical, Robust Implementation and Sustainability Model (PRISM) is suitable for the proposed study. I had earlier proposed the RE-AIM framework but this model does not address all constructs pertinent to this study. The proposed study is a hybrid effectiveness/implementation trial, type I design which is designed to investigate the effect of two evidence-based interventions for the delivery of an integrated, multi-component HIV and breast cancer intervention. Both interventions (HIV and Breast cancer) are evidence based. However, there is limited information on (1) the suitability of the Breast cancer intervention for the Nigerian setting and (2) the effect of the integrated approach. Hence, it is important to use a model/framework which has constructs for the effectiveness trial and IR components of this study. The PRISM is suitable because it has constructs that succinctly captures information on the adaptation of the  Breast cancer intervention to the Nigeria setting, acceptability of the intervention by the artisans, the context i.e. the socio-cultural, political, organizational and economic characteristics of the association/network of artisans and how it influences the intervention, the complexity and workload of the integrated approach considering that artisans/laypersons will be trained to deliver the intervention, roles of diverse stakeholders from the ministries of health, women affairs, trades and industry and the artisan groups. Other important construct outlined by the PRISM which I find very useful for this study include the readiness, characteristics and needs of women who belong to the artisan groups. The model provides opportunities to measures the client outcomes (i.e. age-appropriate screening for BC), service outcomes (i.e. provider’s workload, quality of services, facilitators and barriers etc) and implementation outcomes. It also captures information on the reach, implementation and maintenance/sustainability of the intervention. I think it is a comprehensive model which will guide the development of the hypotheses, selection of study outcomes,  implementation of strategies and evaluation.

Oluwasanu_Assignment #3b - Measures & Evaluations:
1.	What outcomes (both clinical/system/public health and dissemination/implementation) are you measuring in your study, how are you measuring them, and why are you measuring them? What processes are you measuring in your study, how are you measuring them, and why are you measuring them? 
For this study, I will measure the client, service and implementation outcomes.

Client outcomes:
The key client outcomes are breast cancer knowledge, preventive behaviors and utilization of age-appropriate breast cancer screening services. Other client outcomes are subjective norms and attitudes regarding these diseases, fatalism and cultural factors associated with BC screening, perceived behavioural control to adopt HIV and BC preventive practices, self efficacy and behavioural intentions to screen for HIV and BC. 

The Breast Cancer Awareness Measure (Breast CAM) toolkit of the Cancer Research UK will be adapted and used to assess these client outcome measures. Information on breast cancer screening will be complemented with data from referral forms and service statistics collected at designated primary and secondary healthcare facilities.  Information will be obtained at three time points: baseline (T0), immediately post intervention (T1) and 24 months after the intervention (T2).

Service outcomes will be measured and include:
i)	Quality of information and services and clients’ satisfaction with BC information and BC screening services will be assessed using semi-structured questionnaires which will be completed by the artisans at (T1) and (T2).
ii)	Barriers and facilitators for BC information and service provision

Implementation outcomes:
i)	Acceptability and feasibility will be measured through focus group discussions/key informant interviews with the various stakeholders (beneficiaries, artisans trained as peer influencers, leaders of the artisan associations and officials of ministries of health, women affairs and trades) and semi-structured questionnaires. Indicators include number of artisans trained as peer influencers/leaders to provide information and referral services for HIV and breast cancer screening; Proportion of trained artisans/peer influencers skilled in the provision of integrated HIV and BC information and service, Proportion of artisans referred and screened for BC.

ii)	Adoption will be assessed using administrative data/records and key informant interviews with leaders of the trade associations. Key indicator is the proportion of artisan groups which commence the implementation of  the integrated HIV and BC intervention  
iii)	Sustainability will be assessed using checklist and key informant interviews with leaders of the trade associations. Key indicator is the proportion of artisan groups which continue to implement the integrated HIV and BC intervention  24 months post- intervention.

 
Process Measure	
A process measure for the study is Fidelity/Adaptation. This will be measured through self-report, observations and audio recording of selected sessions and assessment of adherence using a checklist .Measures of fidelity which will be assessed are: number of training sessions held using the stipulated curricula, duration of the training sessions, No. of participants (artisans) who attend at least 90% of the sessions, quality of engagement of participants and feedback etc. A complementary approach will be the live observations of some selected training sessions (especially sessions which require the transfer of skills for breast health examination).

2.	Will you be assessing any potential co-benefits or unintended consequences of the implementation? If so, what outcomes will you assess and how will you measure this? If not, why not? 
	 Provider’s workload  is a potential negative consequence of the integration and will be measured through focus group discussion. In addition, another unintended consequence is the potential adverse effects on either of the services.

";s:5:"xhtml";s:6592:"Oluwasanu_Assignment #3a - Models<br />1.	Which model or combination of models is most applicable to your proposed study and why? How might your selected model(s) guide or inform other aspects of your study (e.g., hypotheses, measures, outcomes, processes, selection of strategies, etc.)? <br />The Practical, Robust Implementation and Sustainability Model (PRISM) is suitable for the proposed study. I had earlier proposed the RE-AIM framework but this model does not address all constructs pertinent to this study. The proposed study is a hybrid effectiveness/implementation trial, type I design which is designed to investigate the effect of two evidence-based interventions for the delivery of an integrated, multi-component HIV and breast cancer intervention. Both interventions (HIV and Breast cancer) are evidence based. However, there is limited information on (1) the suitability of the Breast cancer intervention for the Nigerian setting and (2) the effect of the integrated approach. Hence, it is important to use a model/framework which has constructs for the effectiveness trial and IR components of this study. The PRISM is suitable because it has constructs that succinctly captures information on the adaptation of the  Breast cancer intervention to the Nigeria setting, acceptability of the intervention by the artisans, the context i.e. the socio-cultural, political, organizational and economic characteristics of the association/network of artisans and how it influences the intervention, the complexity and workload of the integrated approach considering that artisans/laypersons will be trained to deliver the intervention, roles of diverse stakeholders from the ministries of health, women affairs, trades and industry and the artisan groups. Other important construct outlined by the PRISM which I find very useful for this study include the readiness, characteristics and needs of women who belong to the artisan groups. The model provides opportunities to measures the client outcomes (i.e. age-appropriate screening for BC), service outcomes (i.e. provider’s workload, quality of services, facilitators and barriers etc) and implementation outcomes. It also captures information on the reach, implementation and maintenance/sustainability of the intervention. I think it is a comprehensive model which will guide the development of the hypotheses, selection of study outcomes,  implementation of strategies and evaluation.<br /><br />Oluwasanu_Assignment #3b - Measures &amp; Evaluations:<br />1.	What outcomes (both clinical/system/public health and dissemination/implementation) are you measuring in your study, how are you measuring them, and why are you measuring them? What processes are you measuring in your study, how are you measuring them, and why are you measuring them? <br />For this study, I will measure the client, service and implementation outcomes.<br /><br />Client outcomes:<br />The key client outcomes are breast cancer knowledge, preventive behaviors and utilization of age-appropriate breast cancer screening services. Other client outcomes are subjective norms and attitudes regarding these diseases, fatalism and cultural factors associated with BC screening, perceived behavioural control to adopt HIV and BC preventive practices, self efficacy and behavioural intentions to screen for HIV and BC. <br /><br />The Breast Cancer Awareness Measure (Breast CAM) toolkit of the Cancer Research UK will be adapted and used to assess these client outcome measures. Information on breast cancer screening will be complemented with data from referral forms and service statistics collected at designated primary and secondary healthcare facilities.  Information will be obtained at three time points: baseline (T0), immediately post intervention (T1) and 24 months after the intervention (T2).<br /><br />Service outcomes will be measured and include:<br />i)	Quality of information and services and clients’ satisfaction with BC information and BC screening services will be assessed using semi-structured questionnaires which will be completed by the artisans at (T1) and (T2).<br />ii)	Barriers and facilitators for BC information and service provision<br /><br />Implementation outcomes:<br />i)	Acceptability and feasibility will be measured through focus group discussions/key informant interviews with the various stakeholders (beneficiaries, artisans trained as peer influencers, leaders of the artisan associations and officials of ministries of health, women affairs and trades) and semi-structured questionnaires. Indicators include number of artisans trained as peer influencers/leaders to provide information and referral services for HIV and breast cancer screening; Proportion of trained artisans/peer influencers skilled in the provision of integrated HIV and BC information and service, Proportion of artisans referred and screened for BC.<br /><br />ii)	Adoption will be assessed using administrative data/records and key informant interviews with leaders of the trade associations. Key indicator is the proportion of artisan groups which commence the implementation of  the integrated HIV and BC intervention  <br />iii)	Sustainability will be assessed using checklist and key informant interviews with leaders of the trade associations. Key indicator is the proportion of artisan groups which continue to implement the integrated HIV and BC intervention  24 months post- intervention.<br /><br /> <br />Process Measure	<br />A process measure for the study is Fidelity/Adaptation. This will be measured through self-report, observations and audio recording of selected sessions and assessment of adherence using a checklist .Measures of fidelity which will be assessed are: number of training sessions held using the stipulated curricula, duration of the training sessions, No. of participants (artisans) who attend at least 90% of the sessions, quality of engagement of participants and feedback etc. A complementary approach will be the live observations of some selected training sessions (especially sessions which require the transfer of skills for breast health examination).<br /><br />2.	Will you be assessing any potential co-benefits or unintended consequences of the implementation? If so, what outcomes will you assess and how will you measure this? If not, why not? <br />	 Provider’s workload  is a potential negative consequence of the integration and will be measured through focus group discussion. In addition, another unintended consequence is the potential adverse effects on either of the services.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"825625a8b67c2518124e47cc7726e8c0";}s:4:"show";b:1;s:3:"cid";s:32:"05f748362d110269df4e9ae6003154f4";}s:32:"d8424ae6845d3dc485d3b951fa1aecb2";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"lpace";s:4:"name";s:10:"Lydia Pace";s:4:"mail";s:21:"LPACE@BWH.HARVARD.EDU";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1537730633;}s:3:"raw";s:7535:"
Pace – assignment 3
Assignment #3a - Models:

1) Which model or combination of models is most applicable to your proposed study and why?

This proposed project is primarily focused on implementation, and focuses on system, community and organization-level aspects of implementation (though does assess learning in individuals as well). I think the RE-AIM model is particularly applicable. I think how Glasgow et al conceptualize implementation is very meaningful – we are trying to figure out how to “do” breast cancer early detection or screening in a real-world, low-income setting. Further, we are taking a resource-intensive pilot project and scaling it up to 2 additional districts, adapted to a limited budget. So we need to look at outcomes that are meaningful in that context. 
How I interpret the dimensions of RE-AIM for this study:
-Reach - since we are evaluating the scale-up of our breast cancer early detection model to 2 new districts, it will be important to describe the number of health centers and provider involved, and number of women who received clinical breast exam (CBE). 
-Efficacy – I’m a little confused about how Glasgow et al see “efficacy” in implementation studies/ projects, since “efficacy” primarily pertains to the evidence-based intervention that is being implemented, right? In our proposed study, I think I’m not LOOKING at efficacy (but effectiveness), and our knowledge of the efficacy of screening CBE in a setting without screening mammography is limited.
-Adoption – proportion of health centers that had regular breast (and cervical) clinics. I’m not sure whether “acceptability” or perceived facilitators/ barriers and perceived feasibility of the intervention from the provider standpoint would fit here, or under implementation, or whether this is a domain not well-captured in RE-AIM.
-Implementation – effectiveness of the intervention. We’ll look at how well providers are doing in providing CBE (through our mentorship visits and observation checklists) and how much their knowledge improved. We’ll also look at patient referrals, cancer detection rates, loss-to-follow-up and times to diagnosis (though we don’t have an ideal control group necessarily). 
-Maintenance – we’ll do delayed post-tests and can look at results from mentorship months after the training. We should also look at adoption of the intervention one year after initial trainings (eg how often are the supposedly weekly breast/ cervical cancer screening clinics happening).

2.  How might your selected model(s) guide or inform other aspects of your study (e.g., hypotheses, measures, outcomes, processes, selection of strategies, etc.)? 

The RE-AIM model is helping me think more about maintenance, and how to define and examine that issue. It is also helping me think more formally about how we define “effectiveness” in our context.

Assignment #3b - Measures & Evaluations:

1. What outcomes (both clinical/system/public health and dissemination/implementation) are you measuring in your study, how are you measuring them, and why are you measuring them?
Outcomes, data source, and rationale:
a. Nurses’ knowledge about breast health, breast cancer, and service availability; source: assessed using pre-training, immediate post-training and delayed-post training written assessments. Rationale: demonstrating effectiveness of training in improving knowledge is important component of its overall effectiveness; we also can compare results to our pilot

b. Nurses’ comfort with CBE and breast care; source: pre-training, immediate post-training, and delayed post-training written assessments; Rationale: demonstrating nurses’ comfort is also important dimension of intervention effectiveness
		
c. Nurses CBE skills; source: supervisors’ observation with standardized checklists before and immediately after the training as well as during clinical mentorship; rationale: demonstrating effectiveness of training in improving CBE skills is important component of its overall effectiveness as well as quality of CBE performed; we also can compare results to our pilot

d. Average number of patients/ month referred from the district hospital to referral facilities; source: Patient navigator; rationale: understanding health system impact.  Challenge is that we don’t know the “ideal” number

e. Proportion of patients referred to the district hospital who ultimately received biopsies, and where a pathology result is available; source: Patient navigator; rationale: understanding cancer detection rate and LTFU

f. Proportion of patients referred to the DH diagnosed with cancer; source: Patient navigator; rationale: to identify cancer detection rate (can compare to pilot and other settings)

2. What processes are you measuring in your study, how are you measuring them, and why are you measuring them?

a. Nurses’ perceived barriers to implementing breast clinics and breast care; source: delayed post-training written assessments; rationale: nurses’ perceptions are important to identify in terms of understanding health system barriers

b. Average number of patients/ month seen per health center for breast concerns after the intervention; source: health center registries and/ or breast documentation forms; rationale: will give sense of impact of intervention on patient volume and health system burden (again, not sure of ideal, or feasible, number)

c. Average number of referrals to the district hospital/ month for breast concerns from a trained health center after the intervention; source: health center breast documentation forms; rationale: will give sense of impact of intervention on patient volume and health system burden. We can also compare referral rates to other settings.

d. Proportion of weeks that a weekly breast clinic was held at the health centers and the district hospitals; source: health center and district hospital focal point records; rationale: adoption of intervention

e. Average number of patients/ month seen for breast concerns at the district hospital; source: district hospital focal point records; rationale: health system burden

f. Among patient who received biopsies, number of weeks from first district hospital visit to pathology report date; source: district hospital records/ pathology records/ patient navigator; rationale: Effectiveness and timeliness of patient navigation and referral pathways

g. Among patients who received biopsies and initiated treatment for breast cancer, number of weeks from first district hospital visit to cancer treatment initiation date; source: district hospital records/ BCCOE records/ patient navigator; rationale: same as above	

h. Proportion of patients seen at DH who have diagnostic resolution (given definitive diagnosis or discharged); source: district hospital records/ patient navigator; rationale: same as above

3. Will you be assessing any potential co-benefits or unintended consequences of the implementation? If so, what outcomes will you assess and how will you measure this? If not, why not? 
Unintended consequences – we will look at false positive rates. It would be ideal to also look at the impact of this new health service on delivery of OTHER health services (opportunity cost of the intervention) but I’m not sure how to do that. Would also be great to examine patients’ perspectives of co-benefits and unintended consequences (and overall satisfaction) but I’m not currently planning that (though with funding, could).
";s:5:"xhtml";s:7797:"Pace – assignment 3<br />Assignment #3a - Models:<br /><br />1) Which model or combination of models is most applicable to your proposed study and why?<br /><br />This proposed project is primarily focused on implementation, and focuses on system, community and organization-level aspects of implementation (though does assess learning in individuals as well). I think the RE-AIM model is particularly applicable. I think how Glasgow et al conceptualize implementation is very meaningful – we are trying to figure out how to “do” breast cancer early detection or screening in a real-world, low-income setting. Further, we are taking a resource-intensive pilot project and scaling it up to 2 additional districts, adapted to a limited budget. So we need to look at outcomes that are meaningful in that context. <br />How I interpret the dimensions of RE-AIM for this study:<br />-Reach - since we are evaluating the scale-up of our breast cancer early detection model to 2 new districts, it will be important to describe the number of health centers and provider involved, and number of women who received clinical breast exam (CBE). <br />-Efficacy – I’m a little confused about how Glasgow et al see “efficacy” in implementation studies/ projects, since “efficacy” primarily pertains to the evidence-based intervention that is being implemented, right? In our proposed study, I think I’m not LOOKING at efficacy (but effectiveness), and our knowledge of the efficacy of screening CBE in a setting without screening mammography is limited.<br />-Adoption – proportion of health centers that had regular breast (and cervical) clinics. I’m not sure whether “acceptability” or perceived facilitators/ barriers and perceived feasibility of the intervention from the provider standpoint would fit here, or under implementation, or whether this is a domain not well-captured in RE-AIM.<br />-Implementation – effectiveness of the intervention. We’ll look at how well providers are doing in providing CBE (through our mentorship visits and observation checklists) and how much their knowledge improved. We’ll also look at patient referrals, cancer detection rates, loss-to-follow-up and times to diagnosis (though we don’t have an ideal control group necessarily). <br />-Maintenance – we’ll do delayed post-tests and can look at results from mentorship months after the training. We should also look at adoption of the intervention one year after initial trainings (eg how often are the supposedly weekly breast/ cervical cancer screening clinics happening).<br /><br />2.  How might your selected model(s) guide or inform other aspects of your study (e.g., hypotheses, measures, outcomes, processes, selection of strategies, etc.)? <br /><br />The RE-AIM model is helping me think more about maintenance, and how to define and examine that issue. It is also helping me think more formally about how we define “effectiveness” in our context.<br /><br />Assignment #3b - Measures &amp; Evaluations:<br /><br />1. What outcomes (both clinical/system/public health and dissemination/implementation) are you measuring in your study, how are you measuring them, and why are you measuring them?<br />Outcomes, data source, and rationale:<br />a. Nurses’ knowledge about breast health, breast cancer, and service availability; source: assessed using pre-training, immediate post-training and delayed-post training written assessments. Rationale: demonstrating effectiveness of training in improving knowledge is important component of its overall effectiveness; we also can compare results to our pilot<br /><br />b. Nurses’ comfort with CBE and breast care; source: pre-training, immediate post-training, and delayed post-training written assessments; Rationale: demonstrating nurses’ comfort is also important dimension of intervention effectiveness<br />		<br />c. Nurses CBE skills; source: supervisors’ observation with standardized checklists before and immediately after the training as well as during clinical mentorship; rationale: demonstrating effectiveness of training in improving CBE skills is important component of its overall effectiveness as well as quality of CBE performed; we also can compare results to our pilot<br /><br />d. Average number of patients/ month referred from the district hospital to referral facilities; source: Patient navigator; rationale: understanding health system impact.  Challenge is that we don’t know the “ideal” number<br /><br />e. Proportion of patients referred to the district hospital who ultimately received biopsies, and where a pathology result is available; source: Patient navigator; rationale: understanding cancer detection rate and LTFU<br /><br />f. Proportion of patients referred to the DH diagnosed with cancer; source: Patient navigator; rationale: to identify cancer detection rate (can compare to pilot and other settings)<br /><br />2. What processes are you measuring in your study, how are you measuring them, and why are you measuring them?<br /><br />a. Nurses’ perceived barriers to implementing breast clinics and breast care; source: delayed post-training written assessments; rationale: nurses’ perceptions are important to identify in terms of understanding health system barriers<br /><br />b. Average number of patients/ month seen per health center for breast concerns after the intervention; source: health center registries and/ or breast documentation forms; rationale: will give sense of impact of intervention on patient volume and health system burden (again, not sure of ideal, or feasible, number)<br /><br />c. Average number of referrals to the district hospital/ month for breast concerns from a trained health center after the intervention; source: health center breast documentation forms; rationale: will give sense of impact of intervention on patient volume and health system burden. We can also compare referral rates to other settings.<br /><br />d. Proportion of weeks that a weekly breast clinic was held at the health centers and the district hospitals; source: health center and district hospital focal point records; rationale: adoption of intervention<br /><br />e. Average number of patients/ month seen for breast concerns at the district hospital; source: district hospital focal point records; rationale: health system burden<br /><br />f. Among patient who received biopsies, number of weeks from first district hospital visit to pathology report date; source: district hospital records/ pathology records/ patient navigator; rationale: Effectiveness and timeliness of patient navigation and referral pathways<br /><br />g. Among patients who received biopsies and initiated treatment for breast cancer, number of weeks from first district hospital visit to cancer treatment initiation date; source: district hospital records/ BCCOE records/ patient navigator; rationale: same as above	<br /><br />h. Proportion of patients seen at DH who have diagnostic resolution (given definitive diagnosis or discharged); source: district hospital records/ patient navigator; rationale: same as above<br /><br />3. Will you be assessing any potential co-benefits or unintended consequences of the implementation? If so, what outcomes will you assess and how will you measure this? If not, why not? <br />Unintended consequences – we will look at false positive rates. It would be ideal to also look at the impact of this new health service on delivery of OTHER health services (opportunity cost of the intervention) but I’m not sure how to do that. Would also be great to examine patients’ perspectives of co-benefits and unintended consequences (and overall satisfaction) but I’m not currently planning that (though with funding, could).";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"225b57be185702fff6f9c9e76a04ea67";}s:4:"show";b:1;s:3:"cid";s:32:"d8424ae6845d3dc485d3b951fa1aecb2";}s:32:"9485aaa6e6f30e2edfd6fe983a7d7551";a:8:{s:4:"user";a:5:{s:2:"id";s:8:"kschmitz";s:4:"name";s:15:"Kathryn Schmitz";s:4:"mail";s:20:"kschmitz@phs.psu.edu";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1537735172;}s:3:"raw";s:8671:"Schmitz. Assignment #3a - Models:
1.	Which model or combination of models is most applicable to your proposed study and why?
The RE-AIM model appears to be a good fit for the ENACT Implementation trial, as the overarching goal of this line of research relates to the first element of the model:  Reach.  The majority of cancer patients are not currently connected to any type of exercise programming and it is of high interest to the investigator group to measurably improve this outcome.  In addition, because the intervention was shown to be effective within the setting of research performed in an academic medical center, there is value to demonstrating effectiveness when the staffing model and setting are both altered (nursing, community oncology centers).  Adoption is a key variable for the success of the ENACT program as well:  we know that when we embed an exercise professional directly into a chemo infusion suite, the program is taken up by clinicians, staff, and patients.  But when the interventionists are nurses, who may see delivery of the intervention as a burden beyond their current job responsibilities, it is unclear how well adoption will go.  Evaluation and comparison of multiple methods to improve adoption could be tested as part of the implementation project.  Evaluation of the fidelity of Implementation is key for the ENACT program, to ensure both effectiveness and safety are maintained in a new setting, with new staff.  The evaluation of maintenance is unclear to our investigative team.  It is suggested that evaluations of maintenance be over a 2 year period, but that this is ‘arbitrary’.  We seek feedback on whether it would be of value to evaluate the sustainability (maintenance) of the intervention in the new setting and with new staff one year after the program is ENACTed .
In addition, to evaluate the process of implementation, there are specific elements from the CFIR model that would appear to be particularly useful:  planning, engagement, and reflecting and evaluation.  Each of these process measures will be evaluated as well.

2.	How might your selected model(s) guide or inform other aspects of your study (e.g., hypotheses, measures, outcomes, processes, selection of strategies, etc.)?
In the concept paper, the primary aim was stated to be: To successfully implement an exercise intervention program (ENACT) within the setting of chemotherapy infusion suites of community oncology clinics.  This likely stays intact.
However, the secondary aims and hypotheses will likely shift to evaluate each of the elements of the RE-AIM framework, as well as the process constructs from CFIR.

Schmitz Assignment #3b - Measures & Evaluations:
1.	What outcomes (both clinical/system/public health and dissemination/implementation) are you measuring in your study, how are you measuring them, and why are you measuring them?
REACH will be assessed using the Penetration index (Woltmann 2008).  This is a key construct for the evaluation framework to be used for the project, and a key outcome for the goal of the research.
EFFECTIVENESS will be evaluated using the 30 second chair stand, a physical activity survey (Paffenbarger)  and a 20 item PROMIS survey recommended for use in this population.  These are important outcomes to establish that the intervention maintains effectiveness in the new setting, with new staff.
ACCEPTABILITY will be measured using Henninger’s ‘Acceptability of intervention measure’ pre and post, which was designed specifically for RE-AIM evaluations.  We measure this to discern whether the nurses and other clinicians and staff in the community oncology find the intervention to be acceptable within the context of the community oncology clinic.
ADOPTION will be measured using the REAIM adoption calculator (Detwaltowski 2004).  This is a key construct in the REAIM framework and key to documenting success of the implementation study.
FEASIBILITY will be assessed using the Measure of Disseminability tool (Trent 2010), because it is the measure of feasibility that appears to embody the most favorable internal and structural consistency and usability, according to the SCIR instrument review.  Measurement of feasibility is needed to understand whether variability in successful implementation can be explained by this construct.
COST will be assessed the Treatment Cost Analysis Tool (Flynn 2009) and the, as it appears to be the cost tool most relevant to the project under development.  This measure is vital to convince other practices that the intervention can be enacted within current cost structures (or not).
PENETRATION will be assessed using the Levels of Institutionalization Scales for Health Promotion Programs (Goodman 1993).  This instrument will allow evaluation of the extent to which the program becomes embedded in the production, maintenance, supportive, and managerial subsystems of the organization. 
MAINTENANCE (SUSTAINABILITY) will be measured using the program sustainability assessment tool (Center for Public Health System Science 2012).  This is a key construct in the REAIM framework.
PARTICIPANTS’ SATISFACTION with the intervention will be measured at the end of the intervention period using 3 items from the Experience of Care and Health Outcomes Survey (ECHO). Participants will rate the following items on a 5-point Likert scale (from “not at all” to “very much so”): 1) How satisfied were you with the intervention you received; 2) Did you find the intervention to be helpful; and 3) Did you find the intervention to be worthwhile?  This is among the IOM recommended measures to determine health care quality and satisfaction.
2.	What processes are you measuring in your study, how are you measuring them, and why are you measuring them?
** I found the readings on this to be scant.  Additional readings on PROCESS MEASURES would be great ***
We will measure three process measures, though each may have sub-measures.  They include planning, engagement, and reflecting and evaluating.  Each of these constructs have been evaluated to be central to implementation success and included as key process elements of the CFIR model.
PLANNING will be assessed using measures of stakeholder needs and perspectives, data collection on contextual factors that would suggest value to tailoring the implementation strategy for a given clinic, including altering the style and approach for nursing education, identification of appropriate communication channels, setting goals and tracking progress, and the use of a ‘dry run’ or incremental implementation approach before full scale implementation. (Question:  are there formal measures for these?  I could not find them.)
ENGAGEMENT.  We will look for ‘first users’ or obvious implementation leaders within each clinic.  We will note whether the clinic has an implementation ‘champion’ and whether that champion was volunteered versus appointed, formally named or ‘de facto’ appointed.   We will record the presence of opinion leaders, champions, external change agents, or formal implementation leaders.  The results for outcome measures will be evaluated according to these engagement factors for clinics. 
REFLECTING AND EVALUATION will take the form of qualitative data collection.  Semi-structured interviews with nurses, clinic staff, physicians, and any other members of the clinic personnel who will have influenced the implementation process.  This will be accomplishe using the staff of the Health Services Behavioral Research team at Penn State. The interviews will take place at least 6 months into the full implementation at a given clinic.
3.	Will you be assessing any potential co-benefits or unintended consequences of the implementation? If so, what outcomes will you assess and how will you measure this? If not, why not?
Co-benefits to be assessed will include 1) adherence to other Evidence based practices for clinical care during chemotherapy, assessed using the Penetration index for key EBPs yet to be identified.  This will be assessed to discern whether the new program sensitizes the clinical staff to adoption of other EBPs. 2) physical activity levels of the clinic staff, as delivery of physical activity programming may become an intervention in and of itself.  Physical activity will be assessed using a valid, reliable survey (Paffenbarger).
Unintended consequences to be assessed will include injuries or adverse events among patients.  This will be assessed as it has been in all of Dr. Schmitz’ prior studies (standardized reporting and intervention system, debrief,  and intervention alterations to prevent future adverse events).
";s:5:"xhtml";s:8814:"Schmitz. Assignment #3a - Models:<br />1.	Which model or combination of models is most applicable to your proposed study and why?<br />The RE-AIM model appears to be a good fit for the ENACT Implementation trial, as the overarching goal of this line of research relates to the first element of the model:  Reach.  The majority of cancer patients are not currently connected to any type of exercise programming and it is of high interest to the investigator group to measurably improve this outcome.  In addition, because the intervention was shown to be effective within the setting of research performed in an academic medical center, there is value to demonstrating effectiveness when the staffing model and setting are both altered (nursing, community oncology centers).  Adoption is a key variable for the success of the ENACT program as well:  we know that when we embed an exercise professional directly into a chemo infusion suite, the program is taken up by clinicians, staff, and patients.  But when the interventionists are nurses, who may see delivery of the intervention as a burden beyond their current job responsibilities, it is unclear how well adoption will go.  Evaluation and comparison of multiple methods to improve adoption could be tested as part of the implementation project.  Evaluation of the fidelity of Implementation is key for the ENACT program, to ensure both effectiveness and safety are maintained in a new setting, with new staff.  The evaluation of maintenance is unclear to our investigative team.  It is suggested that evaluations of maintenance be over a 2 year period, but that this is ‘arbitrary’.  We seek feedback on whether it would be of value to evaluate the sustainability (maintenance) of the intervention in the new setting and with new staff one year after the program is ENACTed .<br />In addition, to evaluate the process of implementation, there are specific elements from the CFIR model that would appear to be particularly useful:  planning, engagement, and reflecting and evaluation.  Each of these process measures will be evaluated as well.<br /><br />2.	How might your selected model(s) guide or inform other aspects of your study (e.g., hypotheses, measures, outcomes, processes, selection of strategies, etc.)?<br />In the concept paper, the primary aim was stated to be: To successfully implement an exercise intervention program (ENACT) within the setting of chemotherapy infusion suites of community oncology clinics.  This likely stays intact.<br />However, the secondary aims and hypotheses will likely shift to evaluate each of the elements of the RE-AIM framework, as well as the process constructs from CFIR.<br /><br />Schmitz Assignment #3b - Measures &amp; Evaluations:<br />1.	What outcomes (both clinical/system/public health and dissemination/implementation) are you measuring in your study, how are you measuring them, and why are you measuring them?<br />REACH will be assessed using the Penetration index (Woltmann 2008).  This is a key construct for the evaluation framework to be used for the project, and a key outcome for the goal of the research.<br />EFFECTIVENESS will be evaluated using the 30 second chair stand, a physical activity survey (Paffenbarger)  and a 20 item PROMIS survey recommended for use in this population.  These are important outcomes to establish that the intervention maintains effectiveness in the new setting, with new staff.<br />ACCEPTABILITY will be measured using Henninger’s ‘Acceptability of intervention measure’ pre and post, which was designed specifically for RE-AIM evaluations.  We measure this to discern whether the nurses and other clinicians and staff in the community oncology find the intervention to be acceptable within the context of the community oncology clinic.<br />ADOPTION will be measured using the REAIM adoption calculator (Detwaltowski 2004).  This is a key construct in the REAIM framework and key to documenting success of the implementation study.<br />FEASIBILITY will be assessed using the Measure of Disseminability tool (Trent 2010), because it is the measure of feasibility that appears to embody the most favorable internal and structural consistency and usability, according to the SCIR instrument review.  Measurement of feasibility is needed to understand whether variability in successful implementation can be explained by this construct.<br />COST will be assessed the Treatment Cost Analysis Tool (Flynn 2009) and the, as it appears to be the cost tool most relevant to the project under development.  This measure is vital to convince other practices that the intervention can be enacted within current cost structures (or not).<br />PENETRATION will be assessed using the Levels of Institutionalization Scales for Health Promotion Programs (Goodman 1993).  This instrument will allow evaluation of the extent to which the program becomes embedded in the production, maintenance, supportive, and managerial subsystems of the organization. <br />MAINTENANCE (SUSTAINABILITY) will be measured using the program sustainability assessment tool (Center for Public Health System Science 2012).  This is a key construct in the REAIM framework.<br />PARTICIPANTS’ SATISFACTION with the intervention will be measured at the end of the intervention period using 3 items from the Experience of Care and Health Outcomes Survey (ECHO). Participants will rate the following items on a 5-point Likert scale (from “not at all” to “very much so”): 1) How satisfied were you with the intervention you received; 2) Did you find the intervention to be helpful; and 3) Did you find the intervention to be worthwhile?  This is among the IOM recommended measures to determine health care quality and satisfaction.<br />2.	What processes are you measuring in your study, how are you measuring them, and why are you measuring them?<br />** I found the readings on this to be scant.  Additional readings on PROCESS MEASURES would be great ***<br />We will measure three process measures, though each may have sub-measures.  They include planning, engagement, and reflecting and evaluating.  Each of these constructs have been evaluated to be central to implementation success and included as key process elements of the CFIR model.<br />PLANNING will be assessed using measures of stakeholder needs and perspectives, data collection on contextual factors that would suggest value to tailoring the implementation strategy for a given clinic, including altering the style and approach for nursing education, identification of appropriate communication channels, setting goals and tracking progress, and the use of a ‘dry run’ or incremental implementation approach before full scale implementation. (Question:  are there formal measures for these?  I could not find them.)<br />ENGAGEMENT.  We will look for ‘first users’ or obvious implementation leaders within each clinic.  We will note whether the clinic has an implementation ‘champion’ and whether that champion was volunteered versus appointed, formally named or ‘de facto’ appointed.   We will record the presence of opinion leaders, champions, external change agents, or formal implementation leaders.  The results for outcome measures will be evaluated according to these engagement factors for clinics. <br />REFLECTING AND EVALUATION will take the form of qualitative data collection.  Semi-structured interviews with nurses, clinic staff, physicians, and any other members of the clinic personnel who will have influenced the implementation process.  This will be accomplishe using the staff of the Health Services Behavioral Research team at Penn State. The interviews will take place at least 6 months into the full implementation at a given clinic.<br />3.	Will you be assessing any potential co-benefits or unintended consequences of the implementation? If so, what outcomes will you assess and how will you measure this? If not, why not?<br />Co-benefits to be assessed will include 1) adherence to other Evidence based practices for clinical care during chemotherapy, assessed using the Penetration index for key EBPs yet to be identified.  This will be assessed to discern whether the new program sensitizes the clinical staff to adoption of other EBPs. 2) physical activity levels of the clinic staff, as delivery of physical activity programming may become an intervention in and of itself.  Physical activity will be assessed using a valid, reliable survey (Paffenbarger).<br />Unintended consequences to be assessed will include injuries or adverse events among patients.  This will be assessed as it has been in all of Dr. Schmitz’ prior studies (standardized reporting and intervention system, debrief,  and intervention alterations to prevent future adverse events).";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"292ea58049682535d5521225dc77763e";}s:4:"show";b:1;s:3:"cid";s:32:"9485aaa6e6f30e2edfd6fe983a7d7551";}s:32:"87a7e1694392fa1fb687f53011317cf2";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"gneta";s:4:"name";s:9:"Gila Neta";s:4:"mail";s:20:"netagil@mail.nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1537979173;}s:3:"raw";s:714:"Hi Lydia, I'm just catching up on earlier threads and wanted to chime in here to address your question about generating hypotheses. I think it might help to hone in on a specific barrier and consider what the literature says about how best to overcome that barrier. Wynne's suggestion to look to other areas of health may be incredibly helpful here. One thing to keep in mind in implementation science is that the idea is to generate generalizable knowledge about implementation. So while you are addressing a problem in a specific context/setting, there may be lessons learned that can apply beyond, and similarly, the literature in other contexts/settings may help inform your study. I hope this helps a little. ";s:5:"xhtml";s:723:"Hi Lydia, I&#039;m just catching up on earlier threads and wanted to chime in here to address your question about generating hypotheses. I think it might help to hone in on a specific barrier and consider what the literature says about how best to overcome that barrier. Wynne&#039;s suggestion to look to other areas of health may be incredibly helpful here. One thing to keep in mind in implementation science is that the idea is to generate generalizable knowledge about implementation. So while you are addressing a problem in a specific context/setting, there may be lessons learned that can apply beyond, and similarly, the literature in other contexts/settings may help inform your study. I hope this helps a little.";s:6:"parent";s:32:"9fc6437d9a00380a70900947c9194d49";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"87a7e1694392fa1fb687f53011317cf2";}s:32:"b6a01a941960b49e439c74b0538867e4";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"gneta";s:4:"name";s:9:"Gila Neta";s:4:"mail";s:20:"netagil@mail.nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1538067856;}s:3:"raw";s:1210:"Very nicely done and well thought through. And a very good question you raise about CFIR and what guides decisions about its use. I think, ideally, these decisions would be guided by the study question(s). So not all constructs may be relevant to the questions at hand. 
In terms of your choice of theories/models/frameworks: If you haven't already looked at the http://dissemination-implementation.org/ website, you may find it helpful in selecting an appropriate one. Based on your interest in measuring acceptability, feasibility, fidelity, and costs, PRISM also may be one to consider in addition to May's. But there may be others. And May's theory could fit, but I'm curious why you think it may be helpful beyond it's being parsimonious. 
In terms of your outcomes, it's great you are thinking about the multiple levels of implementation. But you may want to consider honing in on fewer outcomes. The more outcomes you try to measure, the harder it will be to measure them well. It think that once you hone in on your specific research questions about implementation, and what specific barriers you are trying to overcome, this can help you focus your selection of implementation outcomes, specifically. ";s:5:"xhtml";s:1249:"Very nicely done and well thought through. And a very good question you raise about CFIR and what guides decisions about its use. I think, ideally, these decisions would be guided by the study question(s). So not all constructs may be relevant to the questions at hand. <br />In terms of your choice of theories/models/frameworks: If you haven&#039;t already looked at the http://dissemination-implementation.org/ website, you may find it helpful in selecting an appropriate one. Based on your interest in measuring acceptability, feasibility, fidelity, and costs, PRISM also may be one to consider in addition to May&#039;s. But there may be others. And May&#039;s theory could fit, but I&#039;m curious why you think it may be helpful beyond it&#039;s being parsimonious. <br />In terms of your outcomes, it&#039;s great you are thinking about the multiple levels of implementation. But you may want to consider honing in on fewer outcomes. The more outcomes you try to measure, the harder it will be to measure them well. It think that once you hone in on your specific research questions about implementation, and what specific barriers you are trying to overcome, this can help you focus your selection of implementation outcomes, specifically.";s:6:"parent";s:32:"5bf81e7a37b39241336e259f8ea2ca0a";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"b6a01a941960b49e439c74b0538867e4";}s:32:"bb7477cdb83af07b99d421ade11a49eb";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"gneta";s:4:"name";s:9:"Gila Neta";s:4:"mail";s:20:"netagil@mail.nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1538069059;}s:3:"raw";s:741:"Good! Nice to see you are focusing on the multiple levels and service outcomes for your hybrid study. And great that you are thinking about implementation outcomes that will drive buy-in by decision makers.
One limitation of Proctor's framework for your aim #2, to test an implementation strategy, is that it doesn't provide guidance on factors that may influence whether and how a strategy works, so it may be hard to determine what factors to measure to understand what may be influencing implementation success, beyond or related to the strategy you are testing. While this doesn't rule out using Proctor's framework, you may consider supplementing with an additional theory to understand how and/or why the strategy may or may not work.
";s:5:"xhtml";s:765:"Good! Nice to see you are focusing on the multiple levels and service outcomes for your hybrid study. And great that you are thinking about implementation outcomes that will drive buy-in by decision makers.<br />One limitation of Proctor&#039;s framework for your aim #2, to test an implementation strategy, is that it doesn&#039;t provide guidance on factors that may influence whether and how a strategy works, so it may be hard to determine what factors to measure to understand what may be influencing implementation success, beyond or related to the strategy you are testing. While this doesn&#039;t rule out using Proctor&#039;s framework, you may consider supplementing with an additional theory to understand how and/or why the strategy may or may not work.";s:6:"parent";s:32:"d82a1b4b58773ae36467c58ed8251efc";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"bb7477cdb83af07b99d421ade11a49eb";}s:32:"f1dca38429923b681f76a4a5d31468ee";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"gneta";s:4:"name";s:9:"Gila Neta";s:4:"mail";s:20:"netagil@mail.nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1538069964;}s:3:"raw";s:906:"Nicely done! Your selection and justification for your theories/models/frameworks is clear and well thought through. And nice that you have taken advantage of the plethora of models to select the ones you need for the purposes they serve. It's common to see proposals select more than one since these models/theories/frameworks often do not address all questions we seek to answer. 
One thing to keep in mind in your selection is that you don't have to measure everything in a given framework, so if you did want to use RE-AIM, that doesn't mean you have to measure all five dimensions, as long as you justify why you are using something and why you are measuring something (or not measuring something, as the case may be.)
And great to see you're taking advantage of existing instruments to measure your implementation outcomes. Have you also considered exit interviews with patients to assess adoption? 
";s:5:"xhtml";s:934:"Nicely done! Your selection and justification for your theories/models/frameworks is clear and well thought through. And nice that you have taken advantage of the plethora of models to select the ones you need for the purposes they serve. It&#039;s common to see proposals select more than one since these models/theories/frameworks often do not address all questions we seek to answer. <br />One thing to keep in mind in your selection is that you don&#039;t have to measure everything in a given framework, so if you did want to use RE-AIM, that doesn&#039;t mean you have to measure all five dimensions, as long as you justify why you are using something and why you are measuring something (or not measuring something, as the case may be.)<br />And great to see you&#039;re taking advantage of existing instruments to measure your implementation outcomes. Have you also considered exit interviews with patients to assess adoption?";s:6:"parent";s:32:"eb6ff85355433be22964ebbb1682c9cc";s:7:"replies";a:1:{i:0;s:32:"713781e5f56020ac0712e98e01563657";}s:4:"show";b:1;s:3:"cid";s:32:"f1dca38429923b681f76a4a5d31468ee";}s:32:"2df1c4c9faf07ddb495d00d02940d662";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"gneta";s:4:"name";s:9:"Gila Neta";s:4:"mail";s:20:"netagil@mail.nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:2:{s:7:"created";i:1538075769;s:8:"modified";i:1538079137;}s:3:"raw";s:1:"
";s:5:"xhtml";s:0:"";s:6:"parent";N;s:7:"replies";a:0:{}s:4:"show";b:0;s:3:"cid";s:32:"2df1c4c9faf07ddb495d00d02940d662";}s:32:"292ea58049682535d5521225dc77763e";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"gneta";s:4:"name";s:9:"Gila Neta";s:4:"mail";s:20:"netagil@mail.nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1538079123;}s:3:"raw";s:267:"Good. One thought: CFIR as a determinants framework might also be helpful to think about not just processes but also measures that might influence your implementation outcomes, so inputs you may want to measure and include in your analyses evaluating your strategies.";s:5:"xhtml";s:267:"Good. One thought: CFIR as a determinants framework might also be helpful to think about not just processes but also measures that might influence your implementation outcomes, so inputs you may want to measure and include in your analyses evaluating your strategies.";s:6:"parent";s:32:"9485aaa6e6f30e2edfd6fe983a7d7551";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"292ea58049682535d5521225dc77763e";}s:32:"483d368291c99113a9babfe0047e8bf9";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"gneta";s:4:"name";s:9:"Gila Neta";s:4:"mail";s:20:"netagil@mail.nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1538148541;}s:3:"raw";s:393:"Nice job. And interesting point you raise about the potential knock on benefit of improving communication among teams. It will be interesting to see what key issues with implementation will arise from the hybrid 1. It might be helpful to look to similar types of studies to see what sorts of barriers were identified, that might help you narrow your focus on collecting data on implementation.";s:5:"xhtml";s:393:"Nice job. And interesting point you raise about the potential knock on benefit of improving communication among teams. It will be interesting to see what key issues with implementation will arise from the hybrid 1. It might be helpful to look to similar types of studies to see what sorts of barriers were identified, that might help you narrow your focus on collecting data on implementation.";s:6:"parent";s:32:"7dcdf7ee37ee89e2a0c0880e6044f43e";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"483d368291c99113a9babfe0047e8bf9";}s:32:"225b57be185702fff6f9c9e76a04ea67";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"gneta";s:4:"name";s:9:"Gila Neta";s:4:"mail";s:20:"netagil@mail.nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1538148831;}s:3:"raw";s:687:"Nicely done and well described. Regarding the REAIM constructs, the E is for effectiveness of the intervention, so collecting outcomes on whether the intervention has the intended health effect. And regarding your question about acceptability and barriers, I think these make sense to understand in the context of the adoption construct as those may be determinants of adoption. The Implementation construct is really about fidelity to the intervention at the setting level: "implementation refers to the intervention agents’ fidelity to the various elements of an intervention’s protocol. This includes consistency of delivery as intended and the time and cost of the intervention."";s:5:"xhtml";s:697:"Nicely done and well described. Regarding the REAIM constructs, the E is for effectiveness of the intervention, so collecting outcomes on whether the intervention has the intended health effect. And regarding your question about acceptability and barriers, I think these make sense to understand in the context of the adoption construct as those may be determinants of adoption. The Implementation construct is really about fidelity to the intervention at the setting level: &quot;implementation refers to the intervention agents’ fidelity to the various elements of an intervention’s protocol. This includes consistency of delivery as intended and the time and cost of the intervention.&quot;";s:6:"parent";s:32:"d8424ae6845d3dc485d3b951fa1aecb2";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"225b57be185702fff6f9c9e76a04ea67";}s:32:"e6ff2db7679e6dc68c3af58fb56d682f";a:8:{s:4:"user";a:5:{s:2:"id";s:9:"aibraheem";s:4:"name";s:15:"Abiola Ibraheem";s:4:"mail";s:35:"aibraheem@medicine.bsd.uchicago.edu";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1538188212;}s:3:"raw";s:5559:"Ibraheem Assignment 3

Increasing awareness to clinical trial to Clinical trial in Nigeria. 

I had so many discussions in the background and I really do understand that my proposed research work is not totally implementing an evidence-based medicine into clinical practice but probably a program into clinical practice. 
Going back to understanding barriers to enrolling clinical trials especially within the minority group and now with my pilot study- there seemed to be some very peculiar similarities1, 2. 
Therefore I have somewhat changed my research work to a proper implementation project which still implementing an evidence-based program into clinical practice in Nigeria. 


Which model or combination of models is most applicable to your proposed study and why? I will use the Active implementation Framework also known as the Core Implementation Component framework Fixsen et al. (2005) to facilitate the feasibility studies implementation process.  This is because the critical component of this design is the inclusion of team members who play a critical role in multiple levels of the program implementation, known as purveyors. A purveyor teams is a “group of individuals representing a program or practice that actively work to implement an evidence-based program with fidelity and good effect” to guide their efforts. This is particularly useful if a new concept such as “oncology clinical trials” is going to be inducted into the Nigerian healthcare system. The use of a group of individuals known to the system and trusted by their other colleagues is very useful. The purveyor team will consist of a representative of all relevant healthcare professionals that is physicians (oncologist, surgeon and family medicine), nurses, pharmacists, lab technician, clerk, and pathologist. The purveyor will be the communication link between the source (information about clinical trials) and the destination (health care providers within that organization). 
The purveyor team in this framework was selected based on their expertise in various range of functions but since there is no expertise in oncology clinical trials in Nigeria, the team will be selected due to their willingness, their involvement in infectious disease clinical trial, champion or natural opinion leader who could serve as a role model for supporting and endorsing engagement in trial recruitment and participation, referral basis by team members. After selection of team members, they will undergo training about increasing awareness of their peers to clinical trials and also how to deliver the concept of clinical trials to their focus groups. The training will be tailored according to their education level. This is culturally important because a front desk clerk can sometimes be more believable by the patients as opposed to their physicians. 



2. How might your selected model(s) guide or inform other aspects of your study (e.g., hypotheses, measures, outcomes, processes, selection of strategies, etc.)?

It will inform my hypothesis that is increasing awareness of health care providers to the presence of clinical trials by (i) increase in the pre and post survey basic questionnaires about their understanding of clinical trials (ii) knowledge of the clinical trial referral system in place, (iii) responsiveness to the clinical trial referral team. 
Of note the clinical trial referral team is not part of the purveyor team, the clinical trial team is the part staff who are the data managers, the trial coordinators, clinical trial nurses, investigators/sub-investigators etc trained and paid to manage patients on study 



Assignment 3b

1.	What outcomes (both clinical/system/public health and dissemination/implementation) are you measuring in your study, how are you measuring them, and why are you measuring them? 
As highlighted above, the outcomes are measured by an increase in knowledge, referral of new patients to the clinical trial team. This will be measured by the number of newly eligible patients referred to the clinical trial team. For example, for our index neoadjuvant trial in early stage (non-metastatic) HER2 breast cancer, we will measure the number of these patients referred to the clinical trial team by assessing new intakes. I will measure this to assess the effect of our purveyors. 

2.What processes are you measuring in your study, how are you measuring them, and why are you measuring them? 
I will measure the delivery of intervention components, the compliance of the healthcare providers, feedback from the healthcare providers and the purveyor team. 


2.	Will you be assessing any potential co-benefits or unintended consequences of the implementation? If so, what outcomes will you assess and how will you measure this? If not, why not?
Co-benefits- Meeting the target of my accrual plan and also improvement of (i) patient navigation system, (ii) a change in clinical practice, for example, the increased use of breast cancer receptor subtyping in clinical practice. 




1. Kaluzny A, Brawley O, Garson-Angert D, et al. Assuring access to state-of-the-art care for US minority populations: the first 2 years of the Minority-Based Community Clinical Oncology Program. JNCI: Journal of the National Cancer Institute. 1993;85: 1945-1950.
2. McCaskill-Stevens W, Pinto H, Marcus AC, et al. Recruiting minority cancer patients into cancer clinical trials: a pilot project involving the Eastern Cooperative Oncology Group and the National Medical Association. Journal of Clinical Oncology. 1999;17: 1029-1029.

";s:5:"xhtml";s:5742:"Ibraheem Assignment 3<br /><br />Increasing awareness to clinical trial to Clinical trial in Nigeria. <br /><br />I had so many discussions in the background and I really do understand that my proposed research work is not totally implementing an evidence-based medicine into clinical practice but probably a program into clinical practice. <br />Going back to understanding barriers to enrolling clinical trials especially within the minority group and now with my pilot study- there seemed to be some very peculiar similarities1, 2. <br />Therefore I have somewhat changed my research work to a proper implementation project which still implementing an evidence-based program into clinical practice in Nigeria. <br /><br /><br />Which model or combination of models is most applicable to your proposed study and why? I will use the Active implementation Framework also known as the Core Implementation Component framework Fixsen et al. (2005) to facilitate the feasibility studies implementation process.  This is because the critical component of this design is the inclusion of team members who play a critical role in multiple levels of the program implementation, known as purveyors. A purveyor teams is a “group of individuals representing a program or practice that actively work to implement an evidence-based program with fidelity and good effect” to guide their efforts. This is particularly useful if a new concept such as “oncology clinical trials” is going to be inducted into the Nigerian healthcare system. The use of a group of individuals known to the system and trusted by their other colleagues is very useful. The purveyor team will consist of a representative of all relevant healthcare professionals that is physicians (oncologist, surgeon and family medicine), nurses, pharmacists, lab technician, clerk, and pathologist. The purveyor will be the communication link between the source (information about clinical trials) and the destination (health care providers within that organization). <br />The purveyor team in this framework was selected based on their expertise in various range of functions but since there is no expertise in oncology clinical trials in Nigeria, the team will be selected due to their willingness, their involvement in infectious disease clinical trial, champion or natural opinion leader who could serve as a role model for supporting and endorsing engagement in trial recruitment and participation, referral basis by team members. After selection of team members, they will undergo training about increasing awareness of their peers to clinical trials and also how to deliver the concept of clinical trials to their focus groups. The training will be tailored according to their education level. This is culturally important because a front desk clerk can sometimes be more believable by the patients as opposed to their physicians. <br /><br /><br /><br />2. How might your selected model(s) guide or inform other aspects of your study (e.g., hypotheses, measures, outcomes, processes, selection of strategies, etc.)?<br /><br />It will inform my hypothesis that is increasing awareness of health care providers to the presence of clinical trials by (i) increase in the pre and post survey basic questionnaires about their understanding of clinical trials (ii) knowledge of the clinical trial referral system in place, (iii) responsiveness to the clinical trial referral team. <br />Of note the clinical trial referral team is not part of the purveyor team, the clinical trial team is the part staff who are the data managers, the trial coordinators, clinical trial nurses, investigators/sub-investigators etc trained and paid to manage patients on study <br /><br /><br /><br />Assignment 3b<br /><br />1.	What outcomes (both clinical/system/public health and dissemination/implementation) are you measuring in your study, how are you measuring them, and why are you measuring them? <br />As highlighted above, the outcomes are measured by an increase in knowledge, referral of new patients to the clinical trial team. This will be measured by the number of newly eligible patients referred to the clinical trial team. For example, for our index neoadjuvant trial in early stage (non-metastatic) HER2 breast cancer, we will measure the number of these patients referred to the clinical trial team by assessing new intakes. I will measure this to assess the effect of our purveyors. <br /><br />2.What processes are you measuring in your study, how are you measuring them, and why are you measuring them? <br />I will measure the delivery of intervention components, the compliance of the healthcare providers, feedback from the healthcare providers and the purveyor team. <br /><br /><br />2.	Will you be assessing any potential co-benefits or unintended consequences of the implementation? If so, what outcomes will you assess and how will you measure this? If not, why not?<br />Co-benefits- Meeting the target of my accrual plan and also improvement of (i) patient navigation system, (ii) a change in clinical practice, for example, the increased use of breast cancer receptor subtyping in clinical practice. <br /><br /><br /><br /><br />1. Kaluzny A, Brawley O, Garson-Angert D, et al. Assuring access to state-of-the-art care for US minority populations: the first 2 years of the Minority-Based Community Clinical Oncology Program. JNCI: Journal of the National Cancer Institute. 1993;85: 1945-1950.<br />2. McCaskill-Stevens W, Pinto H, Marcus AC, et al. Recruiting minority cancer patients into cancer clinical trials: a pilot project involving the Eastern Cooperative Oncology Group and the National Medical Association. Journal of Clinical Oncology. 1999;17: 1029-1029.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"f99457f489d4f23281390d3aa5bc72fb";}s:4:"show";b:1;s:3:"cid";s:32:"e6ff2db7679e6dc68c3af58fb56d682f";}s:32:"dc057fe59fe989b7eb5d25fdd6edbaca";a:8:{s:4:"user";a:5:{s:2:"id";s:8:"kschmitz";s:4:"name";s:15:"Kathryn Schmitz";s:4:"mail";s:20:"kschmitz@phs.psu.edu";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1538419005;}s:3:"raw";s:1379:"Lesson 4 schmitz

1.	What is your proposed study design? Why is that the best design to answer your research questions or hypotheses?
A Hybrid type 2 Stepped Wedge Cluster Randomized Trial design is proposed.  There are several reasons why this proposed design as the ‘best’ to answer the research question of interest.  First, this approach allows all sites to receive training and to deliver the intervention to their patients during the study period.  Second, the rollout design makes it more feasible to carry out the implementation and evaluation of the implementation (fewer sites to study at a given time).   Finally, we will balance our interest in the implementation outcome (fidelity) with our interest in effectiveness (function).
2.	Will you be incorporating a mixed methods design into your study? If so, what approach will you use to incorporate the qualitative data into the study (e.g., integrate the quantitative and qualitative data to inform your aims? If not, why?
Yes, we will incorporate mixed methods into the study.  We will incorporate qualitative data collection before (exploratory) and after (explanatory) the quantitative data collection.  This will allow us to explore the qualitative characteristics of each clinical site that appear to be associated with implementation success, as well as explaining the quantitative data regarding fidelity.
";s:5:"xhtml";s:1403:"Lesson 4 schmitz<br /><br />1.	What is your proposed study design? Why is that the best design to answer your research questions or hypotheses?<br />A Hybrid type 2 Stepped Wedge Cluster Randomized Trial design is proposed.  There are several reasons why this proposed design as the ‘best’ to answer the research question of interest.  First, this approach allows all sites to receive training and to deliver the intervention to their patients during the study period.  Second, the rollout design makes it more feasible to carry out the implementation and evaluation of the implementation (fewer sites to study at a given time).   Finally, we will balance our interest in the implementation outcome (fidelity) with our interest in effectiveness (function).<br />2.	Will you be incorporating a mixed methods design into your study? If so, what approach will you use to incorporate the qualitative data into the study (e.g., integrate the quantitative and qualitative data to inform your aims? If not, why?<br />Yes, we will incorporate mixed methods into the study.  We will incorporate qualitative data collection before (exploratory) and after (explanatory) the quantitative data collection.  This will allow us to explore the qualitative characteristics of each clinical site that appear to be associated with implementation success, as well as explaining the quantitative data regarding fidelity.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"75b2251590fe4d28eeeef36d6dbda4c9";}s:4:"show";b:1;s:3:"cid";s:32:"dc057fe59fe989b7eb5d25fdd6edbaca";}s:32:"825625a8b67c2518124e47cc7726e8c0";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"wnorton";s:4:"name";s:12:"Wynne Norton";s:4:"mail";s:20:"wynne.norton@nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1538426811;}s:3:"raw";s:1491:"Sorry for my late reply!

Looks good overall. I like your explanation for selecting PRISM and how it is a better fit for your proposed study than RE-AIM. 

Couple of suggestions:
--Consider reducing the number of constructs you plan to measure. I think it's great that you are thinking of all of these, but make sure to balance that with the amount of work (i.e., budget for collecting data, participant incentives, data analysis, and time constraints) that extensive data collection would require, and qualitative data in particular, which is costly, intensive, and time-consuming. Of course, you want to collect some qual and quant process and outcome data, but might try to narrow it down a bit to the key measures and outcomes that are necessary to answer your research questions. 
--Consider assessing the intervention at a 6-month post-intervention follow-up instead of 24-months. I think  a pre-post intervention assessment is ok, but it might be a stretch to assume that you could see a difference 2-years after the intervention. Maybe 6-months is a better option or perhaps 1-year? 
--You might consider trying to identify clinic work flow as an option for reducing provider workload and thereby creating more time for providers and fewer competing demands. 
--If you are collecting qualitative and quantitative data, might consider reviewing the mixed methods study designs, if you plan to integrate the data in a more robust way and use the data as complementary vs. stand-alone. ";s:5:"xhtml";s:1535:"Sorry for my late reply!<br /><br />Looks good overall. I like your explanation for selecting PRISM and how it is a better fit for your proposed study than RE-AIM. <br /><br />Couple of suggestions:<br />--Consider reducing the number of constructs you plan to measure. I think it&#039;s great that you are thinking of all of these, but make sure to balance that with the amount of work (i.e., budget for collecting data, participant incentives, data analysis, and time constraints) that extensive data collection would require, and qualitative data in particular, which is costly, intensive, and time-consuming. Of course, you want to collect some qual and quant process and outcome data, but might try to narrow it down a bit to the key measures and outcomes that are necessary to answer your research questions. <br />--Consider assessing the intervention at a 6-month post-intervention follow-up instead of 24-months. I think  a pre-post intervention assessment is ok, but it might be a stretch to assume that you could see a difference 2-years after the intervention. Maybe 6-months is a better option or perhaps 1-year? <br />--You might consider trying to identify clinic work flow as an option for reducing provider workload and thereby creating more time for providers and fewer competing demands. <br />--If you are collecting qualitative and quantitative data, might consider reviewing the mixed methods study designs, if you plan to integrate the data in a more robust way and use the data as complementary vs. stand-alone.";s:6:"parent";s:32:"05f748362d110269df4e9ae6003154f4";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"825625a8b67c2518124e47cc7726e8c0";}s:32:"713781e5f56020ac0712e98e01563657";a:8:{s:4:"user";a:5:{s:2:"id";s:10:"ldimartino";s:4:"name";s:14:"Lisa DiMartino";s:4:"mail";s:18:"ldimartino@rti.org";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1538488403;}s:3:"raw";s:189:"Thanks, Gila.  I have been trying to think of how to incorporated the patient perspective into all of this and your suggestion of exit interviews to assess adoption is a great suggestion.  ";s:5:"xhtml";s:187:"Thanks, Gila.  I have been trying to think of how to incorporated the patient perspective into all of this and your suggestion of exit interviews to assess adoption is a great suggestion.";s:6:"parent";s:32:"f1dca38429923b681f76a4a5d31468ee";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"713781e5f56020ac0712e98e01563657";}s:32:"b13f9f0c63a850f4d78461367429f89b";a:8:{s:4:"user";a:5:{s:2:"id";s:6:"klyons";s:4:"name";s:14:"Kathleen Lyons";s:4:"mail";s:30:"Kathleen.D.Lyons@dartmouth.edu";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1538582275;}s:3:"raw";s:2061:"Lyons Assignment #4:
1.	What is your proposed study design? Why is that the best design to answer your research questions or hypotheses?
Research questions: In what ways can we adapt the ENABLE symptom management module to surmount barriers to implementation in the low resource setting in Honduras? To what degree will those adaptations enhance or dilute the effectiveness of the intervention?
Study design: This would be a hybrid II trial, where I am equally interested in the effectiveness of the adapted intervention and the implementation strategies used in this environment. I don’t think that we will be in a place where we will randomize and compare two different implementation strategies, but instead use a no-treatment run in phase where we can track what is currently occurring (i.e., to act as a historical control comparison) and identify the potential modifications then implement the adapted intervention.
2.	Will you be incorporating a mixed methods design into your study? If so, what approach will you use to incorporate the qualitative data into the study (e.g., integrate the quantitative and qualitative data to inform your aims? If not, why?
Yes, we will need to collect and analyze both qualitative and quantitative data. I see the function as “complementarity” – using different types of data to answer different questions (e.g., quantitative data regarding rates of healthcare use, treatment delay, symptom burden and qualitative data to describe barriers, perceptions of intervention, organizational culture). It would be embedded and simultaneous in that we’d need to collect both qualitative and quantitative in each phase. In terms of actual mixing, I’m not sure at this moment the degree to which we will be able to do that. What I have done before is to take scores of high performers and low performers (patients who do well with an intervention versus those who struggle) and then use that to sample the qualitative data to see if we can learn anything new from their descriptions of experiences and perceptions.  
";s:5:"xhtml";s:2083:"Lyons Assignment #4:<br />1.	What is your proposed study design? Why is that the best design to answer your research questions or hypotheses?<br />Research questions: In what ways can we adapt the ENABLE symptom management module to surmount barriers to implementation in the low resource setting in Honduras? To what degree will those adaptations enhance or dilute the effectiveness of the intervention?<br />Study design: This would be a hybrid II trial, where I am equally interested in the effectiveness of the adapted intervention and the implementation strategies used in this environment. I don’t think that we will be in a place where we will randomize and compare two different implementation strategies, but instead use a no-treatment run in phase where we can track what is currently occurring (i.e., to act as a historical control comparison) and identify the potential modifications then implement the adapted intervention.<br />2.	Will you be incorporating a mixed methods design into your study? If so, what approach will you use to incorporate the qualitative data into the study (e.g., integrate the quantitative and qualitative data to inform your aims? If not, why?<br />Yes, we will need to collect and analyze both qualitative and quantitative data. I see the function as “complementarity” – using different types of data to answer different questions (e.g., quantitative data regarding rates of healthcare use, treatment delay, symptom burden and qualitative data to describe barriers, perceptions of intervention, organizational culture). It would be embedded and simultaneous in that we’d need to collect both qualitative and quantitative in each phase. In terms of actual mixing, I’m not sure at this moment the degree to which we will be able to do that. What I have done before is to take scores of high performers and low performers (patients who do well with an intervention versus those who struggle) and then use that to sample the qualitative data to see if we can learn anything new from their descriptions of experiences and perceptions.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"78b2bddd41a60d6e36a60166cc8616ca";}s:4:"show";b:1;s:3:"cid";s:32:"b13f9f0c63a850f4d78461367429f89b";}s:32:"18807fe8cf0bf7e332f3c719712398b0";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"lreinke";s:4:"name";s:11:"Lynn Reinke";s:4:"mail";s:19:"Lynn.Reinke1@va.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1538693309;}s:3:"raw";s:2396:"Reinke  Assignment #4 10/4/17
1.	What is your proposed study design? 
My proposed study design is a hybrid effectiveness/implementation design, Type 2 using either a cluster RCT or a stepped wedge cluster RCT. I believe this design is appropriate to address our research questions:
R Q1: to determine the clinical effectiveness of an evidence-based palliative care intervention for patients newly diagnosed with lung cancer on clinical outcomes (quality of life, symptom burden and patient satisfaction of care) while simultaneously testing implementation strategies in 4 geographically diverse Veterans Integrated Service Networks (VISNs). 

I believe this is the best design because we need to establish effectiveness of the intervention in the real world setting as well as develop and pilot test implementation strategies to facilitate wide spread dissemination and sustainability across all VA medical centers. 

2.	Will you be incorporating a mixed methods design into your study? If so, what approach will you use to incorporate the qualitative data into the study (e.g., integrate the quantitative and qualitative data to inform your aims? If not, why? 

We will use a mixed methods approach to address research question 2: 
Among 4 VISNs, test an implementation strategy of a nurse-led palliative care intervention on provider education, champion engagement, marketing and cost estimates to facilitate adoption, fidelity and sustainability of the palliative care intervention.  

We will take a convergence approach to collecting qualitative and quantitative data to help us understand processes, context and complexity of each medical center within the VISNs. We will
directly observe oncology and palliative care operations and conduct interviews with stakeholders (nurses, physicians, administrators) to identify factors (behavioral, social, cultural, institutional, economic) that may shape behavior, such as adoption, or organizational processes. 

We will also collect quantitative data such as nurse FTE to deliver the intervention, RN salaries, reduction in patient face to face time for providers, efficiency of patient visits, reduction in patient travel time and cost, and patient health care utilization (ED visits, acute hospitalizations, ancillary services). Collectively these data will inform the implementation strategy for adoption of the intervention across VAs. 

 

";s:5:"xhtml";s:2465:"Reinke  Assignment #4 10/4/17<br />1.	What is your proposed study design? <br />My proposed study design is a hybrid effectiveness/implementation design, Type 2 using either a cluster RCT or a stepped wedge cluster RCT. I believe this design is appropriate to address our research questions:<br />R Q1: to determine the clinical effectiveness of an evidence-based palliative care intervention for patients newly diagnosed with lung cancer on clinical outcomes (quality of life, symptom burden and patient satisfaction of care) while simultaneously testing implementation strategies in 4 geographically diverse Veterans Integrated Service Networks (VISNs). <br /><br />I believe this is the best design because we need to establish effectiveness of the intervention in the real world setting as well as develop and pilot test implementation strategies to facilitate wide spread dissemination and sustainability across all VA medical centers. <br /><br />2.	Will you be incorporating a mixed methods design into your study? If so, what approach will you use to incorporate the qualitative data into the study (e.g., integrate the quantitative and qualitative data to inform your aims? If not, why? <br /><br />We will use a mixed methods approach to address research question 2: <br />Among 4 VISNs, test an implementation strategy of a nurse-led palliative care intervention on provider education, champion engagement, marketing and cost estimates to facilitate adoption, fidelity and sustainability of the palliative care intervention.  <br /><br />We will take a convergence approach to collecting qualitative and quantitative data to help us understand processes, context and complexity of each medical center within the VISNs. We will<br />directly observe oncology and palliative care operations and conduct interviews with stakeholders (nurses, physicians, administrators) to identify factors (behavioral, social, cultural, institutional, economic) that may shape behavior, such as adoption, or organizational processes. <br /><br />We will also collect quantitative data such as nurse FTE to deliver the intervention, RN salaries, reduction in patient face to face time for providers, efficiency of patient visits, reduction in patient travel time and cost, and patient health care utilization (ED visits, acute hospitalizations, ancillary services). Collectively these data will inform the implementation strategy for adoption of the intervention across VAs.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"8a7c6e2fa85f5c457a8c3a22566838d0";}s:4:"show";b:1;s:3:"cid";s:32:"18807fe8cf0bf7e332f3c719712398b0";}s:32:"80d1db5e2f1815d76195e70c521e1dc3";a:8:{s:4:"user";a:5:{s:2:"id";s:10:"ldimartino";s:4:"name";s:14:"Lisa DiMartino";s:4:"mail";s:18:"ldimartino@rti.org";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:2:{s:7:"created";i:1538764120;s:8:"modified";i:1538768973;}s:3:"raw";s:3453:"DiMartino - Assignment #4.

1. What is your proposed study design? Why is that the best design to answer your research questions or hypotheses?

For my R21 pilot project, my current aims are to 1) Conduct a formative evaluation of how a novel machine-learning based CDS tool could be used to identify hospitalized cancer patients who need palliative care; 2) examine the effectiveness of a CDS tool to improve delivery of palliative care for cancer inpatients in preparation for a larger R01 trial; and 3) examine the multi-level barriers and facilitators to implementation of the tool.   Due to funding constraints, the implementation of the tool would only be occurring at a single hospital, and randomization would not be possible.  Thus, I would use a within-site, quasi-experimental design such as interrupted time series (ITS) to assess the impact of the tool on clinical/service outcomes for Aim 2, such as palliative care services or hospice use.  ITS is the best design because it allows for multiple assessments before and after an intervention has been introduced and examines the effect of the intervention on outcomes by comparing pre and post changes in the slope level. This would be possible due to ample availability of pre-data in the UNC EHR on these outcomes.  For the implementation outcomes assessed in Aim 3 (e,g, adoption, acceptability, feasibility, appropriateness of the tool) pre data would not be available on these so I would rely on a post only measurement of these outcomes.  

For a future implementation trial, I could see using a multi-site cluster randomized hybrid-effectiveness Type 3 trial where the focus would be on the testing different strategies to support implementation of the CDS tool, while also gathering data on patient clinical outcomes.  This would be appropriate given the existing body of evidence on the effectiveness of CDS tools for improving uptake of evidence based interventions; however, their use in studies regarding palliative care cancer populations specifically has been is limited.    

2. Will you be incorporating a mixed methods design into your study? If so, what approach will you use to incorporate the qualitative data into the study (e.g., integrate the quantitative and qualitative data to inform your aims? If not, why? 

Yes, I would incorporate a mixed-methods approach by primarily using an “embedded” study design. This would occur in several ways.  First, qualitative data would be collected during the formative evaluation through semi-structured interviews with stakeholders to explore how the CDS tool could be adapted prior to pilot testing (Aim 1).  Second, qualitative data from interviews with providers (oncologists, nurses, PC physicians) who are exposed to the CDS tool (and possibly observations) would be collected during the pilot testing to complement any quantitative process (e.g., fidelity) and outcomes measures and to understand multi-level contextual factors that may influence tool implementation (Aim 3).  The questionnaire would use constructs from the Theoretical Domains Framework as a guide.   Data would be collected and analyzed simultaneously during the pilot (QUAL+QUAN) and given equal weight.  Finally, the qualitative data gathered from my pilot study will be used to inform the development of strategies that could best support implementation of the CDS tool which would be tested in a larger implementation effectiveness trial.   

";s:5:"xhtml";s:3498:"DiMartino - Assignment #4.<br /><br />1. What is your proposed study design? Why is that the best design to answer your research questions or hypotheses?<br /><br />For my R21 pilot project, my current aims are to 1) Conduct a formative evaluation of how a novel machine-learning based CDS tool could be used to identify hospitalized cancer patients who need palliative care; 2) examine the effectiveness of a CDS tool to improve delivery of palliative care for cancer inpatients in preparation for a larger R01 trial; and 3) examine the multi-level barriers and facilitators to implementation of the tool.   Due to funding constraints, the implementation of the tool would only be occurring at a single hospital, and randomization would not be possible.  Thus, I would use a within-site, quasi-experimental design such as interrupted time series (ITS) to assess the impact of the tool on clinical/service outcomes for Aim 2, such as palliative care services or hospice use.  ITS is the best design because it allows for multiple assessments before and after an intervention has been introduced and examines the effect of the intervention on outcomes by comparing pre and post changes in the slope level. This would be possible due to ample availability of pre-data in the UNC EHR on these outcomes.  For the implementation outcomes assessed in Aim 3 (e,g, adoption, acceptability, feasibility, appropriateness of the tool) pre data would not be available on these so I would rely on a post only measurement of these outcomes.  <br /><br />For a future implementation trial, I could see using a multi-site cluster randomized hybrid-effectiveness Type 3 trial where the focus would be on the testing different strategies to support implementation of the CDS tool, while also gathering data on patient clinical outcomes.  This would be appropriate given the existing body of evidence on the effectiveness of CDS tools for improving uptake of evidence based interventions; however, their use in studies regarding palliative care cancer populations specifically has been is limited.    <br /><br />2. Will you be incorporating a mixed methods design into your study? If so, what approach will you use to incorporate the qualitative data into the study (e.g., integrate the quantitative and qualitative data to inform your aims? If not, why? <br /><br />Yes, I would incorporate a mixed-methods approach by primarily using an “embedded” study design. This would occur in several ways.  First, qualitative data would be collected during the formative evaluation through semi-structured interviews with stakeholders to explore how the CDS tool could be adapted prior to pilot testing (Aim 1).  Second, qualitative data from interviews with providers (oncologists, nurses, PC physicians) who are exposed to the CDS tool (and possibly observations) would be collected during the pilot testing to complement any quantitative process (e.g., fidelity) and outcomes measures and to understand multi-level contextual factors that may influence tool implementation (Aim 3).  The questionnaire would use constructs from the Theoretical Domains Framework as a guide.   Data would be collected and analyzed simultaneously during the pilot (QUAL+QUAN) and given equal weight.  Finally, the qualitative data gathered from my pilot study will be used to inform the development of strategies that could best support implementation of the CDS tool which would be tested in a larger implementation effectiveness trial.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"7f932ba3a459677f54fc8c6f6f496d90";}s:4:"show";b:1;s:3:"cid";s:32:"80d1db5e2f1815d76195e70c521e1dc3";}s:32:"650bee29eaff1cc87279b4c9b9aa10bd";a:8:{s:4:"user";a:5:{s:2:"id";s:8:"khuggins";s:4:"name";s:12:"Kate Huggins";s:4:"mail";s:23:"kate.huggins@monash.edu";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1538770526;}s:3:"raw";s:2552:"Huggins_Assignment 4

1.	What is your proposed study design? Why is that the best design to answer your research questions or hypotheses?

The study I proposed in the concept note is best described as an effectiveness-implementation trial Hybrid Type 1. The primary goal of the RCT is to assess the effectiveness and cost-effectiveness of early (at time of diagnosis) and frequent nutrition care on quality of life, and a secondary goal is to examine process measures. Two novel service delivery models are utilised to get the nutrition care delivered to the patient: 1) via telephone (synchronous) and 2) through mHealth (asynchronous). The nutrition care delivered to the patient is designed to be using best practice behaviour change techniques. The main aims of the process evaluation are to investigate:

a) fidelity in terms of adherence to protocol i.e to the behaviour change techniques prescribed and to the mode of service delivery (telephone vs. mHealth); dose in terms of how many attempts the dietitian tried to reach the participant as well as those successfully delivered (i.e the patient responded to phone call or message)

b) acceptability of the intervention to patients and their families and also their health care team (in-depth interviews).

c) adaptation of nutrition care delivery, which will be a comparative analysis between the two service delivery models (content analysis of recorded transcripts – phone recordings or written messages).

A future study would consider a preference design for the two intervention arms. Our early analysis of the post intervention interviews with participants clearly shows that different people have preferences for communication.

2. Will you be incorporating a mixed methods design into your study? If so, what design? If not, why?

Mixed-methods have been part of the design from the beginning. Quantitative and qualitative data are being collected concurrently. Qualitative data will be derived from direct observation through audio recoding of the patient consultations (telephone) or review of the written messages (mHealth), as well as from post-intervention semi-structured in depth interviews. Thematic analysis will be used to assess acceptability. Coding of observation data to compare against the protocol will also be performed. Quantitative analysis of process measures is also expected and likely to include negative binomial regression to assess adaptation. Sensitivity analyses to look at how participant characteristics impact on the outcomes will also be undertaken.

";s:5:"xhtml";s:2630:"Huggins_Assignment 4<br /><br />1.	What is your proposed study design? Why is that the best design to answer your research questions or hypotheses?<br /><br />The study I proposed in the concept note is best described as an effectiveness-implementation trial Hybrid Type 1. The primary goal of the RCT is to assess the effectiveness and cost-effectiveness of early (at time of diagnosis) and frequent nutrition care on quality of life, and a secondary goal is to examine process measures. Two novel service delivery models are utilised to get the nutrition care delivered to the patient: 1) via telephone (synchronous) and 2) through mHealth (asynchronous). The nutrition care delivered to the patient is designed to be using best practice behaviour change techniques. The main aims of the process evaluation are to investigate:<br /><br />a) fidelity in terms of adherence to protocol i.e to the behaviour change techniques prescribed and to the mode of service delivery (telephone vs. mHealth); dose in terms of how many attempts the dietitian tried to reach the participant as well as those successfully delivered (i.e the patient responded to phone call or message)<br /><br />b) acceptability of the intervention to patients and their families and also their health care team (in-depth interviews).<br /><br />c) adaptation of nutrition care delivery, which will be a comparative analysis between the two service delivery models (content analysis of recorded transcripts – phone recordings or written messages).<br /><br />A future study would consider a preference design for the two intervention arms. Our early analysis of the post intervention interviews with participants clearly shows that different people have preferences for communication.<br /><br />2. Will you be incorporating a mixed methods design into your study? If so, what design? If not, why?<br /><br />Mixed-methods have been part of the design from the beginning. Quantitative and qualitative data are being collected concurrently. Qualitative data will be derived from direct observation through audio recoding of the patient consultations (telephone) or review of the written messages (mHealth), as well as from post-intervention semi-structured in depth interviews. Thematic analysis will be used to assess acceptability. Coding of observation data to compare against the protocol will also be performed. Quantitative analysis of process measures is also expected and likely to include negative binomial regression to assess adaptation. Sensitivity analyses to look at how participant characteristics impact on the outcomes will also be undertaken.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"e8a3cf63e5a5e51c00faf2d9147cf97e";}s:4:"show";b:1;s:3:"cid";s:32:"650bee29eaff1cc87279b4c9b9aa10bd";}s:32:"05e16271391a12b4ffbe9d0f29a8593d";a:8:{s:4:"user";a:5:{s:2:"id";s:10:"moluwasanu";s:4:"name";s:18:"Mojisola Oluwasanu";s:4:"mail";s:15:"ope3m@yahoo.com";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1538850872;}s:3:"raw";s:2312:"Oluwasanu_Assignment 4

1.	What is your proposed study design? Why is that the best design to answer your research questions or hypotheses?

The proposed study design is a Cluster randomised trial.  This is suited for a hybrid effectiveness/implementation type I study which investigates the effects of an integrated, multi-component HIV and breast cancer intervention for screening and adoption of preventive practices. 

Cluster randomised trials are suited and commonly used to evaluate public health interventions especially when decision to implement an intervention is taken on behalf of a group and it is not feasible to randomize individuals. They are also appropriate for studies which carry a significant risk of contamination such as public health promotion interventions within settings such as schools, workplaces or communities (Moberg and Kramer, 2015). The women in the informal work sector (artisans) belong to associations which have a structured governance/constitution and regular meeting time. These associations are organised based on the different types of trades for instance, hair dressing, tailors, caterers etc and there are several groups which can serve as a cluster and setting for the implementation of the integrated, multi-component HIV and breast cancer intervention.


2.	Will you be incorporating a mixed methods design into your study? If so, what approach will you use to incorporate the qualitative data into the study (e.g., integrate the quantitative and qualitative data to inform your aims? If not, why? 

This study will be utilize a Mixed methods, Multiphase design. A typical feature of this approach is that both sequential and concurrent strands are combined over a period of time within a program of study (Schoonenboom et al, 2017). For instance, the research question on the Acceptability of the intervention can be answered using a “Concurrent explanatory approach” i.e. questionnaire administration and focus group discussion with the beneficiaries at about the same time period while Adoption can be assessed using an “Explanatory sequential design” for instance review and analysis of administrative data/records followed by key informant interviews with leaders of the trade associations based on the findings from the administrative data/records.
";s:5:"xhtml";s:2366:"Oluwasanu_Assignment 4<br /><br />1.	What is your proposed study design? Why is that the best design to answer your research questions or hypotheses?<br /><br />The proposed study design is a Cluster randomised trial.  This is suited for a hybrid effectiveness/implementation type I study which investigates the effects of an integrated, multi-component HIV and breast cancer intervention for screening and adoption of preventive practices. <br /><br />Cluster randomised trials are suited and commonly used to evaluate public health interventions especially when decision to implement an intervention is taken on behalf of a group and it is not feasible to randomize individuals. They are also appropriate for studies which carry a significant risk of contamination such as public health promotion interventions within settings such as schools, workplaces or communities (Moberg and Kramer, 2015). The women in the informal work sector (artisans) belong to associations which have a structured governance/constitution and regular meeting time. These associations are organised based on the different types of trades for instance, hair dressing, tailors, caterers etc and there are several groups which can serve as a cluster and setting for the implementation of the integrated, multi-component HIV and breast cancer intervention.<br /><br /><br />2.	Will you be incorporating a mixed methods design into your study? If so, what approach will you use to incorporate the qualitative data into the study (e.g., integrate the quantitative and qualitative data to inform your aims? If not, why? <br /><br />This study will be utilize a Mixed methods, Multiphase design. A typical feature of this approach is that both sequential and concurrent strands are combined over a period of time within a program of study (Schoonenboom et al, 2017). For instance, the research question on the Acceptability of the intervention can be answered using a “Concurrent explanatory approach” i.e. questionnaire administration and focus group discussion with the beneficiaries at about the same time period while Adoption can be assessed using an “Explanatory sequential design” for instance review and analysis of administrative data/records followed by key informant interviews with leaders of the trade associations based on the findings from the administrative data/records.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"288c473a6437f5ac1c1b361422845830";}s:4:"show";b:1;s:3:"cid";s:32:"05e16271391a12b4ffbe9d0f29a8593d";}s:32:"01d8ba0f21cee55de3d3b3e37e94a1e1";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"lpace";s:4:"name";s:10:"Lydia Pace";s:4:"mail";s:21:"LPACE@BWH.HARVARD.EDU";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1539034577;}s:3:"raw";s:3398:"Pace - Assignment 4, Study designs (sorry for my delay!!).

1.	What is your proposed study design? Why is that the best design to answer your research questions or hypotheses?

My proposed study design is a post-implementation design to investigate the uptake and effectiveness of a new implementation strategy for breast cancer early detection in 2 Rwandan districts where breast cancer early detection efforts have not previously been pursued. We will use a pre/post strategy to investigate improvements in breast health knowledge and clinical skills after the trainings, which are the centerpiece of the intervention.

I think that the post-implementation design is the most feasible option given that the MOH is rolling out the intervention currently (in collaboration with my team) and we weren’t able to establish a control group or use randomization to assign the intervention facilities (which were chosen by MOH, with our input). The adaptations to our pilot mostly reflect the limited resources we have in this scale-up phase (as opposed to our pilot), and the preferences of our MOH colleagues.

I wanted to mention that we could informally compare numbers such as cancer detection rate and patient volume to those that we have found in our pilot project in Burera District, where we adopted a symptomatic approach to breast cancer early detection (training communities in breast symptoms and training nurses to manage breast concerns, rather than focusing on screening of asymptomatic women, which is the approach being pursued in the 2 new districts). However, we aren’t planning a formal statistical comparison and there are reasons why Burera is hard to compare. I do think that a future study in which health centers are randomized to adopt a screening-CBE versus symptomatic approach would be of value and I'm thinking about that.

With regard to feasibility of a pre/post design: we could abstract data from health registries to determine the volume of patients with breast concerns who presented at health facilities prior to the intervention – we actually did this in Burera during our pilot study. However, it was quite laborious and we’d need additional resources to achieve this….and I’m also not sure that it’s essential since we already demonstrated a significant increase in volume in our pilot. I think the question I’d like to answer in this phase is whether the post-intervention volume is manageable for health facilities (more than simply documenting an increase, which we would expect).

2.	Will you be incorporating a mixed methods design into your study? If so, what approach will you use to incorporate the qualitative data into the study (e.g., integrate the quantitative and qualitative data to inform your aims? If not, why? 

I am planning to use a “convergent” design. Resources permitting, I will interview health center and district hospital clinicians to get a better understanding of how the breast cancer early detection intervention has impacted their workload, how comfortable they feel with providing breast care, and their perceptions of persistent barriers and aspects we need to improve. I will use this information along with the quantitative information to develop a more complete understanding of the effectiveness and feasibility of the intervention overall, and its impact on patients, providers, and the health system.  
";s:5:"xhtml";s:3470:"Pace - Assignment 4, Study designs (sorry for my delay!!).<br /><br />1.	What is your proposed study design? Why is that the best design to answer your research questions or hypotheses?<br /><br />My proposed study design is a post-implementation design to investigate the uptake and effectiveness of a new implementation strategy for breast cancer early detection in 2 Rwandan districts where breast cancer early detection efforts have not previously been pursued. We will use a pre/post strategy to investigate improvements in breast health knowledge and clinical skills after the trainings, which are the centerpiece of the intervention.<br /><br />I think that the post-implementation design is the most feasible option given that the MOH is rolling out the intervention currently (in collaboration with my team) and we weren’t able to establish a control group or use randomization to assign the intervention facilities (which were chosen by MOH, with our input). The adaptations to our pilot mostly reflect the limited resources we have in this scale-up phase (as opposed to our pilot), and the preferences of our MOH colleagues.<br /><br />I wanted to mention that we could informally compare numbers such as cancer detection rate and patient volume to those that we have found in our pilot project in Burera District, where we adopted a symptomatic approach to breast cancer early detection (training communities in breast symptoms and training nurses to manage breast concerns, rather than focusing on screening of asymptomatic women, which is the approach being pursued in the 2 new districts). However, we aren’t planning a formal statistical comparison and there are reasons why Burera is hard to compare. I do think that a future study in which health centers are randomized to adopt a screening-CBE versus symptomatic approach would be of value and I&#039;m thinking about that.<br /><br />With regard to feasibility of a pre/post design: we could abstract data from health registries to determine the volume of patients with breast concerns who presented at health facilities prior to the intervention – we actually did this in Burera during our pilot study. However, it was quite laborious and we’d need additional resources to achieve this….and I’m also not sure that it’s essential since we already demonstrated a significant increase in volume in our pilot. I think the question I’d like to answer in this phase is whether the post-intervention volume is manageable for health facilities (more than simply documenting an increase, which we would expect).<br /><br />2.	Will you be incorporating a mixed methods design into your study? If so, what approach will you use to incorporate the qualitative data into the study (e.g., integrate the quantitative and qualitative data to inform your aims? If not, why? <br /><br />I am planning to use a “convergent” design. Resources permitting, I will interview health center and district hospital clinicians to get a better understanding of how the breast cancer early detection intervention has impacted their workload, how comfortable they feel with providing breast care, and their perceptions of persistent barriers and aspects we need to improve. I will use this information along with the quantitative information to develop a more complete understanding of the effectiveness and feasibility of the intervention overall, and its impact on patients, providers, and the health system.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"3fa8505551a728238a341081cb786cf0";}s:4:"show";b:1;s:3:"cid";s:32:"01d8ba0f21cee55de3d3b3e37e94a1e1";}s:32:"75b2251590fe4d28eeeef36d6dbda4c9";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"wnorton";s:4:"name";s:12:"Wynne Norton";s:4:"mail";s:20:"wynne.norton@nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1539113919;}s:3:"raw";s:680:"Good! I like your justification for using the study design, and the stepped-wedge design is a good way to make sure that all sites receive the intervention and implementation strategy, and much easier to manage logistically as a study team, as you note. With the mixed methods data, make sure you plan for how you will integrate the qual and quant data to answer your research questions. Since you are proposing a type 2, will be important to collect data from individuals/patients as well as providers delivering the intervention, while being mindful of the cost of collecting such data balanced against sample size estimates for qual data (i.e., ~20-30 participants per group). ";s:5:"xhtml";s:679:"Good! I like your justification for using the study design, and the stepped-wedge design is a good way to make sure that all sites receive the intervention and implementation strategy, and much easier to manage logistically as a study team, as you note. With the mixed methods data, make sure you plan for how you will integrate the qual and quant data to answer your research questions. Since you are proposing a type 2, will be important to collect data from individuals/patients as well as providers delivering the intervention, while being mindful of the cost of collecting such data balanced against sample size estimates for qual data (i.e., ~20-30 participants per group).";s:6:"parent";s:32:"dc057fe59fe989b7eb5d25fdd6edbaca";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"75b2251590fe4d28eeeef36d6dbda4c9";}s:32:"78b2bddd41a60d6e36a60166cc8616ca";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"wnorton";s:4:"name";s:12:"Wynne Norton";s:4:"mail";s:20:"wynne.norton@nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1539114293;}s:3:"raw";s:1001:"I like your proposed use of quantitative data to inform sampling strategy for qualitative interviews. You'll want to interview individuals who are delivering the intervention as well, since you are proposing a type 2 design. 
The no-treatment run-in phase design: Is this a within-subject (clinic/site) pre-post design? It sounds like you might be better suited for a hybrid type 1, where your primary aim is to assess the effectiveness of the adapted intervention while collecting implementation process and outcome data (observational vs. manipulating or exposing to any type of implementation strategy). You could systematically assess what adaptations are needed during the implementation phase and look at association with patient outcomes, but I'm not sure it sounds like you are pilot testing or assessing the effectiveness of the intervention as well as the implementation strategy. No right or wrong answers, but might consider a hybrid type 1 instead of type 2, given your study objectives. ";s:5:"xhtml";s:1015:"I like your proposed use of quantitative data to inform sampling strategy for qualitative interviews. You&#039;ll want to interview individuals who are delivering the intervention as well, since you are proposing a type 2 design. <br />The no-treatment run-in phase design: Is this a within-subject (clinic/site) pre-post design? It sounds like you might be better suited for a hybrid type 1, where your primary aim is to assess the effectiveness of the adapted intervention while collecting implementation process and outcome data (observational vs. manipulating or exposing to any type of implementation strategy). You could systematically assess what adaptations are needed during the implementation phase and look at association with patient outcomes, but I&#039;m not sure it sounds like you are pilot testing or assessing the effectiveness of the intervention as well as the implementation strategy. No right or wrong answers, but might consider a hybrid type 1 instead of type 2, given your study objectives.";s:6:"parent";s:32:"b13f9f0c63a850f4d78461367429f89b";s:7:"replies";a:1:{i:0;s:32:"a73ce8839e226b4f968a174c493d93bc";}s:4:"show";b:1;s:3:"cid";s:32:"78b2bddd41a60d6e36a60166cc8616ca";}s:32:"8a7c6e2fa85f5c457a8c3a22566838d0";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"wnorton";s:4:"name";s:12:"Wynne Norton";s:4:"mail";s:20:"wynne.norton@nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1539114918;}s:3:"raw";s:598:"Good detail and justification for use of designs and methods. 

Do you have an idea of why the nurse-led palliative care intervention (i.e., implementation strategy, as you note above) will work--maybe from some pilot data or review of published literature? If yes, great. If no, might consider a type 1 design so you can collect barriers/facilitators and then use those data to inform selection of strategies to test in follow-up trial. The impl strategies lecture will likely help, but what is it about the nurse-led intervention that is hypothesized to have an impact on implementation outcomes?";s:5:"xhtml";s:608:"Good detail and justification for use of designs and methods. <br /><br />Do you have an idea of why the nurse-led palliative care intervention (i.e., implementation strategy, as you note above) will work--maybe from some pilot data or review of published literature? If yes, great. If no, might consider a type 1 design so you can collect barriers/facilitators and then use those data to inform selection of strategies to test in follow-up trial. The impl strategies lecture will likely help, but what is it about the nurse-led intervention that is hypothesized to have an impact on implementation outcomes?";s:6:"parent";s:32:"18807fe8cf0bf7e332f3c719712398b0";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"8a7c6e2fa85f5c457a8c3a22566838d0";}s:32:"7f932ba3a459677f54fc8c6f6f496d90";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"wnorton";s:4:"name";s:12:"Wynne Norton";s:4:"mail";s:20:"wynne.norton@nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1539115382;}s:3:"raw";s:956:"Great explanation and description. The ITS is a very appropriate design given the limitations you note and the research question. ITS usually requires a dozen if not dozens of pre-post assessments, so you'll want to consult with an expert to make sure you have sufficient data points to answer your question (although if it's a pilot study, you may not be powered to detect pre-post differences and instead use as estimate of effect size for your follow-up R01 fully-powered trial). Make sure that the R21 mechanism is appropriate here given study objectives, budget, and time constraints (2 years). The quant data shouldn't take too much time to pull since you can rely on EMR system (vs. original data collection), but some of the other data collection and analysis might be more expensive and time-consuming. This is where it is helpful to rely on a theory, as you note, to guide data collection given that you can't collect all processes and outcomes. ";s:5:"xhtml";s:975:"Great explanation and description. The ITS is a very appropriate design given the limitations you note and the research question. ITS usually requires a dozen if not dozens of pre-post assessments, so you&#039;ll want to consult with an expert to make sure you have sufficient data points to answer your question (although if it&#039;s a pilot study, you may not be powered to detect pre-post differences and instead use as estimate of effect size for your follow-up R01 fully-powered trial). Make sure that the R21 mechanism is appropriate here given study objectives, budget, and time constraints (2 years). The quant data shouldn&#039;t take too much time to pull since you can rely on EMR system (vs. original data collection), but some of the other data collection and analysis might be more expensive and time-consuming. This is where it is helpful to rely on a theory, as you note, to guide data collection given that you can&#039;t collect all processes and outcomes.";s:6:"parent";s:32:"80d1db5e2f1815d76195e70c521e1dc3";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"7f932ba3a459677f54fc8c6f6f496d90";}s:32:"e8a3cf63e5a5e51c00faf2d9147cf97e";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"gneta";s:4:"name";s:9:"Gila Neta";s:4:"mail";s:20:"netagil@mail.nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1539194308;}s:3:"raw";s:573:"Good. But remember to justify why you are proposing a Hybrid Type 1 as opposed to a Type 2 or 3. What do we know about the effectiveness of this intervention already? In other settings and populations? Why do you need more effectiveness evidence here and now? And for the implementation part of the hybrid, the process measures, make sure you are focused on the implementers here. 

And in terms of mixed methods: it's good you are looking at both qual and quant data, but how is this mixed methods per se? How will you integrate these data? And will one inform the other? ";s:5:"xhtml";s:587:"Good. But remember to justify why you are proposing a Hybrid Type 1 as opposed to a Type 2 or 3. What do we know about the effectiveness of this intervention already? In other settings and populations? Why do you need more effectiveness evidence here and now? And for the implementation part of the hybrid, the process measures, make sure you are focused on the implementers here. <br /><br />And in terms of mixed methods: it&#039;s good you are looking at both qual and quant data, but how is this mixed methods per se? How will you integrate these data? And will one inform the other?";s:6:"parent";s:32:"650bee29eaff1cc87279b4c9b9aa10bd";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"e8a3cf63e5a5e51c00faf2d9147cf97e";}s:32:"288c473a6437f5ac1c1b361422845830";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"gneta";s:4:"name";s:9:"Gila Neta";s:4:"mail";s:20:"netagil@mail.nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1539194612;}s:3:"raw";s:497:"Good justification for the cluster RCT! Can you also elaborate why this would be a hybrid type 1 vs. type 2 or 3? For example, you could think about the existing level of evidence for the intervention, why you would need another effectiveness study rather than more of a focus on implementation. And, why not a type 2? I'm not saying it should be a type 2, but just that it would be good to hear from you why you picked a type 1. :) And good description of the mixed methods approach! Nicely done!";s:5:"xhtml";s:502:"Good justification for the cluster RCT! Can you also elaborate why this would be a hybrid type 1 vs. type 2 or 3? For example, you could think about the existing level of evidence for the intervention, why you would need another effectiveness study rather than more of a focus on implementation. And, why not a type 2? I&#039;m not saying it should be a type 2, but just that it would be good to hear from you why you picked a type 1. :) And good description of the mixed methods approach! Nicely done!";s:6:"parent";s:32:"05e16271391a12b4ffbe9d0f29a8593d";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"288c473a6437f5ac1c1b361422845830";}s:32:"3fa8505551a728238a341081cb786cf0";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"gneta";s:4:"name";s:9:"Gila Neta";s:4:"mail";s:20:"netagil@mail.nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1539195692;}s:3:"raw";s:747:"Good and thoughtful justification. But can you clarify what a post-implementation design means? Is this an observational design? Or if it's quasi-experimental, can you explain how it is so? A few additional thoughts: Might it be possible to collect pre-implementation data on at least some of the sites where implementation has not yet occurred? And glad to see you thinking about what might be possible comparison groups. Perhaps others than Burera, depending on propensity scores if that's even feasible, or perhaps non-equivalent group comparison? But if your primary question is whether the post-intervention volume is manageable, this sounds more like program evaluation? And good job describing how you will use mixed methods in your study. ";s:5:"xhtml";s:756:"Good and thoughtful justification. But can you clarify what a post-implementation design means? Is this an observational design? Or if it&#039;s quasi-experimental, can you explain how it is so? A few additional thoughts: Might it be possible to collect pre-implementation data on at least some of the sites where implementation has not yet occurred? And glad to see you thinking about what might be possible comparison groups. Perhaps others than Burera, depending on propensity scores if that&#039;s even feasible, or perhaps non-equivalent group comparison? But if your primary question is whether the post-intervention volume is manageable, this sounds more like program evaluation? And good job describing how you will use mixed methods in your study.";s:6:"parent";s:32:"01d8ba0f21cee55de3d3b3e37e94a1e1";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"3fa8505551a728238a341081cb786cf0";}s:32:"f99457f489d4f23281390d3aa5bc72fb";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"gneta";s:4:"name";s:9:"Gila Neta";s:4:"mail";s:20:"netagil@mail.nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1539197526;}s:3:"raw";s:267:"Good use and justification of the framework and linking it to your outcome measures. For your process measures, how are you planning to measure them?

Also, per Dara's reminder earlier in the course, please remember to exclude references in your future posts. Thanks!";s:5:"xhtml";s:282:"Good use and justification of the framework and linking it to your outcome measures. For your process measures, how are you planning to measure them?<br /><br />Also, per Dara&#039;s reminder earlier in the course, please remember to exclude references in your future posts. Thanks!";s:6:"parent";s:32:"e6ff2db7679e6dc68c3af58fb56d682f";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"f99457f489d4f23281390d3aa5bc72fb";}s:32:"a73ce8839e226b4f968a174c493d93bc";a:8:{s:4:"user";a:5:{s:2:"id";s:6:"klyons";s:4:"name";s:14:"Kathleen Lyons";s:4:"mail";s:30:"Kathleen.D.Lyons@dartmouth.edu";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1539630869;}s:3:"raw";s:905:"Thank you, Wynne, you've got me convinced that a type 1 hybrid is more appropriate because it will be good to evaluate the effectiveness of the intervention that we already adapted slightly (and may decide to adapt more based upon the descriptive first part of the study). 
Regarding the no-treatment run in phase design, yes it would be a within site design because we only have one cancer center working with us, but not exactly within subjects because I see that first no treatment phase as a way to pilot the measures and get outcomes on people not exposed to the treatment. Then once we have the adaptations and process finalized we can expose people to the intervention. So, ultimately, it would be a quasi-experiment, comparing the treated sample to the historical control/untreated sample. I'm probably not explaining that well, but I will work on my wording and clarity as I progress. Thank you! ";s:5:"xhtml";s:919:"Thank you, Wynne, you&#039;ve got me convinced that a type 1 hybrid is more appropriate because it will be good to evaluate the effectiveness of the intervention that we already adapted slightly (and may decide to adapt more based upon the descriptive first part of the study). <br />Regarding the no-treatment run in phase design, yes it would be a within site design because we only have one cancer center working with us, but not exactly within subjects because I see that first no treatment phase as a way to pilot the measures and get outcomes on people not exposed to the treatment. Then once we have the adaptations and process finalized we can expose people to the intervention. So, ultimately, it would be a quasi-experiment, comparing the treated sample to the historical control/untreated sample. I&#039;m probably not explaining that well, but I will work on my wording and clarity as I progress. Thank you!";s:6:"parent";s:32:"78b2bddd41a60d6e36a60166cc8616ca";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"a73ce8839e226b4f968a174c493d93bc";}s:32:"a2ce9061c1dcaa3d8fadf05d4d6c1d38";a:8:{s:4:"user";a:5:{s:2:"id";s:6:"klyons";s:4:"name";s:14:"Kathleen Lyons";s:4:"mail";s:30:"Kathleen.D.Lyons@dartmouth.edu";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1539636872;}s:3:"raw";s:3798:"Lyons Assignment #5:
1.	If relevant, what are the specific implementation strategies that you will be focusing on in your proposed research and how have you selected them?
The feedback from assignment 4 has helped me to think of the study design as a Type I hybrid trial where I will primarily be monitoring the effectiveness of the intervention, while gathering information about the implementation process. It would be important to establish the effectiveness of the intervention itself because of two adaptations we have made: a) tailoring the content to include only symptom management strategies that are locally available and b) not providing a workbook to the patients (i.e., information is delivered via nurse as opposed to what occurred in the North American studies which was closer to self-management that was guided by a nurse). 

As such, I’m not certain that I will have a specific implementation strategy that I will be evaluating. That said, I am thinking of using training (for the nurses) and provision of feedback/auditing (from and for the nurses in addition to for the clinical team) as a way to build competence (in the nurses delivering the intervention) and motivation for entire team to sustain the intervention. I am thinking that is important because while the nurses in the pilot study enjoyed expanding their skill set they also reported a lack of time to complete the symptom management telephone calls. In addition to solving the system level problem of how to find the time for intervention delivery, I think the feedback will be important so that the whole team understands the way in which the intervention could contribute to helping patients adhere to treatment. Of course, that will only serve as a motivation if the intervention goes well and has the degree of effectiveness we saw in other settings… 

In terms of an implementation strategy that would help with the lack of time to deliver the intervention, I have been studying the readings in an attempt for ideas to address that barrier. The only things I can think of at the moment are “role revision” (a strategy noted in the category of supporting clinicians in the slide deck) and changing the infrastructure in some way. There is a new director of nursing being hired at the Honduran facility, so we will need to do some preparatory work with her/him and  the local team, assessing readiness for change and engaging them in problem-solving these challenges. To be honest, I am no longer certain that this particular project will be the one they choose as the vehicle to continue collaborating with us (it depends on the priorities of the new director), but I am continuing to work on the concept of this proposal because the approach and measures may be transferable to other lines of research we might pursue with them.

2.	How might you link specific implementation strategies to the context in which your work is set?
I will need to find a way to capitalize on existing meetings or processes if we are going to use feedback and auditing to enhance uptake or try to promote sustainability. For example, I am imaging that if nurses had some formal way to summarize/report back about patient symptom management needs and successes during chemotherapy visits then it would make any improvements (or deficits) salient for providers and that might help everyone see and understand the way in which proactive symptom management is designed to work.

3.	If your proposed study does not involve selecting implementation strategies but you are evaluating the outcomes of exposure to a program or policy implemented by others (e.g., natural experiment), how will you measure key differences in implementation variation such as by time, population, setting/location, dose or, content? 
Not applicable.
";s:5:"xhtml";s:3857:"Lyons Assignment #5:<br />1.	If relevant, what are the specific implementation strategies that you will be focusing on in your proposed research and how have you selected them?<br />The feedback from assignment 4 has helped me to think of the study design as a Type I hybrid trial where I will primarily be monitoring the effectiveness of the intervention, while gathering information about the implementation process. It would be important to establish the effectiveness of the intervention itself because of two adaptations we have made: a) tailoring the content to include only symptom management strategies that are locally available and b) not providing a workbook to the patients (i.e., information is delivered via nurse as opposed to what occurred in the North American studies which was closer to self-management that was guided by a nurse). <br /><br />As such, I’m not certain that I will have a specific implementation strategy that I will be evaluating. That said, I am thinking of using training (for the nurses) and provision of feedback/auditing (from and for the nurses in addition to for the clinical team) as a way to build competence (in the nurses delivering the intervention) and motivation for entire team to sustain the intervention. I am thinking that is important because while the nurses in the pilot study enjoyed expanding their skill set they also reported a lack of time to complete the symptom management telephone calls. In addition to solving the system level problem of how to find the time for intervention delivery, I think the feedback will be important so that the whole team understands the way in which the intervention could contribute to helping patients adhere to treatment. Of course, that will only serve as a motivation if the intervention goes well and has the degree of effectiveness we saw in other settings… <br /><br />In terms of an implementation strategy that would help with the lack of time to deliver the intervention, I have been studying the readings in an attempt for ideas to address that barrier. The only things I can think of at the moment are “role revision” (a strategy noted in the category of supporting clinicians in the slide deck) and changing the infrastructure in some way. There is a new director of nursing being hired at the Honduran facility, so we will need to do some preparatory work with her/him and  the local team, assessing readiness for change and engaging them in problem-solving these challenges. To be honest, I am no longer certain that this particular project will be the one they choose as the vehicle to continue collaborating with us (it depends on the priorities of the new director), but I am continuing to work on the concept of this proposal because the approach and measures may be transferable to other lines of research we might pursue with them.<br /><br />2.	How might you link specific implementation strategies to the context in which your work is set?<br />I will need to find a way to capitalize on existing meetings or processes if we are going to use feedback and auditing to enhance uptake or try to promote sustainability. For example, I am imaging that if nurses had some formal way to summarize/report back about patient symptom management needs and successes during chemotherapy visits then it would make any improvements (or deficits) salient for providers and that might help everyone see and understand the way in which proactive symptom management is designed to work.<br /><br />3.	If your proposed study does not involve selecting implementation strategies but you are evaluating the outcomes of exposure to a program or policy implemented by others (e.g., natural experiment), how will you measure key differences in implementation variation such as by time, population, setting/location, dose or, content? <br />Not applicable.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"5e0c74a427298705a68e0bae03259a12";}s:4:"show";b:1;s:3:"cid";s:32:"a2ce9061c1dcaa3d8fadf05d4d6c1d38";}s:32:"cf5fddebc19817d21890f65f97ab06b0";a:8:{s:4:"user";a:5:{s:2:"id";s:10:"ldimartino";s:4:"name";s:14:"Lisa DiMartino";s:4:"mail";s:18:"ldimartino@rti.org";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1539975567;}s:3:"raw";s:3933:"DiMartino - Assignment #5


1.If relevant, what are the specific implementation strategies that you will be focusing on in your proposed research and how have you selected them?

Implementation strategies are the methods or approaches to enhance the adoption, implementation and maintenance of interventions within healthcare settings.  The clinical decision support (CDS) tool using machine learning is the implementation strategy that I will be focusing on developing and testing in the pilot study to improve the use of palliative care in inpatient oncology at UNC Hospitals.  I selected this as the strategy because prior research indicates that implementation of manualized clinical “triggers” can improve use of palliative care services, while machine learning can help to make the CDS recommendations more personalized and patient-specific.  CDS tools fall under the ERIC strategy to “remind clinicians” and is a quality management strategy.  Consistent with the Powell et al definition, the intent of the tool is to prompt or remind clinicians to use palliative care services (the clinical innovation) for hospitalized cancer patients. In my study, the CDS tool is defined as an automated electronic health record (EHR) generated reminder that uses machine learning algorithms to efficiently identify hospitalized cancer patients who need palliative care services based on clinical criteria in the EHR.

As described in Module #2, I also intend to gather feedback from stakeholders before the tool is developed.  This will be accomplished by obtaining data on the barriers and facilitators to how the machine learning algorithms could potentially be incorporated into an actual CDS tool and exploring how the tool could be adapted to work with other institutions’ EHRs and workflows.  This is consistent with the ERIC planning strategy to “tailor strategies to overcome barriers”.  

2. How might you link specific implementation strategies to the context in which your work is set?

I would link the CDS tool using machine learning (the implementation strategy) to the context of where the work is set  (inpatient oncology settings) by clearly specifying the strategy to understand how and why it is effective in that particular context. I would do this by operationalizing or specifying the strategy across the seven dimensions described by Proctor et al.: 
1) the actor, or stakeholder responsible for delivering the CDS tool.  I anticipate this would be the oncology physicians who are able to refer patients for palliative care services.  This may also be house staff (residents, fellows) and oncology nurses;  2) the actions involved; 3) the action target.  For example, the tool may target clinician skills for identifying patients who need palliative care; 4) temporality. For example, the tool may be introduced only following training; 5) dose; 6) implementation outcome affected (e.g., uptake of palliative care); 7) justification.   

One of the objectives of the pilot study will be to report on these 7 dimensions and to identify and select additional strategies to support the adoption of the CDS tool and promote use of palliative care.  The information gathered from the pilot using the Theoretical Domains Framework will help to further develop strategies across the various categories (e.g., plan, educate, restructure, quality management).   I will then use intervention mapping to develop strategies based on the findings from the qualitative analyses in the pilot that could be tested in a larger hybrid - effectiveness implementation trial. 

3.If your proposed study does not involve selecting implementation strategies but you are evaluating the outcomes of exposure to a program or policy implemented by others (e.g., natural experiment), how will you measure key differences in implementation variation such as by time, population, setting/location, dose or, content?
Not applicable.
";s:5:"xhtml";s:4017:"DiMartino - Assignment #5<br /><br /><br />1.If relevant, what are the specific implementation strategies that you will be focusing on in your proposed research and how have you selected them?<br /><br />Implementation strategies are the methods or approaches to enhance the adoption, implementation and maintenance of interventions within healthcare settings.  The clinical decision support (CDS) tool using machine learning is the implementation strategy that I will be focusing on developing and testing in the pilot study to improve the use of palliative care in inpatient oncology at UNC Hospitals.  I selected this as the strategy because prior research indicates that implementation of manualized clinical “triggers” can improve use of palliative care services, while machine learning can help to make the CDS recommendations more personalized and patient-specific.  CDS tools fall under the ERIC strategy to “remind clinicians” and is a quality management strategy.  Consistent with the Powell et al definition, the intent of the tool is to prompt or remind clinicians to use palliative care services (the clinical innovation) for hospitalized cancer patients. In my study, the CDS tool is defined as an automated electronic health record (EHR) generated reminder that uses machine learning algorithms to efficiently identify hospitalized cancer patients who need palliative care services based on clinical criteria in the EHR.<br /><br />As described in Module #2, I also intend to gather feedback from stakeholders before the tool is developed.  This will be accomplished by obtaining data on the barriers and facilitators to how the machine learning algorithms could potentially be incorporated into an actual CDS tool and exploring how the tool could be adapted to work with other institutions’ EHRs and workflows.  This is consistent with the ERIC planning strategy to “tailor strategies to overcome barriers”.  <br /><br />2. How might you link specific implementation strategies to the context in which your work is set?<br /><br />I would link the CDS tool using machine learning (the implementation strategy) to the context of where the work is set  (inpatient oncology settings) by clearly specifying the strategy to understand how and why it is effective in that particular context. I would do this by operationalizing or specifying the strategy across the seven dimensions described by Proctor et al.: <br />1) the actor, or stakeholder responsible for delivering the CDS tool.  I anticipate this would be the oncology physicians who are able to refer patients for palliative care services.  This may also be house staff (residents, fellows) and oncology nurses;  2) the actions involved; 3) the action target.  For example, the tool may target clinician skills for identifying patients who need palliative care; 4) temporality. For example, the tool may be introduced only following training; 5) dose; 6) implementation outcome affected (e.g., uptake of palliative care); 7) justification.   <br /><br />One of the objectives of the pilot study will be to report on these 7 dimensions and to identify and select additional strategies to support the adoption of the CDS tool and promote use of palliative care.  The information gathered from the pilot using the Theoretical Domains Framework will help to further develop strategies across the various categories (e.g., plan, educate, restructure, quality management).   I will then use intervention mapping to develop strategies based on the findings from the qualitative analyses in the pilot that could be tested in a larger hybrid - effectiveness implementation trial. <br /><br />3.If your proposed study does not involve selecting implementation strategies but you are evaluating the outcomes of exposure to a program or policy implemented by others (e.g., natural experiment), how will you measure key differences in implementation variation such as by time, population, setting/location, dose or, content?<br />Not applicable.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"60542e19e4d8811c12a868533ea813f6";}s:4:"show";b:1;s:3:"cid";s:32:"cf5fddebc19817d21890f65f97ab06b0";}s:32:"7e5cb32557cf4678cbd001e585c67250";a:8:{s:4:"user";a:5:{s:2:"id";s:9:"aibraheem";s:4:"name";s:15:"Abiola Ibraheem";s:4:"mail";s:35:"aibraheem@medicine.bsd.uchicago.edu";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1539976423;}s:3:"raw";s:1965:"Ibraheem Assignment 4 .
I posted this assignment last week- I can not see it on the site. I hope it is not showing up 2x 


1) What is your proposed study design? Why is that the best design to answer your research questions or hypotheses?

I plan to use the stepped- wedge cluster RCT. 
We plan to conduct a feasibility Phase 2 neoadjuvant study in early-stage HER 2 breast cancer using 4 institutions in the southwest of Nigeria. Therefore to increase awareness to oncology clinical trials in these institutions is key (not only in to improve accrual), but it is important all healthcare providers have a basic understanding of what clinical trial is and also its availability in the center. 
I will first start in a center (LASUTH), comparing the proposed outcomes of our intervention with other centers. After this, we will pick the next center and lastly the two other centers concurrently. 

To the previous question of how I will measure the processes I have chosen ( this can be measured by audio recording, pre- and post intervention measured by the use of questionnaires which is expected to show a statistical increase in knowledge after being trained by our purveyor team. 

2) Will you be incorporating a mixed methods design into your study? If so, what approach will you use to incorporate the qualitative data into the study (e.g., integrate the quantitative and qualitative data to inform your aims? If not, why? 
Yes, mixed methods design has been incorporated into the study from the beginning. We initially collected data from few healthcare providers quantitatively assessing perceived barriers against clinical trials. The choice of the surveyed questionnaire used was adapted from barriers known to reduce minority participation in clinical trials. 
Using our purveyor team to help gain access and confidence with our participants, we would qualitatively explore the concerns and barriers raised by the subjects concerning clinical trials. 

";s:5:"xhtml";s:2032:"Ibraheem Assignment 4 .<br />I posted this assignment last week- I can not see it on the site. I hope it is not showing up 2x <br /><br /><br />1) What is your proposed study design? Why is that the best design to answer your research questions or hypotheses?<br /><br />I plan to use the stepped- wedge cluster RCT. <br />We plan to conduct a feasibility Phase 2 neoadjuvant study in early-stage HER 2 breast cancer using 4 institutions in the southwest of Nigeria. Therefore to increase awareness to oncology clinical trials in these institutions is key (not only in to improve accrual), but it is important all healthcare providers have a basic understanding of what clinical trial is and also its availability in the center. <br />I will first start in a center (LASUTH), comparing the proposed outcomes of our intervention with other centers. After this, we will pick the next center and lastly the two other centers concurrently. <br /><br />To the previous question of how I will measure the processes I have chosen ( this can be measured by audio recording, pre- and post intervention measured by the use of questionnaires which is expected to show a statistical increase in knowledge after being trained by our purveyor team. <br /><br />2) Will you be incorporating a mixed methods design into your study? If so, what approach will you use to incorporate the qualitative data into the study (e.g., integrate the quantitative and qualitative data to inform your aims? If not, why? <br />Yes, mixed methods design has been incorporated into the study from the beginning. We initially collected data from few healthcare providers quantitatively assessing perceived barriers against clinical trials. The choice of the surveyed questionnaire used was adapted from barriers known to reduce minority participation in clinical trials. <br />Using our purveyor team to help gain access and confidence with our participants, we would qualitatively explore the concerns and barriers raised by the subjects concerning clinical trials.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"b440a0235764bdc1ec97a793e9925558";}s:4:"show";b:1;s:3:"cid";s:32:"7e5cb32557cf4678cbd001e585c67250";}s:32:"8f12a656a35109071e6bbafa135a8819";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"lpace";s:4:"name";s:10:"Lydia Pace";s:4:"mail";s:21:"LPACE@BWH.HARVARD.EDU";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1539979523;}s:3:"raw";s:2968:"Pace, Assignment 5

1.If relevant, what are the specific implementation strategies that you will be focusing on in your proposed research and how have you selected them?

We will be studying a program whose implementation we have contributed to (an adaptation of our pilot) – so I think that considering the specific implementation strategies being used is important in order to identify the “active ingredients” or “building blocks” of the project, and refine my evaluation strategy.

The implementation strategies are:
a) Scale-up of our previous breast health early detection project trainings, adapting them to 2 new districts:
-use train-the-trainer strategies
-Conduct ongoing training
-Develop educational materials
-make training dynamic
-provide clinical supervision
-visit other sites

b) Establish weekly breast clinics in the new health centers and hospital and support patient navigation and tracking 
-identify and prepare champions
-facilitate relay of clinical data to providers
-develop and implement tools for quality monitoring
-promote network weaving
-purposely reexamine the implementation

2.How might you link specific implementation strategies to the context in which your work is set?
All of these strategies are very much tailored to the rural Rwandan health center and district hospital context, though I think we do need to ensure that we are continually revising our model to respond to challenges. For example – we are training every health center nurse in each health center because of the frequency of staff turnover and the challenge of assigning specific nurses to be always staffing specific clinics. Also, in this scaleup period, we adapted the trainings to be “on-site” at the health centers, and occur at the end of nurses’ workdays, instead of taking them away entirely from their usual work. Overall, key challenges in this limited resource setting are making the early detection program sustainable in an underresourced system and maintain knowledge in busy staff.

3.If your proposed study does not involve selecting implementational strategies but you are evaluating the outcomes of exposure to a program or policy implemented by others (e.g., natural experiment), how will you measure key differences in implementation variation such as by time, population, setting/location, dose or, content?
This is a good question. In some ways this was part of the outcomes that I was hoping to examine – eg how regularly are these clinics happening in each health center, how many patients are coming, etc. I think even though we were part of selecting the strategies, there will inevitably be differences in implementation in our 2 districts, and health center to health center. I think the best way to do this will be by surveying weekly (monthly?) the champions we’ve identified at each health center and asking about the clinics that occurred. We will need to also look at the frequency of mentoring visits.
";s:5:"xhtml";s:3097:"Pace, Assignment 5<br /><br />1.If relevant, what are the specific implementation strategies that you will be focusing on in your proposed research and how have you selected them?<br /><br />We will be studying a program whose implementation we have contributed to (an adaptation of our pilot) – so I think that considering the specific implementation strategies being used is important in order to identify the “active ingredients” or “building blocks” of the project, and refine my evaluation strategy.<br /><br />The implementation strategies are:<br />a) Scale-up of our previous breast health early detection project trainings, adapting them to 2 new districts:<br />-use train-the-trainer strategies<br />-Conduct ongoing training<br />-Develop educational materials<br />-make training dynamic<br />-provide clinical supervision<br />-visit other sites<br /><br />b) Establish weekly breast clinics in the new health centers and hospital and support patient navigation and tracking <br />-identify and prepare champions<br />-facilitate relay of clinical data to providers<br />-develop and implement tools for quality monitoring<br />-promote network weaving<br />-purposely reexamine the implementation<br /><br />2.How might you link specific implementation strategies to the context in which your work is set?<br />All of these strategies are very much tailored to the rural Rwandan health center and district hospital context, though I think we do need to ensure that we are continually revising our model to respond to challenges. For example – we are training every health center nurse in each health center because of the frequency of staff turnover and the challenge of assigning specific nurses to be always staffing specific clinics. Also, in this scaleup period, we adapted the trainings to be “on-site” at the health centers, and occur at the end of nurses’ workdays, instead of taking them away entirely from their usual work. Overall, key challenges in this limited resource setting are making the early detection program sustainable in an underresourced system and maintain knowledge in busy staff.<br /><br />3.If your proposed study does not involve selecting implementational strategies but you are evaluating the outcomes of exposure to a program or policy implemented by others (e.g., natural experiment), how will you measure key differences in implementation variation such as by time, population, setting/location, dose or, content?<br />This is a good question. In some ways this was part of the outcomes that I was hoping to examine – eg how regularly are these clinics happening in each health center, how many patients are coming, etc. I think even though we were part of selecting the strategies, there will inevitably be differences in implementation in our 2 districts, and health center to health center. I think the best way to do this will be by surveying weekly (monthly?) the champions we’ve identified at each health center and asking about the clinics that occurred. We will need to also look at the frequency of mentoring visits.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"f0ca67e4ea599386c8601c2d8cf48a13";}s:4:"show";b:1;s:3:"cid";s:32:"8f12a656a35109071e6bbafa135a8819";}s:32:"da1638919e38e681a361c3dd849abc6d";a:8:{s:4:"user";a:5:{s:2:"id";s:9:"aibraheem";s:4:"name";s:15:"Abiola Ibraheem";s:4:"mail";s:35:"aibraheem@medicine.bsd.uchicago.edu";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1539985068;}s:3:"raw";s:2203:"Ibraheem Assignment 5

1.	If relevant, what are the specific implementation strategies that you will be focusing on in your proposed research and how have you selected them?
My pre-identified determinants from my preliminary pilot study showed lack of knowledge about clinical trials, lack of motivation (overworked physicians seeing up to 50 patients daily were not enthusiastic about discussing clinical trials with patients) and the poor attitudes of providers. Taking all these pre-identified determinants, I plan to address them with the use of the purveyor team as this team will represent all providers (nurses, physicians, technicians, clerks etc) and the choice of the team will also include opinionated or identified leaders or respected persons. I will use the influence of our team, collaborative interactive tailored education sessions with the team.


2.	How might you link specific implementation strategies to the context in which your work is set?
As I earlier said in assignment #3, I will use the I will use the Active implementation Framework also known as the Core Implementation Component framework to facilitate my implementation strategy. I will be using a multifaceted implementation strategy which encompasses 3 categories namely 
(i)	Developing stakeholder relationships- Using our purveyor team, we will build a relationship and trust amongst the healthcare providers as this is important to address the known barriers of mistrust, concerns of being used as guinea pig, fear of the unknown which has been reported in literature. 
(ii)	Training and educating the stakeholders- This will appropriately inform health care providers about clinical trials. Using the gathered information from our preliminary studies where we found a baseline poor knowledge and attitude to clinical trials, we will conduct ongoing training, collaborating with our purveyor team to develop educational materials. 
(iii)	Supporting the target group- Our target group is all health care providers working in parts of the hospital where cancer patients are mostly encountered (family practice, surgery, clin/radoncology). This is because in most centers, there is no clearly defined oncology unit. 

";s:5:"xhtml";s:2250:"Ibraheem Assignment 5<br /><br />1.	If relevant, what are the specific implementation strategies that you will be focusing on in your proposed research and how have you selected them?<br />My pre-identified determinants from my preliminary pilot study showed lack of knowledge about clinical trials, lack of motivation (overworked physicians seeing up to 50 patients daily were not enthusiastic about discussing clinical trials with patients) and the poor attitudes of providers. Taking all these pre-identified determinants, I plan to address them with the use of the purveyor team as this team will represent all providers (nurses, physicians, technicians, clerks etc) and the choice of the team will also include opinionated or identified leaders or respected persons. I will use the influence of our team, collaborative interactive tailored education sessions with the team.<br /><br /><br />2.	How might you link specific implementation strategies to the context in which your work is set?<br />As I earlier said in assignment #3, I will use the I will use the Active implementation Framework also known as the Core Implementation Component framework to facilitate my implementation strategy. I will be using a multifaceted implementation strategy which encompasses 3 categories namely <br />(i)	Developing stakeholder relationships- Using our purveyor team, we will build a relationship and trust amongst the healthcare providers as this is important to address the known barriers of mistrust, concerns of being used as guinea pig, fear of the unknown which has been reported in literature. <br />(ii)	Training and educating the stakeholders- This will appropriately inform health care providers about clinical trials. Using the gathered information from our preliminary studies where we found a baseline poor knowledge and attitude to clinical trials, we will conduct ongoing training, collaborating with our purveyor team to develop educational materials. <br />(iii)	Supporting the target group- Our target group is all health care providers working in parts of the hospital where cancer patients are mostly encountered (family practice, surgery, clin/radoncology). This is because in most centers, there is no clearly defined oncology unit.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"4450fee4a5ad744ae4706ddbbfe9fe95";}s:4:"show";b:1;s:3:"cid";s:32:"da1638919e38e681a361c3dd849abc6d";}s:32:"b440a0235764bdc1ec97a793e9925558";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"gneta";s:4:"name";s:9:"Gila Neta";s:4:"mail";s:20:"netagil@mail.nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1540041816;}s:3:"raw";s:472:"Thanks, Abiola. A clarifying question: What design will you use to test your strategy to increase accrual? My understanding is that the stepped wedge cluster RCT is for the chemotherapy trial, no? If your study proposal for TIDIRH is focused on testing a strategy to increase CT accrual, what designs would you use to do that? 

And good re: mixed methods. So it sounds like this is applied to your accrual study. But how might you be integrating your qual and quant here?";s:5:"xhtml";s:482:"Thanks, Abiola. A clarifying question: What design will you use to test your strategy to increase accrual? My understanding is that the stepped wedge cluster RCT is for the chemotherapy trial, no? If your study proposal for TIDIRH is focused on testing a strategy to increase CT accrual, what designs would you use to do that? <br /><br />And good re: mixed methods. So it sounds like this is applied to your accrual study. But how might you be integrating your qual and quant here?";s:6:"parent";s:32:"7e5cb32557cf4678cbd001e585c67250";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"b440a0235764bdc1ec97a793e9925558";}s:32:"f5ba0d1e3871d35f55cef0091038c33e";a:8:{s:4:"user";a:5:{s:2:"id";s:8:"khuggins";s:4:"name";s:12:"Kate Huggins";s:4:"mail";s:23:"kate.huggins@monash.edu";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1540119884;}s:3:"raw";s:2952:"Huggins_Assignment 5

In this study, two service delivery models (mHealth and tele-health) are being trialled to provide effective nutrition care. Prior to study commencement a site audit was undertaken. The intervention was co-designed with key stakeholders including an academic unit. This early development work advances readiness at the site where the trial is operating. Having a research team that is active and committed to trialling and championing these methods may, therefore make our context different from other sites where the intervention will be implemented. Facilitation or change agents could be an important strategy for implementation in other contexts. Dietitians at intervention sites will need support and training in how to communicate effectively with patients using mHealth. Usually dietetic consultations are face-to-face, whereas in this study we are using asynchronous communication. Behaviour change strategies will be used in intervention delivery (clinician to patient), but will also be important for shifting dietitians from face-to-face delivery to mHealth asynchronous delivery. When implementing early and frequent nutrition intervention in other contexts, pre-implementation audit and feedback may be useful to understand the current usual care processes including communication and referral. It will also be necessary to understand what knowledge and beliefs the stakeholders have of the nutrition intervention (e.g oncologists, surgeons). It will also be important to evaluate the knowledge and trust that the dietitians have in mHealth as an effective delivery mode for providing their service. 

Examining the contextual factors at active sites is expected to inform what factors need consideration at future sites. 

Name & definition: Assessment of contextual factors that influence implementation of early nutrition care
Domain Strategy: tele-health (synchronous) and mHealth (asynchronous) delivery of early nutrition intervention
Actor(s): MDT team (surgeons, physicians), dietitian who is expert in managing people undergoing treatment of upper GI cancer, patient 
Action(s): Referral to dietetics service; use of behaviour change techniques to achieve nutrition goals
Target of the action: People newly diagnosed with upper GI cancer
Temporality: Commence as soon as practical after time of diagnosis
Dose:	At least fortnightly for 18 weeks
Implementation outcomes affected: Fidelity to the standard operating protocol, reach among eligible participants, adaptation, acceptance, engagement.

Justification: Research into consumer and practitioner use of, and attitudes towards, integrating technology into healthcare suggests that the right applications are positively accepted by both sets of users (Kelders et al 2011). Further, healthcare systems in Europe and the United States are currently actively encouraging and investing in technological innovations to enhance routine care (Webb et al. 2010).
";s:5:"xhtml";s:3030:"Huggins_Assignment 5<br /><br />In this study, two service delivery models (mHealth and tele-health) are being trialled to provide effective nutrition care. Prior to study commencement a site audit was undertaken. The intervention was co-designed with key stakeholders including an academic unit. This early development work advances readiness at the site where the trial is operating. Having a research team that is active and committed to trialling and championing these methods may, therefore make our context different from other sites where the intervention will be implemented. Facilitation or change agents could be an important strategy for implementation in other contexts. Dietitians at intervention sites will need support and training in how to communicate effectively with patients using mHealth. Usually dietetic consultations are face-to-face, whereas in this study we are using asynchronous communication. Behaviour change strategies will be used in intervention delivery (clinician to patient), but will also be important for shifting dietitians from face-to-face delivery to mHealth asynchronous delivery. When implementing early and frequent nutrition intervention in other contexts, pre-implementation audit and feedback may be useful to understand the current usual care processes including communication and referral. It will also be necessary to understand what knowledge and beliefs the stakeholders have of the nutrition intervention (e.g oncologists, surgeons). It will also be important to evaluate the knowledge and trust that the dietitians have in mHealth as an effective delivery mode for providing their service. <br /><br />Examining the contextual factors at active sites is expected to inform what factors need consideration at future sites. <br /><br />Name &amp; definition: Assessment of contextual factors that influence implementation of early nutrition care<br />Domain Strategy: tele-health (synchronous) and mHealth (asynchronous) delivery of early nutrition intervention<br />Actor(s): MDT team (surgeons, physicians), dietitian who is expert in managing people undergoing treatment of upper GI cancer, patient <br />Action(s): Referral to dietetics service; use of behaviour change techniques to achieve nutrition goals<br />Target of the action: People newly diagnosed with upper GI cancer<br />Temporality: Commence as soon as practical after time of diagnosis<br />Dose:	At least fortnightly for 18 weeks<br />Implementation outcomes affected: Fidelity to the standard operating protocol, reach among eligible participants, adaptation, acceptance, engagement.<br /><br />Justification: Research into consumer and practitioner use of, and attitudes towards, integrating technology into healthcare suggests that the right applications are positively accepted by both sets of users (Kelders et al 2011). Further, healthcare systems in Europe and the United States are currently actively encouraging and investing in technological innovations to enhance routine care (Webb et al. 2010).";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"c9b24390060759260fad27a4ee8ee085";}s:4:"show";b:1;s:3:"cid";s:32:"f5ba0d1e3871d35f55cef0091038c33e";}s:32:"27922f7876f5c3d410f18412f8a562f8";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"lreinke";s:4:"name";s:11:"Lynn Reinke";s:4:"mail";s:19:"Lynn.Reinke1@va.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1540171500;}s:3:"raw";s:4134:"Reinke Assignment #5:
1. If relevant, what are the specific implementation strategies that you will be focusing on in your proposed research and how have you selected them?

SA 2: Among 4 VISNs, test an implementation strategy of a nurse-led palliative care intervention on provider education, champion engagement, marketing and cost estimates to facilitate adoption, fidelity and sustainability of the palliative care intervention.  

This aim will be accomplished by applying mixed methods. We will conduct interviews and focus groups with stakeholders (nurses, physicians, administrators/leaders) to identify factors important to implementing evidence-based, nurse-led palliative care interventions.  Depending on the results of our interviews, we will tailor our proposed implementation strategies to match the needs of the stakeholders. For example, if oncologists are resistant to integrate palliative care interventions into lung cancer care, we will seek support from peers that are cross-trained in oncology and palliative care to become involved in meetings.

We prospectively select the following strategies and provide the rationale for the strategy.

1.	Evaluation and iterative – assess the readiness among the oncology teams; identify barriers and facilitators, conduct regular stakeholder meetings to audit the implementation process and receive and offer feedback.
2.	Adapt the evidence-based interventions to the context and culture of the facility. E.g. incorporating protocols into oncology nurse navigators’ workflow.
3.	Develop and maintain stakeholder relationships (nurses, physicians, administrators/leaders)
4.	Train/educate stakeholders on the content of the protocols.
5.	Supporting clinicians, specifically nurses, to work at their highest scope of practice and independence. Help decrease physician workload by having the nurse serve as a liaison between the patient and physician in between face to face visits.
6.	Engaging consumers. We will ask patients from our efficacy trial to share their perspectives of benefits received from the program. We will engage local community lung cancer patient groups to advocate for program availability.
7.	Financial. We will track nurse FTEs to implement the program; time savings for physicians’ workload; patient use of supportive resources, such as acupuncture sessions to manage pain, ED visits for symptom management. We will seek formal funding to advance implementation and dissemination efforts. 


2. How might you link specific implementation strategies to the context in which your work is set?

All VISNs in which we will test the nurse-led intervention have oncology nurse navigators. Their role is to identify newly diagnosed cancer patients (lung, head/neck and GI – most prevalence cancers among veterans) and conduct 1-2 face to face or telephone visits to identify specific patient needs and coordinate follow up care/resources. Our goal is to leverage these existing programs and expand them to incorporate our evidence based intervention (symptom assessment and management, conducting goals of care conversations, providing education on lung cancer treatments and family caregiver support.)  Incorporation of our intervention will take more time, clinician education and possibly human resources. We will need to learn the current workflow and adapt it to include our intervention. The intervention packet is currently 8 telephone calls over 3 months which may not be feasible depending on caseloads and nurse FTEs. We will need to condense visits and content based on workload. An advantage is that we have developed and tested standardized templates for patient EHR notes and physician recommendation orders which saves time and should facilitate nurse uptake of the intervention.   

3. If your proposed study does not involve selecting implementation strategies but you are evaluating the outcomes of exposure to a program or policy implemented by others (e.g., natural experiment), how will you measure key differences in implementation variation such as by time, population, setting/location, dose or, content? 
Not applicable. 
";s:5:"xhtml";s:4247:"Reinke Assignment #5:<br />1. If relevant, what are the specific implementation strategies that you will be focusing on in your proposed research and how have you selected them?<br /><br />SA 2: Among 4 VISNs, test an implementation strategy of a nurse-led palliative care intervention on provider education, champion engagement, marketing and cost estimates to facilitate adoption, fidelity and sustainability of the palliative care intervention.  <br /><br />This aim will be accomplished by applying mixed methods. We will conduct interviews and focus groups with stakeholders (nurses, physicians, administrators/leaders) to identify factors important to implementing evidence-based, nurse-led palliative care interventions.  Depending on the results of our interviews, we will tailor our proposed implementation strategies to match the needs of the stakeholders. For example, if oncologists are resistant to integrate palliative care interventions into lung cancer care, we will seek support from peers that are cross-trained in oncology and palliative care to become involved in meetings.<br /><br />We prospectively select the following strategies and provide the rationale for the strategy.<br /><br />1.	Evaluation and iterative – assess the readiness among the oncology teams; identify barriers and facilitators, conduct regular stakeholder meetings to audit the implementation process and receive and offer feedback.<br />2.	Adapt the evidence-based interventions to the context and culture of the facility. E.g. incorporating protocols into oncology nurse navigators’ workflow.<br />3.	Develop and maintain stakeholder relationships (nurses, physicians, administrators/leaders)<br />4.	Train/educate stakeholders on the content of the protocols.<br />5.	Supporting clinicians, specifically nurses, to work at their highest scope of practice and independence. Help decrease physician workload by having the nurse serve as a liaison between the patient and physician in between face to face visits.<br />6.	Engaging consumers. We will ask patients from our efficacy trial to share their perspectives of benefits received from the program. We will engage local community lung cancer patient groups to advocate for program availability.<br />7.	Financial. We will track nurse FTEs to implement the program; time savings for physicians’ workload; patient use of supportive resources, such as acupuncture sessions to manage pain, ED visits for symptom management. We will seek formal funding to advance implementation and dissemination efforts. <br /><br /><br />2. How might you link specific implementation strategies to the context in which your work is set?<br /><br />All VISNs in which we will test the nurse-led intervention have oncology nurse navigators. Their role is to identify newly diagnosed cancer patients (lung, head/neck and GI – most prevalence cancers among veterans) and conduct 1-2 face to face or telephone visits to identify specific patient needs and coordinate follow up care/resources. Our goal is to leverage these existing programs and expand them to incorporate our evidence based intervention (symptom assessment and management, conducting goals of care conversations, providing education on lung cancer treatments and family caregiver support.)  Incorporation of our intervention will take more time, clinician education and possibly human resources. We will need to learn the current workflow and adapt it to include our intervention. The intervention packet is currently 8 telephone calls over 3 months which may not be feasible depending on caseloads and nurse FTEs. We will need to condense visits and content based on workload. An advantage is that we have developed and tested standardized templates for patient EHR notes and physician recommendation orders which saves time and should facilitate nurse uptake of the intervention.   <br /><br />3. If your proposed study does not involve selecting implementation strategies but you are evaluating the outcomes of exposure to a program or policy implemented by others (e.g., natural experiment), how will you measure key differences in implementation variation such as by time, population, setting/location, dose or, content? <br />Not applicable.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"f6540f498a984f9493b238f1c29329e2";}s:4:"show";b:1;s:3:"cid";s:32:"27922f7876f5c3d410f18412f8a562f8";}s:32:"5f879b293c49cf3cbf4d092ccd51ba61";a:8:{s:4:"user";a:5:{s:2:"id";s:10:"moluwasanu";s:4:"name";s:18:"Mojisola Oluwasanu";s:4:"mail";s:15:"ope3m@yahoo.com";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1540394616;}s:3:"raw";s:4350:"1)	If relevant, what are the specific implementation strategies that you will be focusing on in your proposed research and how have you selected them?
The goal of the study is to utilize a cluster randomized, hybrid effectiveness/implementation trial, type I design to investigate the effect of an integrated, HIV and Breast Cancer (BC) multi-component, intervention on the breast health preventive behaviors and screening practices for HIV and BC among female informal workers. The proposed implementation strategies are as follow:
Evaluation and iterative strategies:
The community readiness for the intervention will be assessed using the Community Readiness Model (Plested, 2006).  This model has six domains: Community effort on the issue (in this case HIV and BC), Community knowledge of the efforts, Leadership, Community Climate, Community Knowledge about the Issue and Resources Related to the Issue. This implementation strategy is important and it will help to analyze and match the community with the HIV and BC intervention. In addition, the community’s readiness assessment helps identify determine the degree of readiness to implement, barriers that may impede implementation, and strengths that can be used in the implementation effort
Adapting and tailoring to context
The proposed HIV&BC intervention will tailored to the Nigerian context. Two EBI will be integrated - the Combination Prevention - an evidence-based approach for HIV risk reduction and testing and a Research-Tested Intervention Program of the NCI - Life is Precious-Hmong Breast Health Study. The Combination Prevention has been implemented and disseminated among Nigerians. However, the Life is Precious-Hmong Breast Health Study was used for a minority population in the US. To make it relevant to the Nigerian context, there will be adaptations to the content, format and language throughout the study lifespan guided by the Stirman framework and coding system.
Train/educate stakeholders and Distribute educational materials
There will be training programs for artisan peer influencers on breast health promotion,  breast cancer risk factors, symptoms , age-appropriate BC screening,  HIV risk reduction and HIV testing. This is important because the peer influencers have not had experience delivering and motivating peers for BC screening. This is critical for the adoption of this innovation. Though a significant proportion of artisans have participated in HIV programs, there is a need for refresher training.  There will be ongoing training programs to address gaps in HIV and BC knowledge and counseling skills. 
In addition to this, culturally relevant educational materials will be developed and distributed and I am still contemplating the use of videos on Whatsapp to reinforce knowledge and important skills for HIV and BC prevention.

Develop stakeholder relationships
The artisan peer influencers will be identified through a participatory process involving members of the groups and the researches in line with the concept of peer education. They will be trained to lead, support and drive the implementation. This is expected to help sustain the initiative.
Phased Implementation
The implementation will be phased starting with pilot testing and eventual scale up 
The selection of the implementation strategies was based on my experience working with this population as well as evidence from literature.
2) How might you link specific implementation strategies to the context in which your work is set?
This study will be implemented among low literate females in the informal work sector and some context can be linked to the implementation strategies proposed. For instance, the low level of literacy underscores the need for culturally and linguistically appropriate educational materials. In addition,. they have nationwide membership and resources which can be leverage for the implementation of this intervention. Though they belong to the informal sector, they have regular meetings, policies and governance which can aid D&I efforts. In addition, the women have natural leaders within their network who they respect and these can serve as “Artisans Peer Influencers”. Finally, the nationwide membership supports the use of a phased implementation if the initial study demonstrates a reasonable level of adoption and feasibility. 
";s:5:"xhtml";s:4436:"1)	If relevant, what are the specific implementation strategies that you will be focusing on in your proposed research and how have you selected them?<br />The goal of the study is to utilize a cluster randomized, hybrid effectiveness/implementation trial, type I design to investigate the effect of an integrated, HIV and Breast Cancer (BC) multi-component, intervention on the breast health preventive behaviors and screening practices for HIV and BC among female informal workers. The proposed implementation strategies are as follow:<br />Evaluation and iterative strategies:<br />The community readiness for the intervention will be assessed using the Community Readiness Model (Plested, 2006).  This model has six domains: Community effort on the issue (in this case HIV and BC), Community knowledge of the efforts, Leadership, Community Climate, Community Knowledge about the Issue and Resources Related to the Issue. This implementation strategy is important and it will help to analyze and match the community with the HIV and BC intervention. In addition, the community’s readiness assessment helps identify determine the degree of readiness to implement, barriers that may impede implementation, and strengths that can be used in the implementation effort<br />Adapting and tailoring to context<br />The proposed HIV&amp;BC intervention will tailored to the Nigerian context. Two EBI will be integrated - the Combination Prevention - an evidence-based approach for HIV risk reduction and testing and a Research-Tested Intervention Program of the NCI - Life is Precious-Hmong Breast Health Study. The Combination Prevention has been implemented and disseminated among Nigerians. However, the Life is Precious-Hmong Breast Health Study was used for a minority population in the US. To make it relevant to the Nigerian context, there will be adaptations to the content, format and language throughout the study lifespan guided by the Stirman framework and coding system.<br />Train/educate stakeholders and Distribute educational materials<br />There will be training programs for artisan peer influencers on breast health promotion,  breast cancer risk factors, symptoms , age-appropriate BC screening,  HIV risk reduction and HIV testing. This is important because the peer influencers have not had experience delivering and motivating peers for BC screening. This is critical for the adoption of this innovation. Though a significant proportion of artisans have participated in HIV programs, there is a need for refresher training.  There will be ongoing training programs to address gaps in HIV and BC knowledge and counseling skills. <br />In addition to this, culturally relevant educational materials will be developed and distributed and I am still contemplating the use of videos on Whatsapp to reinforce knowledge and important skills for HIV and BC prevention.<br /><br />Develop stakeholder relationships<br />The artisan peer influencers will be identified through a participatory process involving members of the groups and the researches in line with the concept of peer education. They will be trained to lead, support and drive the implementation. This is expected to help sustain the initiative.<br />Phased Implementation<br />The implementation will be phased starting with pilot testing and eventual scale up <br />The selection of the implementation strategies was based on my experience working with this population as well as evidence from literature.<br />2) How might you link specific implementation strategies to the context in which your work is set?<br />This study will be implemented among low literate females in the informal work sector and some context can be linked to the implementation strategies proposed. For instance, the low level of literacy underscores the need for culturally and linguistically appropriate educational materials. In addition,. they have nationwide membership and resources which can be leverage for the implementation of this intervention. Though they belong to the informal sector, they have regular meetings, policies and governance which can aid D&amp;I efforts. In addition, the women have natural leaders within their network who they respect and these can serve as “Artisans Peer Influencers”. Finally, the nationwide membership supports the use of a phased implementation if the initial study demonstrates a reasonable level of adoption and feasibility.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"fb9cde57b21e8b67b9fc213ad87674f9";}s:4:"show";b:1;s:3:"cid";s:32:"5f879b293c49cf3cbf4d092ccd51ba61";}s:32:"4450fee4a5ad744ae4706ddbbfe9fe95";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"gneta";s:4:"name";s:9:"Gila Neta";s:4:"mail";s:20:"netagil@mail.nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1540414615;}s:3:"raw";s:507:"Good. I like how you are thinking about the barriers you are trying to overcome when selecting your strategies. One thing you might also want to start thinking about is not just how to educate providers, but also what strategies you might need to put in place (and what barriers might exist that you would need to overcome) in order to support trained providers to actually have a mechanism to refer their patients to trials. This might be a next step, but it's never too early to start thinking about it.  ";s:5:"xhtml";s:510:"Good. I like how you are thinking about the barriers you are trying to overcome when selecting your strategies. One thing you might also want to start thinking about is not just how to educate providers, but also what strategies you might need to put in place (and what barriers might exist that you would need to overcome) in order to support trained providers to actually have a mechanism to refer their patients to trials. This might be a next step, but it&#039;s never too early to start thinking about it.";s:6:"parent";s:32:"da1638919e38e681a361c3dd849abc6d";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"4450fee4a5ad744ae4706ddbbfe9fe95";}s:32:"5e0c74a427298705a68e0bae03259a12";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"gneta";s:4:"name";s:9:"Gila Neta";s:4:"mail";s:20:"netagil@mail.nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1540414912;}s:3:"raw";s:670:"Good. It does sound like you might be setting yourself up for a Type 2 in a way, since it sounds like you are thinking about strategies you could build in tests for, perhaps not as at large a scale as the effectiveness trial, but still you could think about piloting some of these strategies. And if you are leaning towards role revision, you might want to think about the implications for your effectiveness trial in terms of who should be delivering the intervention. Perhaps consider having an multi-arm trial where you test delivery by a nurse vs. another person, to see whether another health provider could more feasibly deliver the intervention. Just a thought...";s:5:"xhtml";s:670:"Good. It does sound like you might be setting yourself up for a Type 2 in a way, since it sounds like you are thinking about strategies you could build in tests for, perhaps not as at large a scale as the effectiveness trial, but still you could think about piloting some of these strategies. And if you are leaning towards role revision, you might want to think about the implications for your effectiveness trial in terms of who should be delivering the intervention. Perhaps consider having an multi-arm trial where you test delivery by a nurse vs. another person, to see whether another health provider could more feasibly deliver the intervention. Just a thought...";s:6:"parent";s:32:"a2ce9061c1dcaa3d8fadf05d4d6c1d38";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"5e0c74a427298705a68e0bae03259a12";}s:32:"fb9cde57b21e8b67b9fc213ad87674f9";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"gneta";s:4:"name";s:9:"Gila Neta";s:4:"mail";s:20:"netagil@mail.nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1540570286;}s:3:"raw";s:666:"Very nicely done and well thought through. You've considered a lot of important aspects to the implementation process and strategies to address them. Given the limited resources you may have in the context of just one study, you may begin to consider ways to prioritize these in case you aren't able to study all of them. One thing you might consider if you haven't already is what barriers you are most likely to run into that would pose the greatest obstacles, perhaps based on other health interventions delivered in this Nigerian context, and then select the strategies that would best address those. This would also help you make your case to reviewers/funders.";s:5:"xhtml";s:681:"Very nicely done and well thought through. You&#039;ve considered a lot of important aspects to the implementation process and strategies to address them. Given the limited resources you may have in the context of just one study, you may begin to consider ways to prioritize these in case you aren&#039;t able to study all of them. One thing you might consider if you haven&#039;t already is what barriers you are most likely to run into that would pose the greatest obstacles, perhaps based on other health interventions delivered in this Nigerian context, and then select the strategies that would best address those. This would also help you make your case to reviewers/funders.";s:6:"parent";s:32:"5f879b293c49cf3cbf4d092ccd51ba61";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"fb9cde57b21e8b67b9fc213ad87674f9";}s:32:"f6540f498a984f9493b238f1c29329e2";a:8:{s:4:"user";a:5:{s:2:"id";s:5:"gneta";s:4:"name";s:9:"Gila Neta";s:4:"mail";s:20:"netagil@mail.nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1540570917;}s:3:"raw";s:572:"Nicely done and well thought through. One question: how might you weight the various barriers that arise to determine where to focus your study, on which strategy or subset of strategies? Also, are there previous examples in the literature that might help you guess at which barriers are most likely to pose the biggest problem in this scenario, and where you may have the most leverage? It would be important a prior to make the case for which strategy or set of strategies you plan to test in Aim 2, since it's unlikely you'd have the ability/resources to test them all.";s:5:"xhtml";s:582:"Nicely done and well thought through. One question: how might you weight the various barriers that arise to determine where to focus your study, on which strategy or subset of strategies? Also, are there previous examples in the literature that might help you guess at which barriers are most likely to pose the biggest problem in this scenario, and where you may have the most leverage? It would be important a prior to make the case for which strategy or set of strategies you plan to test in Aim 2, since it&#039;s unlikely you&#039;d have the ability/resources to test them all.";s:6:"parent";s:32:"27922f7876f5c3d410f18412f8a562f8";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"f6540f498a984f9493b238f1c29329e2";}s:32:"60542e19e4d8811c12a868533ea813f6";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"wnorton";s:4:"name";s:12:"Wynne Norton";s:4:"mail";s:20:"wynne.norton@nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1540588383;}s:3:"raw";s:418:"Great description and link to literature on strategies and framework. You might consider doing an audit of existing CDS tools used in the settings in which you'd like to embed the tool. Would be interesting to see what other tools exist in the system, and you could ask providers what they like and dislike about some of those tools as part of background toward development and testing of the tool you propose herein. ";s:5:"xhtml";s:422:"Great description and link to literature on strategies and framework. You might consider doing an audit of existing CDS tools used in the settings in which you&#039;d like to embed the tool. Would be interesting to see what other tools exist in the system, and you could ask providers what they like and dislike about some of those tools as part of background toward development and testing of the tool you propose herein.";s:6:"parent";s:32:"cf5fddebc19817d21890f65f97ab06b0";s:7:"replies";a:1:{i:0;s:32:"6068cb0d6484fe126a973d8b37d163b3";}s:4:"show";b:1;s:3:"cid";s:32:"60542e19e4d8811c12a868533ea813f6";}s:32:"6068cb0d6484fe126a973d8b37d163b3";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"wnorton";s:4:"name";s:12:"Wynne Norton";s:4:"mail";s:20:"wynne.norton@nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1540588602;}s:3:"raw";s:447:"One more comment: Consider reviewing the literature on reminder fatigue. Increasing evidence that clinicians are overburdened with reminders and don't pay attention to them as much as they used to before they because ubiquitous. You could add that as part of a question into the pilot work and testing: What else might the CDS include to avoid or minimize the likelihood of reminder fatigue for reminders for referral to palliative care services. ";s:5:"xhtml";s:451:"One more comment: Consider reviewing the literature on reminder fatigue. Increasing evidence that clinicians are overburdened with reminders and don&#039;t pay attention to them as much as they used to before they because ubiquitous. You could add that as part of a question into the pilot work and testing: What else might the CDS include to avoid or minimize the likelihood of reminder fatigue for reminders for referral to palliative care services.";s:6:"parent";s:32:"60542e19e4d8811c12a868533ea813f6";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"6068cb0d6484fe126a973d8b37d163b3";}s:32:"f0ca67e4ea599386c8601c2d8cf48a13";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"wnorton";s:4:"name";s:12:"Wynne Norton";s:4:"mail";s:20:"wynne.norton@nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1540589142;}s:3:"raw";s:905:"Good consideration of the local context and selection of appropriate implementation strategies, in particular the plan to train all nursing staff given high rates of turnover. If possible, you might consider assessing the cost of the implementation strategies (not the cost-effectiveness of the intervention, which is different). This would be informative if you plan to scale-up the intervention in the future elsewhere or need to go back to some clinics to support adoption and integration of the intervention again due to low rates of use. If possible, might try to collect some data on how the strategies are received and perceived--do they like the trainings? Educational materials? Find them to be helpful? Influenced by the champions? This could also help you down the road if you need to deploy the intervention elsewhere or go back to some specific sites and provide more implementation support. ";s:5:"xhtml";s:904:"Good consideration of the local context and selection of appropriate implementation strategies, in particular the plan to train all nursing staff given high rates of turnover. If possible, you might consider assessing the cost of the implementation strategies (not the cost-effectiveness of the intervention, which is different). This would be informative if you plan to scale-up the intervention in the future elsewhere or need to go back to some clinics to support adoption and integration of the intervention again due to low rates of use. If possible, might try to collect some data on how the strategies are received and perceived--do they like the trainings? Educational materials? Find them to be helpful? Influenced by the champions? This could also help you down the road if you need to deploy the intervention elsewhere or go back to some specific sites and provide more implementation support.";s:6:"parent";s:32:"8f12a656a35109071e6bbafa135a8819";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"f0ca67e4ea599386c8601c2d8cf48a13";}s:32:"c9b24390060759260fad27a4ee8ee085";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"wnorton";s:4:"name";s:12:"Wynne Norton";s:4:"mail";s:20:"wynne.norton@nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1540589692;}s:3:"raw";s:351:"Good. Might consider delving a bit more into the potential use of external facilitation or change agents as strategies to increase adoption in care settings, in addition to the contextual factors that influence implementation, as you note above. You might also consider additional implementation strategies, such as audit and feedback, for providers. ";s:5:"xhtml";s:350:"Good. Might consider delving a bit more into the potential use of external facilitation or change agents as strategies to increase adoption in care settings, in addition to the contextual factors that influence implementation, as you note above. You might also consider additional implementation strategies, such as audit and feedback, for providers.";s:6:"parent";s:32:"f5ba0d1e3871d35f55cef0091038c33e";s:7:"replies";a:0:{}s:4:"show";b:1;s:3:"cid";s:32:"c9b24390060759260fad27a4ee8ee085";}s:32:"9d121654f62cdde06f733b2ef5395caf";a:8:{s:4:"user";a:5:{s:2:"id";s:8:"kschmitz";s:4:"name";s:15:"Kathryn Schmitz";s:4:"mail";s:20:"kschmitz@phs.psu.edu";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1540688292;}s:3:"raw";s:3863:"Schmitz assignment #5

1.	If relevant, what are the specific implementation strategies that you will be focusing on in your proposed research and how have you selected them?

Phase:  Exploration and adoption
Actor:  research team, clinical expert
Actions (Implementation strategies): Evaluation and iterative strategies: assess readiness, ID barriers and facilitators, Developing stakeholder relationships: Identification of champions, inform opinion leaders
Target: Clinic nurses (and other clinical staff, to a lesser extent)  Consumers (patients/families)
Dose: Interviews/focus groups with nursing staff (and other clinical staff), environmental assessment
(repeat with consumers)
Temporality:  Step 1
Implementation outcomes: Acceptability, appropriateness.  Process measure:  planning
Justification:  haven’t figured this out yet.  Guidance appreciated.

Phase:  Program installation
Actor: 1.Research team, 2.Champion, 3. Clinical expert from ONS
Actions: Interactive assistance: facilitation, clinical supervision, technical assistance
Target: Staff, Nurses, Clinician champion(s)
Dose: 1. Training with leaders, then all nurses
2. follow-up of training with coaching from clinical expert
Temporality: Step 2
Implementation outcomes:  Fidelity, adoption
Justification:  Haven’t figured this out yet.

Phase:  Initial implementation
Actor: Nursing staff, clinician expert
Actions: Interactive assistance:  creation/adaptation of materials to support clinical practice change
Supporting clinicians: reminders, interventions to enhance uptake;  Adapting/tailoring content: tailor strategies to the clinical setting
Target:  Patients
Dose: 1. New materials provided and revised per input; 2. reminder materials developed to enhance uptake; 3. iteratively revise to improve
Temporality: step 3
Implementation outcomes: Adoption, fidelity
Justification: Still working this out

Phase:  Full operation
Actor:  Nursing Staff, Research Staff, Clinician Expert
Actions:  Support clinicians: reminders, revisions to facilitate adoption, revise professional roles
Target: Patients
Dose: continue work from step 3, but with the full cohort of nurses involved
Temporality: Step 4
Implementation outcomes: Fidelity, implementation cost, penetration
Justification:  Still working that out.

Phase:  Innovation
Actor:  Nursing Staff, Research Staff, Consumers
Actions:  Support clinicians: Revise to make intervention easier to carry out
Engage consumers:  revise per consumer input
Target: Patients
Dose: Further revisions to promote penetration and sustainability
Temporality: Step 5
Implementation outcomes: Sustainability, penetration
Justification: Still working this out.

Phase:  Sustainability
Actor: Research team with champions
Actions: Engage consumers: Involve pts and family, use mass media to spread the word
Interactive assistance:  Develop the train the trainer model to ensure new nurses get up to speed on the intervention
Target: Patients, families, nurses
Dose: 1) Develop mass media materials, post- implementation qualitative data collection (interviews) with nurses and pts. 2) Develop train the trainer model for educating new nursing staff
Temporality: last step (6th step)
Implementation outcomes: Sustainability (hah!)
Justification:  Still working this out.

2.	How might you link specific implementation strategies to the context in which your work is set?
3 possible answers:  theory, pragmatism, empirical. I will review the literature on linking implementation strategies to the context of community oncology settings for a more complete answer.  For now, I expect to make these links using theory, but then using examples from the D&I literature for comparative, pragmatic linkages as well.  I doubt I will find any empirical approaches to the linkages.  Truth be told, I don't really understand what that means!!!

3. - not relevant.
";s:5:"xhtml";s:4201:"Schmitz assignment #5<br /><br />1.	If relevant, what are the specific implementation strategies that you will be focusing on in your proposed research and how have you selected them?<br /><br />Phase:  Exploration and adoption<br />Actor:  research team, clinical expert<br />Actions (Implementation strategies): Evaluation and iterative strategies: assess readiness, ID barriers and facilitators, Developing stakeholder relationships: Identification of champions, inform opinion leaders<br />Target: Clinic nurses (and other clinical staff, to a lesser extent)  Consumers (patients/families)<br />Dose: Interviews/focus groups with nursing staff (and other clinical staff), environmental assessment<br />(repeat with consumers)<br />Temporality:  Step 1<br />Implementation outcomes: Acceptability, appropriateness.  Process measure:  planning<br />Justification:  haven’t figured this out yet.  Guidance appreciated.<br /><br />Phase:  Program installation<br />Actor: 1.Research team, 2.Champion, 3. Clinical expert from ONS<br />Actions: Interactive assistance: facilitation, clinical supervision, technical assistance<br />Target: Staff, Nurses, Clinician champion(s)<br />Dose: 1. Training with leaders, then all nurses<br />2. follow-up of training with coaching from clinical expert<br />Temporality: Step 2<br />Implementation outcomes:  Fidelity, adoption<br />Justification:  Haven’t figured this out yet.<br /><br />Phase:  Initial implementation<br />Actor: Nursing staff, clinician expert<br />Actions: Interactive assistance:  creation/adaptation of materials to support clinical practice change<br />Supporting clinicians: reminders, interventions to enhance uptake;  Adapting/tailoring content: tailor strategies to the clinical setting<br />Target:  Patients<br />Dose: 1. New materials provided and revised per input; 2. reminder materials developed to enhance uptake; 3. iteratively revise to improve<br />Temporality: step 3<br />Implementation outcomes: Adoption, fidelity<br />Justification: Still working this out<br /><br />Phase:  Full operation<br />Actor:  Nursing Staff, Research Staff, Clinician Expert<br />Actions:  Support clinicians: reminders, revisions to facilitate adoption, revise professional roles<br />Target: Patients<br />Dose: continue work from step 3, but with the full cohort of nurses involved<br />Temporality: Step 4<br />Implementation outcomes: Fidelity, implementation cost, penetration<br />Justification:  Still working that out.<br /><br />Phase:  Innovation<br />Actor:  Nursing Staff, Research Staff, Consumers<br />Actions:  Support clinicians: Revise to make intervention easier to carry out<br />Engage consumers:  revise per consumer input<br />Target: Patients<br />Dose: Further revisions to promote penetration and sustainability<br />Temporality: Step 5<br />Implementation outcomes: Sustainability, penetration<br />Justification: Still working this out.<br /><br />Phase:  Sustainability<br />Actor: Research team with champions<br />Actions: Engage consumers: Involve pts and family, use mass media to spread the word<br />Interactive assistance:  Develop the train the trainer model to ensure new nurses get up to speed on the intervention<br />Target: Patients, families, nurses<br />Dose: 1) Develop mass media materials, post- implementation qualitative data collection (interviews) with nurses and pts. 2) Develop train the trainer model for educating new nursing staff<br />Temporality: last step (6th step)<br />Implementation outcomes: Sustainability (hah!)<br />Justification:  Still working this out.<br /><br />2.	How might you link specific implementation strategies to the context in which your work is set?<br />3 possible answers:  theory, pragmatism, empirical. I will review the literature on linking implementation strategies to the context of community oncology settings for a more complete answer.  For now, I expect to make these links using theory, but then using examples from the D&amp;I literature for comparative, pragmatic linkages as well.  I doubt I will find any empirical approaches to the linkages.  Truth be told, I don&#039;t really understand what that means!!!<br /><br />3. - not relevant.";s:6:"parent";N;s:7:"replies";a:1:{i:0;s:32:"60cd2392782cbf65ec28eb00edbbf5ef";}s:4:"show";b:1;s:3:"cid";s:32:"9d121654f62cdde06f733b2ef5395caf";}s:32:"60cd2392782cbf65ec28eb00edbbf5ef";a:8:{s:4:"user";a:5:{s:2:"id";s:7:"wnorton";s:4:"name";s:12:"Wynne Norton";s:4:"mail";s:20:"wynne.norton@nih.gov";s:7:"address";s:0:"";s:3:"url";s:0:"";}s:4:"date";a:1:{s:7:"created";i:1541088003;}s:3:"raw";s:777:"Nice detail. Just to make sure: The involvement of research staff in several of the phases is for purposes of data collection and study-specific tasks, correct? If you are in the effectiveness realm, research staff should not be involved in delivering the patient-focused intervention (I'm sure you know this but just wanted to make sure). This is also a lot of work, so I'm guessing that the first and possibly section phases will be included in R01 application? All phases is unlikely to fit within the $ limitations and 5-year timeline of an R01, in my opinion. 

There's some emerging work on calling for a stronger link between theory, selection, and use of implementation strategies (i.e., causal modeling). See article here:
https://www.ncbi.nlm.nih.gov/pubmed/29868544
";s:5:"xhtml";s:806:"Nice detail. Just to make sure: The involvement of research staff in several of the phases is for purposes of data collection and study-specific tasks, correct? If you are in the effectiveness realm, research staff should not be involved in delivering the patient-focused intervention (I&#039;m sure you know this but just wanted to make sure). This is also a lot of work, so I&#039;m guessing that the first and possibly section phases will be included in R01 application? All phases is unlikely to fit within the $ limitations and 5-year timeline of an R01, in my opinion. <br /><br />There&#039;s some emerging work on calling for a stronger link between theory, selection, and use of implementation strategies (i.e., causal modeling). See article here:<br />https://www.ncbi.nlm.nih.gov/pubmed/29868544";s:6:"parent";s:32:"9d121654f62cdde06f733b2ef5395caf";s:7:"replies";a:0:{}s:4:"show";b:0;s:3:"cid";s:32:"60cd2392782cbf65ec28eb00edbbf5ef";}}s:11:"subscribers";N;}